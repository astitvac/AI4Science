{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔬 Aavishkar.ai Expert System Notebook\n",
    "\n",
    "<img src=\"https://github.com/astitvac/AI4Science/raw/main/assets/AA_Main_Banner.jpg\" alt=\"Aavishkar.ai Banner\" width=\"600\"/>\n",
    "\n",
    "### <span style=\"color:#6C5CE7;\">AI for Science</span>\n",
    "<small><i>Democratizing advanced AI capabilities for scientific research</i></small>\n",
    "\n",
    "---\n",
    "\n",
    "## 👋 Welcome to Aavishkar.ai Expert Systems!\n",
    "\n",
    "<small>This notebook is part of the <b>Aavishkar.ai AI4Science</b> initiative, which develops LLM-based expert systems to enhance scientific research workflows. Our expert systems formalize scientific cognitive processes using Large Language Models, structured knowledge representations, and interactive interfaces.</small>\n",
    "\n",
    "### 🧠 About This Expert System\n",
    "\n",
    "<small>This notebook implements one of the five scientific cognitive archetypes developed by Aavishkar.ai:</small>\n",
    "\n",
    "<small>\n",
    "1. 📚 <b>Literature Synthesist</b>: Identifies patterns, contradictions, and knowledge gaps across research corpora<br>\n",
    "2. 🧪 <b>Experimental Architect</b>: Translates abstract hypotheses into methodologically sound experimental designs<br>\n",
    "3. 📊 <b>Analytical Navigator</b>: Constructs adaptive analytical pathways through complex datasets<br>\n",
    "4. 📝 <b>Research Documentarian</b>: Structures and articulates scientific findings and methodologies<br>\n",
    "5. 🔄 <b>Interdisciplinary Translator</b>: Establishes conceptual bridges between disparate knowledge domains\n",
    "</small>\n",
    "\n",
    "### 👥 Who Can Use This?\n",
    "\n",
    "<small>\n",
    "Aavishkar.ai tools are designed for all practitioners of hypothesis-driven science:<br>\n",
    "• 🎓 Academic researchers and students<br>\n",
    "• 🏢 Commercial/industrial researchers<br>\n",
    "• 🏛️ Government scientists<br>\n",
    "• 🔭 Citizen scientists<br>\n",
    "• 🧩 Independent researchers\n",
    "</small>\n",
    "\n",
    "<small>No matter your technical background or institutional affiliation, this notebook provides accessible AI capabilities for rigorous scientific work.</small>\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ Setup Instructions\n",
    "\n",
    "<small>\n",
    "\n",
    "**Google Colab**\n",
    "* Click on \"Runtime\" in the menu\n",
    "* Select \"Run all\" to install dependencies and initialize the system\n",
    "* Ensure you have your API keys ready for the LLM provider\n",
    "\n",
    "**Local Environment**\n",
    "* Ensure you have Python 3.8+ installed\n",
    "* Install dependencies by running the installation cell below\n",
    "* Set up your API keys as instructed in the initialization section\n",
    "\n",
    "**Prerequisites**\n",
    "* Python 3.8+\n",
    "* API key for OpenAI or Google Vertex AI\n",
    "* Basic familiarity with Jupyter notebooks\n",
    "\n",
    "</small>\n",
    "\n",
    "---\n",
    "\n",
    "### 📜 License\n",
    "\n",
    "<small>This project is licensed under the <b>MIT License</b></small>\n",
    "\n",
    "<small>\n",
    "<details>\n",
    "<summary>View License Text</summary>\n",
    "MIT License<br><br>\n",
    "Copyright (c) 2023-2024 Aavishkar.ai<br><br>\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:<br><br>\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "</details>\n",
    "</small>\n",
    "\n",
    "<small>\n",
    "\n",
    "### 🔗 Connect with Aavishkar.ai\n",
    "* 📦 **GitHub**: [github.com/astitvac/AI4Science](https://github.com/astitvac/AI4Science)\n",
    "* 🌐 **Website**: [aavishkar.ai](https://aavishkar.ai)\n",
    "* 💬 **Community**: [Discord](https://discord.gg/aavishkar)\n",
    "* 🤝 **Contribute**: [Contribution Guidelines](https://github.com/astitvac/AI4Science/tree/main/Contributing)\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Installation\n",
    "<small>\n",
    "This cell installs all required dependencies for this expert system notebook. The installation process uses uv for faster package management when available, with automatic fallback to standard pip.\n",
    "Key components being installed:\n",
    "LLM frameworks: LangChain and provider-specific libraries\n",
    "Data modeling: Pydantic\n",
    "UI: Gradio\n",
    "Core utilities: Data processing and visualization libraries\n",
    "Troubleshooting tips:\n",
    "If you encounter errors, try running the cell again\n",
    "For persistent issues, check your Python version (3.8+ required)\n",
    "In Colab, restart the runtime if packages aren't recognized after installation\n",
    "Note: Initial installation may take 1-2 minutes to complete. A confirmation message will appear when successful.\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "import sys, os, subprocess, time\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# All required packages (no version constraints for better future-proofing)\n",
    "ALL_PACKAGES = {\n",
    "    \"core\": \"langchain pydantic python-dotenv langgraph\",\n",
    "    \"providers\": \"langchain-openai langchain-google-vertexai langchain_experimental\",\n",
    "    \"ui\": \"gradio\",\n",
    "    \"data\": \"numpy pandas matplotlib plotly\",\n",
    "    \"documents\": \"pypdf PyPDF2 pillow\",\n",
    "    \"vectors\": \"chromadb sentence-transformers\"\n",
    "}\n",
    "\n",
    "# Environment detection\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "def show(msg, type=\"info\"):\n",
    "    \"\"\"Message Formatting\"\"\"\n",
    "    colors = {\"info\": \"#3a7bd5\", \"success\": \"#00c853\", \"warning\": \"#f57c00\", \"error\": \"#d50000\"}\n",
    "    icons = {\"info\": \"ℹ️\", \"success\": \"✅\", \"warning\": \"⚠️\", \"error\": \"❌\"}\n",
    "    display(HTML(f\"<div style='color:white; background:{colors[type]}; padding:5px; margin:2px 0; border-radius:3px'>{icons[type]} {msg}</div>\"))\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install all packages\"\"\"\n",
    "    start = time.time()\n",
    "    show(\"Starting installation...\", \"info\")\n",
    "    \n",
    "    # Try to use uv for faster installation\n",
    "    try:\n",
    "        subprocess.run(\"pip install -q uv\", shell=True, check=True, timeout=30)\n",
    "        installer = \"uv pip\"\n",
    "    except:\n",
    "        installer = \"pip\"\n",
    "    \n",
    "    # Install each category\n",
    "    success_count = 0\n",
    "    total_categories = len(ALL_PACKAGES)\n",
    "    \n",
    "    for category, packages in ALL_PACKAGES.items():\n",
    "        try:\n",
    "            # Install entire category at once for speed\n",
    "            cmd = f\"{installer} install -q {packages}\"\n",
    "            result = subprocess.run(cmd, shell=True, capture_output=True, timeout=120)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                success_count += 1\n",
    "        except Exception:\n",
    "            pass  # Silent failure, will be reflected in final success rate\n",
    "    \n",
    "    # Simple verification of core packages\n",
    "    try:\n",
    "        import langchain\n",
    "        import pydantic\n",
    "        import gradio\n",
    "        verification = \"with verification\"\n",
    "    except ImportError:\n",
    "        verification = \"with partial verification failures\"\n",
    "    \n",
    "    # Single completion message with success rate\n",
    "    elapsed = time.time() - start\n",
    "    success_rate = int((success_count / total_categories) * 100)\n",
    "    show(f\"Installation completed in {elapsed:.1f}s ({success_rate}% success) {verification}\", \n",
    "         \"success\" if success_rate > 80 else \"warning\")\n",
    "    \n",
    "    return success_rate > 80\n",
    "\n",
    "# Run installation\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Initialization\n",
    "\n",
    "<small>This section configures the LLM provider, API keys, and core components needed for this expert system. The implementation follows a modular architecture that supports multiple AI providers and environments.</small>\n",
    "\n",
    "## Purpose\n",
    "\n",
    "<small>The initialization process:\n",
    "1. **Sets up environment variables** including API keys\n",
    "2. **Configures the LLM provider** with appropriate models and settings\n",
    "3. **Initializes specialized capabilities** when needed (e.g., vision, embedding)\n",
    "4. **Validates the environment** to ensure all requirements are met\n",
    "</small>\n",
    "\n",
    "## Configuration Options\n",
    "\n",
    "<small>\n",
    "You can customize the initialization by adjusting these parameters:\n",
    "\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| **Provider** | AI service to use (OpenAI, Google, etc.) | OpenAI |\n",
    "| **Model** | Specific model name | Depends on provider |\n",
    "| **Temperature** | Creativity level (0.0-1.0) | 0.7 |\n",
    "| **Features** | Additional capabilities to enable | None |\n",
    "\n",
    "**💡 Tip**: For reproducible results, use lower temperature values (0.0-0.3).\n",
    "</small>\n",
    "\n",
    "## Provider Support\n",
    "\n",
    "<small>\n",
    "This notebook supports these LLM providers:\n",
    "\n",
    "- **OpenAI**: GPT-4, GPT-3.5-Turbo\n",
    "- **Google**: Gemini Pro, PaLM\n",
    "- **Anthropic**: Claude (optional)\n",
    "- **Local**: Ollama with various models (optional)\n",
    "\n",
    "**Note**: Different providers may have varying capabilities and pricing structures.\n",
    "</small>\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "<small>\n",
    "**For Google Colab:**\n",
    "1. Store your API keys in Colab Secrets\n",
    "2. Select your provider from the dropdown\n",
    "3. Run the initialization cell\n",
    "\n",
    "**For Local Environment:**\n",
    "1. Create a `.env` file with your API keys\n",
    "2. Select your provider\n",
    "3. Run the initialization cell\n",
    "\n",
    "**API Key Variables:**\n",
    "- OpenAI: `OPENAI_API_KEY`\n",
    "- Google: `GOOGLE_API_KEY`\n",
    "- Anthropic: `ANTHROPIC_API_KEY`\n",
    "</small>\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "<small>\n",
    "Common issues:\n",
    "- **Authentication errors**: Check your API key is correctly set\n",
    "- **Model unavailability**: Ensure you have access to the specified model\n",
    "- **Import errors**: Run the installation cell first\n",
    "- **Memory issues**: Select a smaller model or reduce context length\n",
    "\n",
    "The initialization cell includes diagnostics that will help identify any configuration problems.\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 LLM Setup\n",
    "import os, sys\n",
    "from IPython.display import Markdown, display\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "\n",
    "# Colab form fields for configuration\n",
    "# @title LLM Configuration\n",
    "api_key = \"\" # @param {type:\"string\"}\n",
    "model = \"gpt-4o\" # @param [\"gpt-4o\", \"gpt-4-turbo\", \"gpt-4\", \"gpt-3.5-turbo\"]\n",
    "embedding_model = \"text-embedding-3-small\" # @param [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]\n",
    "temperature = 0.7 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "debug = False # @param {type:\"boolean\"}\n",
    "\n",
    "# Environment detection\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "def show(msg, type=\"info\"):\n",
    "    \"\"\"Display styled message\"\"\"\n",
    "    if type == \"debug\" and not debug:\n",
    "        return\n",
    "    colors = {\"success\": \"#00C853\", \"info\": \"#2196F3\", \"warning\": \"#FF9800\", \"error\": \"#F44336\", \"debug\": \"#9C27B0\"}\n",
    "    icons = {\"success\": \"✅\", \"info\": \"ℹ️\", \"warning\": \"⚠️\", \"error\": \"❌\", \"debug\": \"🔍\"}\n",
    "    display(Markdown(f\"<div style='padding:8px;border-radius:4px;background:{colors[type]};color:white'>{icons[type]} {msg}</div>\"))\n",
    "\n",
    "def get_api_key() -> Optional[str]:\n",
    "    \"\"\"Get API key from various possible sources\"\"\"\n",
    "    # Check form input first\n",
    "    key = api_key\n",
    "    \n",
    "    # Try Colab secret if empty and in Colab\n",
    "    if not key and IN_COLAB:\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            key = userdata.get('openai_api_key')\n",
    "            if key:\n",
    "                show(\"API key loaded from Colab secret\", \"success\")\n",
    "        except Exception as e:\n",
    "            show(f\"Error accessing Colab secrets: {e}\", \"debug\")\n",
    "    \n",
    "    # Try environment variable\n",
    "    if not key:\n",
    "        key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "        if key:\n",
    "            show(\"API key loaded from environment variable\", \"debug\")\n",
    "    \n",
    "    # Try .env file\n",
    "    if not key:\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "            key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "            if key:\n",
    "                show(\"API key loaded from .env file\", \"debug\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Final check and request if needed\n",
    "    if not key:\n",
    "        if IN_COLAB:\n",
    "            show(\"\"\"\n",
    "            No API key found. Either:\n",
    "            1. Add it in the form field above\n",
    "            2. Set a Colab secret named 'openai_api_key'\n",
    "            \"\"\", \"warning\")\n",
    "        else:\n",
    "            show(\"No API key found. Add it in the form field or set OPENAI_API_KEY environment variable\", \"warning\")\n",
    "        return None\n",
    "        \n",
    "    return key\n",
    "\n",
    "# === PROVIDER-SPECIFIC: OPENAI ===\n",
    "def initialize_models(api_key: str) -> Tuple[Optional[Any], Optional[Any]]:\n",
    "    \"\"\"Initialize OpenAI models with the provided API key\"\"\"\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    \n",
    "    # Set environment variable for consistency\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    try:\n",
    "        llm = ChatOpenAI(\n",
    "            model_name=model,\n",
    "            temperature=temperature,\n",
    "            openai_api_key=api_key\n",
    "        )\n",
    "        \n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=embedding_model,\n",
    "            openai_api_key=api_key\n",
    "        )\n",
    "        \n",
    "        show(f\"OpenAI initialized with {model} and {embedding_model}\", \"success\")\n",
    "        return llm, embeddings\n",
    "        \n",
    "    except Exception as e:\n",
    "        show(f\"Error initializing OpenAI: {e}\", \"error\")\n",
    "        return None, None\n",
    "# === END PROVIDER-SPECIFIC ===\n",
    "\n",
    "def initialize_llm() -> Tuple[Optional[Any], Optional[Any]]:\n",
    "    \"\"\"Main function to set up and initialize LLM\"\"\"\n",
    "    show(\"Initializing LLM...\", \"info\")\n",
    "    \n",
    "    # Get API key\n",
    "    key = get_api_key()\n",
    "    if not key:\n",
    "        return None, None\n",
    "    \n",
    "    # Initialize models\n",
    "    llm, embeddings = initialize_models(key)\n",
    "    \n",
    "    if llm and embeddings:\n",
    "        show(\"Initialization complete! LLM and embeddings ready to use.\", \"success\")\n",
    "    \n",
    "    return llm, embeddings\n",
    "\n",
    "# Run initialization\n",
    "llm, embeddings = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ Core Utilities\n",
    "\"\"\"\n",
    "Core utilities for Aavishkar.ai expert systems.\n",
    "Includes logging, caching, error handling, and JSON parsing.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time, hashlib, functools\n",
    "from typing import Dict, Any, Optional, Callable, Union\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# === GLOBAL SETTINGS ===\n",
    "DEBUG_MODE = False\n",
    "CACHE_ENABLED = True\n",
    "CACHE_DIR = \"./cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# === DISPLAY & ERROR HANDLING ===\n",
    "def show(msg: str, level: str = \"info\") -> None:\n",
    "    \"\"\"Display formatted message with appropriate styling.\n",
    "    \n",
    "    Args:\n",
    "        msg: Message to display\n",
    "        level: Message level (success, info, warning, error, debug)\n",
    "    \"\"\"\n",
    "    colors = {\"success\": \"#00C853\", \"info\": \"#2196F3\", \"warning\": \"#FF9800\", \"error\": \"#F44336\", \"debug\": \"#9C27B0\"}\n",
    "    icons = {\"success\": \"✅\", \"info\": \"ℹ️\", \"warning\": \"⚠️\", \"error\": \"❌\", \"debug\": \"🔍\"}\n",
    "    \n",
    "    if level == \"debug\" and not DEBUG_MODE:\n",
    "        return\n",
    "        \n",
    "    color = colors.get(level, colors[\"info\"])\n",
    "    icon = icons.get(level, icons[\"info\"])\n",
    "    display(Markdown(f\"<div style='padding:6px;border-radius:4px;background:{color};color:white'>{icon} {msg}</div>\"))\n",
    "\n",
    "def retry(max_attempts: int = 3, delay: float = 1.0) -> Callable:\n",
    "    \"\"\"Decorator for retrying functions with exponential backoff.\"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for attempt in range(1, max_attempts + 1):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    if attempt == max_attempts:\n",
    "                        raise\n",
    "                    wait = delay * (2 ** (attempt - 1))\n",
    "                    show(f\"Attempt {attempt} failed: {str(e)}. Retrying in {wait:.1f}s...\", \"warning\")\n",
    "                    time.sleep(wait)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# === CACHE SYSTEM ===\n",
    "def cache_key(**kwargs) -> str:\n",
    "    \"\"\"Generate a cache key from input parameters.\"\"\"\n",
    "    serialized = json.dumps({k: v for k, v in kwargs.items() if v is not None}, sort_keys=True)\n",
    "    return hashlib.md5(serialized.encode()).hexdigest()\n",
    "\n",
    "def get_cache(key: str) -> Optional[Any]:\n",
    "    \"\"\"Get item from cache if available and not expired.\"\"\"\n",
    "    if not CACHE_ENABLED:\n",
    "        return None\n",
    "        \n",
    "    path = os.path.join(CACHE_DIR, f\"{key}.json\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Check if expired (default: 1 day)\n",
    "        if time.time() - data.get(\"timestamp\", 0) > 86400:\n",
    "            return None\n",
    "            \n",
    "        return data.get(\"value\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def set_cache(key, value):\n",
    "    \"\"\"Store value in cache with current timestamp.\"\"\"\n",
    "    if not CACHE_ENABLED:\n",
    "        return\n",
    "        \n",
    "    path = os.path.join(CACHE_DIR, f\"{key}.json\")\n",
    "    try:\n",
    "        # Handle Pydantic models by converting to dictionaries\n",
    "        def serialize_pydantic(obj):\n",
    "            if hasattr(obj, 'model_dump'):  # Pydantic v2 models use model_dump\n",
    "                return obj.model_dump()\n",
    "            elif hasattr(obj, 'dict'):      # Older Pydantic models use dict()\n",
    "                return obj.dict()\n",
    "            elif isinstance(obj, list):\n",
    "                return [serialize_pydantic(item) for item in obj]\n",
    "            elif isinstance(obj, dict):\n",
    "                return {k: serialize_pydantic(v) for k, v in obj.items()}\n",
    "            return obj\n",
    "            \n",
    "        serialized_value = serialize_pydantic(value)\n",
    "        \n",
    "        with open(path, 'w') as f:\n",
    "            json.dump({\"timestamp\": time.time(), \"value\": serialized_value}, f)\n",
    "            \n",
    "    except Exception as e:\n",
    "        show(f\"Cache write error: {str(e)}\", \"debug\")\n",
    "\n",
    "def clear_cache(older_than: Optional[int] = None) -> int:\n",
    "    \"\"\"Clear cache entries, optionally only those older than specified seconds.\n",
    "    \n",
    "    Returns:\n",
    "        Number of entries cleared\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CACHE_DIR):\n",
    "        return 0\n",
    "        \n",
    "    count = 0\n",
    "    for filename in os.listdir(CACHE_DIR):\n",
    "        if not filename.endswith('.json'):\n",
    "            continue\n",
    "            \n",
    "        path = os.path.join(CACHE_DIR, filename)\n",
    "        \n",
    "        if older_than:\n",
    "            try:\n",
    "                with open(path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                if time.time() - data.get(\"timestamp\", 0) <= older_than:\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            os.remove(path)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return count\n",
    "\n",
    "# === LLM & JSON HELPERS ===\n",
    "def call_llm_with_cache(llm, prompt: str, **kwargs) -> Any:\n",
    "    \"\"\"Call LLM with caching to avoid redundant API calls.\"\"\"\n",
    "    if CACHE_ENABLED:\n",
    "        key = cache_key(prompt=prompt, **kwargs)\n",
    "        cached = get_cache(key)\n",
    "        if cached:\n",
    "            show(\"Using cached response\", \"debug\")\n",
    "            return cached\n",
    "    \n",
    "    response = llm.invoke(prompt, **kwargs)\n",
    "    \n",
    "    if CACHE_ENABLED:\n",
    "        set_cache(key, response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "def parse_json_safely(text: str, default: Any = None) -> Any:\n",
    "    \"\"\"Extract and parse JSON from text with multiple fallback strategies.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Try direct parsing first\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try to extract JSON blocks\n",
    "    try:\n",
    "        # Try code blocks with JSON\n",
    "        if \"```json\" in text:\n",
    "            json_block = text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "            return json.loads(json_block)\n",
    "            \n",
    "        # Try any code blocks\n",
    "        if \"```\" in text:\n",
    "            code_block = text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "            if code_block.strip().startswith((\"{\", \"[\")):\n",
    "                return json.loads(code_block)\n",
    "        \n",
    "        # Try regex patterns for JSON objects/arrays\n",
    "        patterns = [\n",
    "            r'\\{[\\s\\S]*?\\}',  # JSON objects\n",
    "            r'\\[[\\s\\S]*?\\]'   # JSON arrays\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    return json.loads(match)\n",
    "                except:\n",
    "                    continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return default\n",
    "\n",
    "# Initialization\n",
    "show(\"Core utilities initialized\", \"debug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Experimental Design Optimizer\n",
    "\n",
    "## Purpose\n",
    "Analyzes experimental protocols from scientific papers to identify methodological improvements, ensuring greater rigor, reproducibility, and statistical validity.\n",
    "\n",
    "## Core Functions\n",
    "\n",
    "* **Protocol Extraction**\n",
    "  * Identifies variables, controls, and experimental procedures\n",
    "  * Extracts sample sizes and statistical approaches\n",
    "  * Captures methodological details and measurement techniques\n",
    "\n",
    "* **Literature Search**\n",
    "  * Finds related protocols in scientific literature\n",
    "  * Identifies methodological standards and best practices\n",
    "  * Discovers field-specific guidelines and requirements\n",
    "\n",
    "* **Weakness Analysis**\n",
    "  * Evaluates statistical rigor and power\n",
    "  * Identifies potential sources of bias\n",
    "  * Assesses reproducibility and reporting completeness\n",
    "\n",
    "* **Protocol Optimization**\n",
    "  * Generates specific improvements with justifications\n",
    "  * Enhances controls and randomization procedures\n",
    "  * Aligns with field-specific standards and practices\n",
    "\n",
    "* **Validation**\n",
    "  * Verifies optimized protocol against methodological standards\n",
    "  * Provides confidence ratings for recommendations\n",
    "  * Highlights areas requiring human expert review\n",
    "\n",
    "## Input\n",
    "\n",
    "* PDF upload, plain text, or structured method description\n",
    "* Best results with papers containing detailed methods sections\n",
    "* Works with protocols from various scientific domains\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Run setup cells (installation and initialization)\n",
    "2. Upload or input a scientific paper's methods section\n",
    "3. Extract the experimental protocol\n",
    "4. Review and initiate optimization process\n",
    "5. Explore improvements and supporting literature\n",
    "\n",
    "**Note**: The system assists researchers in designing more robust experiments but should be used alongside human expertise.\n",
    "\n",
    "---\n",
    "\n",
    "*Implementation of the Experimental Architect cognitive archetype from Aavishkar.ai*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models\n",
    "\n",
    "## Purpose\n",
    "\n",
    "<small>\n",
    "This section defines the structured data representations that power our Literature Synthesis system. These Pydantic models perform two essential functions:\n",
    "\n",
    "1. **Represent Knowledge**: Define how scientific concepts, relationships, and documents are structured\n",
    "2. **Control System Behavior**: Configure how the system processes and analyzes content\n",
    "</small>\n",
    "\n",
    "## How It Works\n",
    "\n",
    "<small>\n",
    "Our system uses Pydantic models to ensure data validation and clear structure. Think of these models as \"smart containers\" that:\n",
    "\n",
    "- Validate data to prevent errors\n",
    "- Provide helpful error messages when something is wrong\n",
    "- Include documentation for each field\n",
    "- Support extensibility for specialized needs\n",
    "</small>\n",
    "\n",
    "## Core Models\n",
    "\n",
    "<small>\n",
    "Our implementation uses these key models:\n",
    "\n",
    "| Model | Purpose |\n",
    "|-------|---------|\n",
    "| **LitSynthConfig** | Consolidated configuration for all system parameters |\n",
    "| **Concept** | Scientific concepts extracted from literature |\n",
    "| **Relationship** | Connections between scientific concepts |\n",
    "| **ResearchGap** | Identified research gaps and opportunities |\n",
    "| **LiteratureSynthesisOutput** | Complete analysis results container |\n",
    "\n",
    "We've simplified the configuration into a single model (`LitSynthConfig`) to make customization easier. You can adjust parameters by modifying the `config` variable in the code cell.\n",
    "</small>\n",
    "\n",
    "## Customization\n",
    "\n",
    "<small>\n",
    "To customize the system behavior, simply modify the config variable:\n",
    "\n",
    "```python\n",
    "# Example: Increase sensitivity to detect more concepts\n",
    "config.extraction_confidence = 0.6\n",
    "config.max_concepts = 40\n",
    "\n",
    "# Example: Focus only on high-importance concepts\n",
    "config.min_concept_importance = \"high\"\n",
    "```\n",
    "\n",
    "This approach allows you to tune the system's behavior without changing the core models or implementation.\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 Data Models\n",
    "\"\"\"\n",
    "This section defines the data structures used throughout the Experimental Architect system.\n",
    "These models represent experimental protocols, process agent reasoning, and track tool usage.\n",
    "\n",
    "CUSTOMIZATION TIPS:\n",
    "1. Update field descriptions to match your domain terminology\n",
    "2. Add domain-specific protocol elements for specialized experiments\n",
    "3. Extend the protocol validation for field-specific requirements\n",
    "4. Modify confidence metrics for different protocol components\n",
    "\n",
    "Each model includes validators to ensure data integrity and clear documentation.\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List, Dict, Optional, Literal, Any, Union, Set\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "import uuid\n",
    "\n",
    "def show_info(message):\n",
    "    \"\"\"Display styled info message.\"\"\"\n",
    "    display(Markdown(f\"<div style='padding:5px;border-radius:3px;background:#2196F3;color:white'>ℹ️ {message}</div>\"))\n",
    "\n",
    "\n",
    "# ===== INPUT MODELS =====\n",
    "# Models for document input and configuration\n",
    "\n",
    "class DocumentSource(BaseModel):\n",
    "    \"\"\"Input document source with type and content.\n",
    "    \n",
    "    This model represents an input document to be analyzed.\n",
    "    It supports multiple source types and includes metadata.\n",
    "    \n",
    "    Attributes:\n",
    "        source_type: The type of document source (pdf, text, etc.)\n",
    "        content: The document content or file path\n",
    "        metadata: Additional information about the document\n",
    "    \"\"\"\n",
    "    source_type: Literal[\"pdf\", \"text\", \"url\", \"doi\", \"arxiv\"]\n",
    "    content: str\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "\n",
    "# ===== AGENT STATE MODELS =====\n",
    "# Models for tracking agent reasoning, actions, and state\n",
    "\n",
    "class AgentStep(BaseModel):\n",
    "    \"\"\"Represents a single step in the agent's reasoning process.\n",
    "    \n",
    "    This model captures the agent's thought process, actions, and observations\n",
    "    to enable transparent reasoning and effective debugging.\n",
    "    \n",
    "    Attributes:\n",
    "        id: Unique identifier for this step\n",
    "        timestamp: When this step occurred\n",
    "        step_type: Type of step (thought, action, observation, final_answer)\n",
    "        content: The actual content of the step\n",
    "        tool_name: Name of the tool used (if action)\n",
    "        tool_input: Input provided to the tool (if action)\n",
    "        tokens_used: Estimated tokens used in this step\n",
    "    \"\"\"\n",
    "    id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "    step_type: Literal[\"thought\", \"action\", \"observation\", \"final_answer\"]\n",
    "    content: str\n",
    "    tool_name: Optional[str] = None\n",
    "    tool_input: Optional[str] = None\n",
    "    tokens_used: int = 0\n",
    "    \n",
    "    @field_validator('step_type')\n",
    "    @classmethod\n",
    "    def validate_step_type(cls, v):\n",
    "        \"\"\"Ensure step type is valid.\"\"\"\n",
    "        valid_types = [\"thought\", \"action\", \"observation\", \"final_answer\"]\n",
    "        if v not in valid_types:\n",
    "            raise ValueError(f\"Step type must be one of: {', '.join(valid_types)}\")\n",
    "        return v\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    \"\"\"Structured representation of a search tool result.\n",
    "    \n",
    "    This model represents results from search tools (ArXiv, web search),\n",
    "    with metadata to track relevance and source information.\n",
    "    \n",
    "    Attributes:\n",
    "        query: Original search query\n",
    "        source: Source of the result (arxiv, web, etc.)\n",
    "        title: Title of the result\n",
    "        content: Main content of the result\n",
    "        url: Source URL if available\n",
    "        date: Publication date if available\n",
    "        authors: List of authors if available\n",
    "        relevance_score: Estimated relevance to the query (0-1)\n",
    "        keywords: Extracted keywords from the result\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    source: Literal[\"arxiv\", \"web\", \"pubmed\", \"other\"]\n",
    "    title: str\n",
    "    content: str\n",
    "    url: Optional[str] = None\n",
    "    date: Optional[str] = None\n",
    "    authors: List[str] = Field(default_factory=list)\n",
    "    relevance_score: float = Field(default=0.5, ge=0.0, le=1.0)\n",
    "    keywords: List[str] = Field(default_factory=list)\n",
    "    \n",
    "    def truncated_content(self, max_chars: int = 500) -> str:\n",
    "        \"\"\"Return a truncated version of the content for display.\"\"\"\n",
    "        if len(self.content) <= max_chars:\n",
    "            return self.content\n",
    "        return self.content[:max_chars] + \"...\"\n",
    "\n",
    "class AgentState(BaseModel):\n",
    "    \"\"\"Complete agent state tracking structure.\n",
    "    \n",
    "    This model maintains the full state of the agent during execution,\n",
    "    including reasoning steps, search results, and any extracted protocols.\n",
    "    It provides methods for updating state and accessing history.\n",
    "    \n",
    "    Attributes:\n",
    "        steps: List of agent reasoning steps\n",
    "        search_results: List of search results from tools\n",
    "        extracted_protocol: The extracted protocol being analyzed\n",
    "        optimized_protocol: The optimized protocol (final output)\n",
    "        start_time: When the agent began execution\n",
    "        finished: Whether the agent has completed its task\n",
    "        final_answer: The agent's final response\n",
    "        facts: Set of established facts (for consistency)\n",
    "    \"\"\"\n",
    "    steps: List[AgentStep] = Field(default_factory=list)\n",
    "    search_results: List[SearchResult] = Field(default_factory=list)\n",
    "    extracted_protocol: Optional[\"ExperimentalProtocol\"] = None\n",
    "    optimized_protocol: Optional[\"OptimizedProtocolOutput\"] = None\n",
    "    start_time: datetime = Field(default_factory=datetime.now)\n",
    "    finished: bool = False\n",
    "    final_answer: str = \"\"\n",
    "    facts: Set[str] = Field(default_factory=set)\n",
    "    \n",
    "    def add_thought(self, thought: str) -> None:\n",
    "        \"\"\"Add a thought step to the agent state.\"\"\"\n",
    "        self.steps.append(AgentStep(\n",
    "            step_type=\"thought\",\n",
    "            content=thought\n",
    "        ))\n",
    "    \n",
    "    def add_action(self, tool_name: str, tool_input: str) -> None:\n",
    "        \"\"\"Add an action step to the agent state.\"\"\"\n",
    "        self.steps.append(AgentStep(\n",
    "            step_type=\"action\",\n",
    "            content=f\"{tool_name}: {tool_input}\",\n",
    "            tool_name=tool_name,\n",
    "            tool_input=tool_input\n",
    "        ))\n",
    "    \n",
    "    def add_observation(self, observation: str) -> None:\n",
    "        \"\"\"Add an observation step to the agent state.\"\"\"\n",
    "        self.steps.append(AgentStep(\n",
    "            step_type=\"observation\",\n",
    "            content=observation\n",
    "        ))\n",
    "    \n",
    "    def add_search_result(self, result: SearchResult) -> None:\n",
    "        \"\"\"Add a search result to the agent state.\"\"\"\n",
    "        self.search_results.append(result)\n",
    "    \n",
    "    def add_final_answer(self, answer: str) -> None:\n",
    "        \"\"\"Add the final answer and mark as finished.\"\"\"\n",
    "        self.steps.append(AgentStep(\n",
    "            step_type=\"final_answer\",\n",
    "            content=answer\n",
    "        ))\n",
    "        self.final_answer = answer\n",
    "        self.finished = True\n",
    "    \n",
    "    def get_recent_steps(self, n: int = 5) -> List[AgentStep]:\n",
    "        \"\"\"Get the most recent n steps.\"\"\"\n",
    "        return self.steps[-n:] if self.steps else []\n",
    "    \n",
    "    def get_formatted_history(self) -> str:\n",
    "        \"\"\"Get a formatted string of the agent's reasoning history.\"\"\"\n",
    "        history = \"\"\n",
    "        for step in self.steps:\n",
    "            if step.step_type == \"thought\":\n",
    "                history += f\"\\nThought: {step.content}\\n\"\n",
    "            elif step.step_type == \"action\":\n",
    "                history += f\"Action: {step.tool_name}\\nAction Input: {step.tool_input}\\n\"\n",
    "            elif step.step_type == \"observation\":\n",
    "                history += f\"Observation: {step.content}\\n\"\n",
    "            elif step.step_type == \"final_answer\":\n",
    "                history += f\"Final Answer: {step.content}\\n\"\n",
    "        return history\n",
    "    \n",
    "    def add_fact(self, fact: str) -> None:\n",
    "        \"\"\"Add a verified fact to the agent's knowledge.\"\"\"\n",
    "        self.facts.add(fact)\n",
    "    \n",
    "    def execution_time(self) -> float:\n",
    "        \"\"\"Calculate execution time in seconds.\"\"\"\n",
    "        return (datetime.now() - self.start_time).total_seconds()\n",
    "\n",
    "\n",
    "# ===== PROTOCOL REPRESENTATION MODELS =====\n",
    "# Models for representing experimental protocols and their elements\n",
    "\n",
    "class VariableDefinition(BaseModel):\n",
    "    \"\"\"Definition of an experimental variable.\n",
    "    \n",
    "    This model represents a variable in an experimental protocol,\n",
    "    including its type, description, and measurement details.\n",
    "    \n",
    "    Attributes:\n",
    "        name: Name of the variable\n",
    "        var_type: Type of variable (independent, dependent, control, covariate)\n",
    "        description: Detailed description of the variable\n",
    "        measurement_method: How the variable is measured\n",
    "        units: Units of measurement if applicable\n",
    "        levels: Different levels/values for the variable (e.g., dosages)\n",
    "        operational_definition: Precise operational definition of the variable\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    var_type: Literal[\"independent\", \"dependent\", \"control\", \"covariate\"]\n",
    "    description: str\n",
    "    measurement_method: Optional[str] = None\n",
    "    units: Optional[str] = None\n",
    "    levels: List[str] = Field(default_factory=list)\n",
    "    operational_definition: Optional[str] = None\n",
    "    \n",
    "    @field_validator('name')\n",
    "    @classmethod\n",
    "    def validate_name(cls, v):\n",
    "        \"\"\"Ensure variable name is valid.\"\"\"\n",
    "        if len(v.strip()) < 2:\n",
    "            raise ValueError(\"Variable name must be at least 2 characters\")\n",
    "        return v.strip()\n",
    "\n",
    "class ProcedureStep(BaseModel):\n",
    "    \"\"\"A step in the experimental procedure.\n",
    "    \n",
    "    This model represents a single step in an experimental protocol,\n",
    "    including what to do, timing, and any relevant materials.\n",
    "    \n",
    "    Attributes:\n",
    "        step_number: Sequence number of this step\n",
    "        description: Detailed description of the step\n",
    "        duration: Time required for this step\n",
    "        materials: Materials needed for this step\n",
    "        equipment: Equipment needed for this step\n",
    "        critical: Whether this step is critical to protocol integrity\n",
    "        notes: Additional notes or cautions\n",
    "    \"\"\"\n",
    "    step_number: int\n",
    "    description: str\n",
    "    duration: Optional[str] = None\n",
    "    materials: List[str] = Field(default_factory=list)\n",
    "    equipment: List[str] = Field(default_factory=list)\n",
    "    critical: bool = False\n",
    "    notes: Optional[str] = None\n",
    "\n",
    "class AnalysisMethod(BaseModel):\n",
    "    \"\"\"Statistical or analytical method used in the experiment.\n",
    "    \n",
    "    This model represents a statistical or data analysis approach\n",
    "    used to analyze experimental results.\n",
    "    \n",
    "    Attributes:\n",
    "        name: Name of the analysis method\n",
    "        description: Detailed description of the method\n",
    "        software: Software used for analysis\n",
    "        parameters: Key parameters for the analysis\n",
    "        assumptions: Assumptions that must be met\n",
    "        justification: Justification for using this method\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    software: Optional[str] = None\n",
    "    parameters: Dict[str, Any] = Field(default_factory=dict)\n",
    "    assumptions: List[str] = Field(default_factory=list)\n",
    "    justification: Optional[str] = None\n",
    "\n",
    "class ExperimentalProtocol(BaseModel):\n",
    "    \"\"\"Comprehensive representation of an experimental protocol.\n",
    "    \n",
    "    This model represents a complete experimental protocol\n",
    "    extracted from scientific literature or created through optimization.\n",
    "    \n",
    "    Attributes:\n",
    "        protocol_id: Unique identifier for this protocol\n",
    "        title: Title or name of the protocol\n",
    "        study_design: Overall study design (e.g., RCT, cohort study)\n",
    "        variables: Variables included in the experiment\n",
    "        sample_size: Total sample size\n",
    "        sample_size_justification: Justification for the sample size\n",
    "        inclusion_criteria: Criteria for including subjects/samples\n",
    "        exclusion_criteria: Criteria for excluding subjects/samples\n",
    "        randomization: Randomization method\n",
    "        blinding: Blinding procedure\n",
    "        controls: Control conditions or groups\n",
    "        procedures: Ordered list of procedure steps\n",
    "        analysis_methods: Statistical/analytical methods\n",
    "        limitations: Known limitations of the protocol\n",
    "        source: Source of this protocol (extraction, optimization)\n",
    "        confidence_score: Overall confidence in protocol completeness (0-1)\n",
    "    \"\"\"\n",
    "    protocol_id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])\n",
    "    title: Optional[str] = None\n",
    "    study_design: str\n",
    "    variables: Dict[str, List[VariableDefinition]] = Field(default_factory=dict)\n",
    "    sample_size: Optional[int] = None\n",
    "    sample_size_justification: Optional[str] = None\n",
    "    inclusion_criteria: List[str] = Field(default_factory=list)\n",
    "    exclusion_criteria: List[str] = Field(default_factory=list)\n",
    "    randomization: Optional[str] = None\n",
    "    blinding: Optional[str] = None\n",
    "    controls: List[str] = Field(default_factory=list)\n",
    "    procedures: List[ProcedureStep] = Field(default_factory=list)\n",
    "    analysis_methods: List[AnalysisMethod] = Field(default_factory=list)\n",
    "    limitations: List[str] = Field(default_factory=list)\n",
    "    source: Literal[\"extracted\", \"optimized\", \"manual\"] = \"extracted\"\n",
    "    confidence_score: float = Field(default=0.7, ge=0.0, le=1.0)\n",
    "    \n",
    "    def add_variable(self, variable: VariableDefinition) -> None:\n",
    "        \"\"\"Add a variable to the protocol.\"\"\"\n",
    "        var_type = variable.var_type\n",
    "        if var_type not in self.variables:\n",
    "            self.variables[var_type] = []\n",
    "        self.variables[var_type].append(variable)\n",
    "    \n",
    "    def add_procedure_step(self, step: ProcedureStep) -> None:\n",
    "        \"\"\"Add a procedure step to the protocol.\"\"\"\n",
    "        self.procedures.append(step)\n",
    "        # Sort procedures by step number\n",
    "        self.procedures.sort(key=lambda x: x.step_number)\n",
    "    \n",
    "    def add_analysis_method(self, method: AnalysisMethod) -> None:\n",
    "        \"\"\"Add an analysis method to the protocol.\"\"\"\n",
    "        self.analysis_methods.append(method)\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"Generate a brief summary of the protocol.\"\"\"\n",
    "        summary = f\"Study design: {self.study_design}\\n\"\n",
    "        \n",
    "        if self.sample_size:\n",
    "            summary += f\"Sample size: {self.sample_size}\\n\"\n",
    "        \n",
    "        # Variables\n",
    "        var_counts = {k: len(v) for k, v in self.variables.items()}\n",
    "        if var_counts:\n",
    "            summary += \"Variables: \" + \", \".join([f\"{count} {var_type}\" for var_type, count in var_counts.items()]) + \"\\n\"\n",
    "        \n",
    "        # Procedures\n",
    "        if self.procedures:\n",
    "            summary += f\"Procedure steps: {len(self.procedures)}\\n\"\n",
    "        \n",
    "        # Analysis\n",
    "        if self.analysis_methods:\n",
    "            summary += f\"Analysis methods: {len(self.analysis_methods)}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def get_completeness_score(self) -> float:\n",
    "        \"\"\"Calculate a protocol completeness score based on required elements.\"\"\"\n",
    "        required_elements = [\n",
    "            bool(self.study_design),\n",
    "            bool(self.variables.get(\"independent\")),\n",
    "            bool(self.variables.get(\"dependent\")),\n",
    "            bool(self.sample_size),\n",
    "            bool(self.procedures),\n",
    "            bool(self.analysis_methods)\n",
    "        ]\n",
    "        \n",
    "        return sum(required_elements) / len(required_elements)\n",
    "\n",
    "class ProtocolImprovement(BaseModel):\n",
    "    \"\"\"Represents a specific improvement to an experimental protocol.\n",
    "    \n",
    "    This model captures a single improvement suggestion, including\n",
    "    the original element, the improved version, and justification.\n",
    "    \n",
    "    Attributes:\n",
    "        component: Protocol component being improved\n",
    "        original_text: Original protocol text/element\n",
    "        improved_text: Improved protocol text/element\n",
    "        justification: Justification for the improvement\n",
    "        evidence: Supporting evidence from literature\n",
    "        confidence: Confidence in this improvement (0-1)\n",
    "        source_url: URL to supporting literature if available\n",
    "        improvement_type: Category of improvement\n",
    "    \"\"\"\n",
    "    component: str\n",
    "    original_text: str\n",
    "    improved_text: str\n",
    "    justification: str\n",
    "    evidence: Optional[str] = None\n",
    "    confidence: float = Field(default=0.7, ge=0.0, le=1.0)\n",
    "    source_url: Optional[str] = None\n",
    "    improvement_type: Literal[\n",
    "        \"statistical_power\", \"bias_reduction\", \"reproducibility\", \n",
    "        \"reporting\", \"measurement\", \"analysis\", \"other\"\n",
    "    ] = \"other\"\n",
    "\n",
    "class ProtocolComparison(BaseModel):\n",
    "    \"\"\"Side-by-side comparison of original and optimized protocols.\n",
    "    \n",
    "    This model provides a structured comparison between the original\n",
    "    and optimized versions of an experimental protocol, with improvements.\n",
    "    \n",
    "    Attributes:\n",
    "        original_protocol: The original experimental protocol\n",
    "        optimized_protocol: The optimized experimental protocol\n",
    "        improvements: List of specific improvements made\n",
    "        overall_quality_score: Quality score of optimized protocol (0-1)\n",
    "        remaining_issues: Issues that could not be fully resolved\n",
    "    \"\"\"\n",
    "    original_protocol: ExperimentalProtocol\n",
    "    optimized_protocol: ExperimentalProtocol\n",
    "    improvements: List[ProtocolImprovement] = Field(default_factory=list)\n",
    "    overall_quality_score: float = Field(default=0.0, ge=0.0, le=1.0)\n",
    "    remaining_issues: List[str] = Field(default_factory=list)\n",
    "    \n",
    "    def add_improvement(self, improvement: ProtocolImprovement) -> None:\n",
    "        \"\"\"Add an improvement to the comparison.\"\"\"\n",
    "        self.improvements.append(improvement)\n",
    "    \n",
    "    def calculate_quality_improvement(self) -> float:\n",
    "        \"\"\"Calculate the improvement in quality score.\"\"\"\n",
    "        # Simple calculation based on completeness scores\n",
    "        original_score = self.original_protocol.get_completeness_score()\n",
    "        optimized_score = self.optimized_protocol.get_completeness_score()\n",
    "        \n",
    "        return optimized_score - original_score\n",
    "\n",
    "class OptimizedProtocolOutput(BaseModel):\n",
    "    \"\"\"Final output from the protocol optimization process.\n",
    "    \n",
    "    This model represents the complete results of protocol optimization,\n",
    "    including the improved protocol, justifications, and metadata.\n",
    "    \n",
    "    Attributes:\n",
    "        protocol_id: Unique identifier for this optimization\n",
    "        original_protocol: The original protocol that was optimized\n",
    "        optimized_protocol: The improved protocol\n",
    "        improvements: List of specific improvements made\n",
    "        literature_references: References to supporting literature\n",
    "        optimization_method: Method used for optimization\n",
    "        timestamp: When the optimization was performed\n",
    "        optimization_time: Time taken for optimization (seconds)\n",
    "        version: Version of the optimizer used\n",
    "    \"\"\"\n",
    "    protocol_id: str = Field(default_factory=lambda: str(uuid.uuid4())[:8])\n",
    "    original_protocol: ExperimentalProtocol\n",
    "    optimized_protocol: ExperimentalProtocol\n",
    "    improvements: List[ProtocolImprovement] = Field(default_factory=list)\n",
    "    literature_references: List[Dict[str, str]] = Field(default_factory=list)\n",
    "    optimization_method: str = \"agent-search\"\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "    optimization_time: float = 0.0\n",
    "    version: str = \"1.0\"\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"Generate a summary of the optimization results.\"\"\"\n",
    "        improvement_types = {}\n",
    "        for imp in self.improvements:\n",
    "            imp_type = imp.improvement_type\n",
    "            improvement_types[imp_type] = improvement_types.get(imp_type, 0) + 1\n",
    "        \n",
    "        summary = f\"Protocol Optimization Summary:\\n\"\n",
    "        summary += f\"- Original protocol: {self.original_protocol.title or 'Unnamed'}\\n\"\n",
    "        summary += f\"- Optimization time: {self.optimization_time:.1f} seconds\\n\"\n",
    "        summary += f\"- Total improvements: {len(self.improvements)}\\n\"\n",
    "        \n",
    "        if improvement_types:\n",
    "            summary += \"- Improvement types:\\n\"\n",
    "            for imp_type, count in improvement_types.items():\n",
    "                summary += f\"  • {imp_type.replace('_', ' ').title()}: {count}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def add_literature_reference(self, title: str, authors: str, url: Optional[str] = None, \n",
    "                               year: Optional[str] = None, journal: Optional[str] = None) -> None:\n",
    "        \"\"\"Add a literature reference supporting the optimization.\"\"\"\n",
    "        self.literature_references.append({\n",
    "            \"title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"url\": url,\n",
    "            \"year\": year,\n",
    "            \"journal\": journal\n",
    "        })\n",
    "\n",
    "\n",
    "# ===== CONFIGURATION MODEL =====\n",
    "# Controls system behavior and processing parameters\n",
    "\n",
    "class ExpArchConfig(BaseModel):\n",
    "    \"\"\"Configuration for the Experimental Architect system.\n",
    "    \n",
    "    This model controls how the system processes and analyzes documents.\n",
    "    Adjust these parameters to customize the analysis for your needs.\n",
    "    \n",
    "    Customization Tips:\n",
    "    - Adjust confidence thresholds based on LLM quality\n",
    "    - Set your scientific domain for more targeted analysis\n",
    "    - Configure tool search depth and timeout settings\n",
    "    - Change agent parameters for different reasoning patterns\n",
    "    \n",
    "    Attributes:\n",
    "        text_chunk_size: Characters per text chunk for processing\n",
    "        text_chunk_overlap: Overlap between chunks to maintain context\n",
    "        extraction_confidence: Minimum confidence for protocol extraction\n",
    "        scientific_domain: Optional domain specialization\n",
    "        agent_max_iterations: Maximum number of iterations for the agent\n",
    "        agent_temperature: Temperature setting for agent reasoning\n",
    "        search_results_count: Maximum number of search results to use\n",
    "        search_timeout: Timeout for search operations (seconds)\n",
    "        optimization_mode: Processing mode (quick, balanced, thorough)\n",
    "    \"\"\"\n",
    "    # Text Processing Parameters\n",
    "    text_chunk_size: int = Field(\n",
    "        default=2000, ge=500, le=8000, \n",
    "        description=\"Characters per text chunk\"\n",
    "    )\n",
    "    text_chunk_overlap: int = Field(\n",
    "        default=200, ge=50, le=1000,\n",
    "        description=\"Overlap between chunks\"\n",
    "    )\n",
    "    \n",
    "    # Extraction Parameters\n",
    "    extraction_confidence: float = Field(\n",
    "        default=0.7, ge=0.0, le=1.0,\n",
    "        description=\"Minimum extraction confidence\"\n",
    "    )\n",
    "    \n",
    "    # Agent Parameters\n",
    "    agent_max_iterations: int = Field(\n",
    "        default=10, ge=3, le=30,\n",
    "        description=\"Maximum agent iterations\"\n",
    "    )\n",
    "    agent_temperature: float = Field(\n",
    "        default=0.2, ge=0.0, le=1.0,\n",
    "        description=\"Temperature for agent reasoning\"\n",
    "    )\n",
    "    \n",
    "    # Search Parameters\n",
    "    search_results_count: int = Field(\n",
    "        default=3, ge=1, le=10,\n",
    "        description=\"Maximum search results to process\"\n",
    "    )\n",
    "    search_timeout: float = Field(\n",
    "        default=30.0, ge=5.0, le=120.0,\n",
    "        description=\"Search timeout in seconds\"\n",
    "    )\n",
    "    \n",
    "    # Customization\n",
    "    scientific_domain: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Scientific domain for specialized analysis\"\n",
    "    )\n",
    "    \n",
    "    # Processing Mode\n",
    "    optimization_mode: Literal[\"quick\", \"balanced\", \"thorough\"] = Field(\n",
    "        default=\"balanced\",\n",
    "        description=\"Processing depth and thoroughness\"\n",
    "    )\n",
    "    \n",
    "    @field_validator('text_chunk_overlap')\n",
    "    @classmethod\n",
    "    def validate_overlap(cls, v, info):\n",
    "        \"\"\"Ensure overlap is less than chunk size.\"\"\"\n",
    "        if 'text_chunk_size' in info.data and v >= info.data['text_chunk_size']:\n",
    "            raise ValueError(\"text_chunk_overlap must be less than text_chunk_size\")\n",
    "        return v\n",
    "    \n",
    "    def get_mode_settings(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get specific settings based on the selected mode.\"\"\"\n",
    "        mode_settings = {\n",
    "            \"quick\": {\n",
    "                \"search_results_count\": 2,\n",
    "                \"agent_max_iterations\": 5,\n",
    "                \"search_timeout\": 20.0,\n",
    "            },\n",
    "            \"balanced\": {\n",
    "                \"search_results_count\": 3,\n",
    "                \"agent_max_iterations\": 10,\n",
    "                \"search_timeout\": 30.0,\n",
    "            },\n",
    "            \"thorough\": {\n",
    "                \"search_results_count\": 5,\n",
    "                \"agent_max_iterations\": 15,\n",
    "                \"search_timeout\": 45.0,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return mode_settings.get(self.optimization_mode, mode_settings[\"balanced\"])\n",
    "    \n",
    "    def apply_mode_settings(self) -> None:\n",
    "        \"\"\"Apply settings based on the selected optimization mode.\"\"\"\n",
    "        settings = self.get_mode_settings()\n",
    "        for key, value in settings.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "\n",
    "# Initialize default configuration\n",
    "config = ExpArchConfig()\n",
    "\n",
    "# Forward references\n",
    "AgentState.model_rebuild()\n",
    "\n",
    "# Show configuration message\n",
    "show_info(\"Data models for Experimental Architect configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "\n",
    "<small>\n",
    "This section contains the heart of our Literature Synthesis system - the functions that analyze documents, extract key information, and generate insights.\n",
    "\n",
    "## What's Included\n",
    "\n",
    "1. **Prompt Library**: The instructions we give to the AI model\n",
    "2. **Function Definitions**: The code that processes documents and manages the analysis\n",
    "\n",
    "## How to Customize\n",
    "\n",
    "You can easily modify the system's behavior by:\n",
    "\n",
    "- **Changing prompts**: Edit the instructions to focus on specific types of information\n",
    "- **Adjusting parameters**: Fine-tune the analysis by modifying the `config` settings\n",
    "\n",
    "No coding knowledge is required - simply edit the text of prompts in the first code cell below.\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📖 Prompt Library\n",
    "\"\"\"\n",
    "This section contains all prompts used by the Experimental Architect system.\n",
    "Each prompt guides the AI to perform specific tasks in the protocol analysis workflow.\n",
    "You can customize these prompts to focus on particular aspects of experimental design.\n",
    "\n",
    "CUSTOMIZATION TIPS:\n",
    "1. Keep the output format instructions intact (especially for JSON responses)\n",
    "2. Add field-specific guidance for your research domain\n",
    "3. Emphasize particular aspects of protocol design important to your work\n",
    "4. Include examples from your discipline to improve extraction quality\n",
    "\"\"\"\n",
    "\n",
    "PROMPTS = {\n",
    "    # === PROTOCOL EXTRACTION ===\n",
    "    # Purpose: Extract structured experimental protocol from methods text\n",
    "    # Output: ExperimentalProtocol object\n",
    "    \"protocol_extraction\": \"\"\"\n",
    "    You are an experimental design specialist. Extract a structured experimental protocol \n",
    "    from the following methods section text.\n",
    "    \n",
    "    METHODS TEXT:\n",
    "    {text}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Identify the core experimental design (e.g., RCT, case-control, cohort study)\n",
    "    2. Extract all variables (independent, dependent, control, covariate)\n",
    "    3. Identify sample size and any randomization procedures\n",
    "    4. Extract procedures as sequential steps\n",
    "    5. Identify statistical analysis methods\n",
    "    6. Note any limitations or controls mentioned\n",
    "    \n",
    "    Return a structured protocol as JSON with this structure:\n",
    "    ```json\n",
    "    {{\n",
    "      \"protocol_id\": \"auto-generated\",\n",
    "      \"study_design\": \"Study design type (e.g., RCT, cohort study)\",\n",
    "      \"variables\": {{\n",
    "        \"independent\": [\n",
    "          {{\"name\": \"Variable name\", \"description\": \"Description\", \"measurement_method\": \"How measured\", \"levels\": [\"level1\", \"level2\"], \"var_type\": \"independent\"}}\n",
    "        ],\n",
    "        \"dependent\": [\n",
    "          {{\"name\": \"Variable name\", \"description\": \"Description\", \"measurement_method\": \"How measured\", \"units\": \"Units if applicable\", \"var_type\": \"dependent\"}}\n",
    "        ],\n",
    "        \"control\": [\n",
    "          {{\"name\": \"Variable name\", \"description\": \"Description\", \"measurement_method\": \"How measured\", \"var_type\": \"control\"}}\n",
    "        ],\n",
    "        \"covariate\": [\n",
    "          {{\"name\": \"Variable name\", \"description\": \"Description\", \"measurement_method\": \"How measured\", \"var_type\": \"covariate\"}}\n",
    "        ]\n",
    "      }},\n",
    "      \"sample_size\": 120,\n",
    "      \"sample_size_justification\": \"Justification if mentioned\",\n",
    "      \"inclusion_criteria\": [\"criterion 1\", \"criterion 2\"],\n",
    "      \"exclusion_criteria\": [\"criterion 1\", \"criterion 2\"],\n",
    "      \"randomization\": \"Randomization method if applicable\",\n",
    "      \"blinding\": \"Blinding procedure if applicable\",\n",
    "      \"controls\": [\"Control 1\", \"Control 2\"],\n",
    "      \"procedures\": [\n",
    "        {{\"step_number\": 1, \"description\": \"Step description\", \"duration\": \"Time if applicable\"}},\n",
    "        {{\"step_number\": 2, \"description\": \"Step description\", \"duration\": \"Time if applicable\"}}\n",
    "      ],\n",
    "      \"analysis_methods\": [\n",
    "        {{\"name\": \"Analysis method\", \"description\": \"Description\", \"software\": \"Software used\", \"parameters\": {{}}}}\n",
    "      ],\n",
    "      \"limitations\": [\"Limitation 1\", \"Limitation 2\"]\n",
    "    }}\n",
    "    ```\n",
    "    \n",
    "    Pay special attention to:\n",
    "    - IMPORTANT: Ensure all variables have the \"var_type\" field explicitly specified \n",
    "    - Statistical methods (power analysis, sample size calculation)\n",
    "    - Randomization and blinding procedures\n",
    "    - Control conditions and baseline measurements\n",
    "    - Subject selection criteria and recruitment\n",
    "    \n",
    "    If information is missing, omit those fields rather than guessing.\n",
    "    \"\"\",\n",
    "    \n",
    "    # === SEARCH AGENT PROMPT ===\n",
    "    # Purpose: Guide ReAct agent to search for protocol improvements\n",
    "    # Output: Agent reasoning and search results\n",
    "    \"search_agent\": \"\"\"\n",
    "    You are an experimental methodology expert helping to improve a scientific protocol.\n",
    "    Analyze this protocol and use the tools to find relevant methodological guidelines,\n",
    "    similar protocols, and best practices.\n",
    "    \n",
    "    PROTOCOL SUMMARY:\n",
    "    {protocol}\n",
    "    \n",
    "    STUDY DESIGN: {study_design}\n",
    "    \n",
    "    KEY VARIABLES: {variables}\n",
    "    \n",
    "    ANALYSIS METHODS: {analysis_methods}\n",
    "    \n",
    "    Your task is to search for:\n",
    "    1. Methodological standards for this type of study\n",
    "    2. Common pitfalls and how to avoid them\n",
    "    3. Statistical best practices for this design\n",
    "    4. Improvements to randomization, blinding, and controls\n",
    "    5. Validation techniques for measurements\n",
    "    \n",
    "    Use the tools to conduct targeted searches. Be specific in your search queries.\n",
    "    Focus on finding concrete, actionable improvements to the protocol.\n",
    "    \n",
    "    Available tools: {tool_names}\n",
    "    \n",
    "    {agent_scratchpad}\n",
    "    \"\"\",\n",
    "    \n",
    "    # === PROTOCOL WEAKNESSES ANALYSIS ===\n",
    "    # Purpose: Identify methodological weaknesses in the protocol\n",
    "    # Output: Structured list of weaknesses with improvement opportunities\n",
    "    \"protocol_weaknesses\": \"\"\"\n",
    "    You are a methodological reviewer for scientific protocols. Analyze this experimental\n",
    "    protocol and identify methodological weaknesses or opportunities for improvement.\n",
    "    \n",
    "    EXPERIMENTAL PROTOCOL:\n",
    "    {protocol}\n",
    "    \n",
    "    RELEVANT METHODOLOGICAL GUIDELINES:\n",
    "    {search_context}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Compare the protocol against best practices for {study_design} studies\n",
    "    2. Identify missing elements or unclear specifications\n",
    "    3. Evaluate statistical rigor and potential sources of bias\n",
    "    4. Assess controls, randomization, and blinding procedures\n",
    "    5. Consider reproducibility and reporting completeness\n",
    "    \n",
    "    Focus on these common areas for improvement:\n",
    "    - Sample size justification and power analysis\n",
    "    - Randomization and allocation procedures\n",
    "    - Blinding of participants, investigators, and analysts\n",
    "    - Selection of appropriate controls\n",
    "    - Validation of measurement methods\n",
    "    - Statistical analysis approach and assumptions\n",
    "    - Reporting standards and transparency\n",
    "    \n",
    "    Provide specific, actionable suggestions for each weakness identified.\n",
    "    \"\"\",\n",
    "    \n",
    "    # === PARSE WEAKNESSES ===\n",
    "    # Purpose: Parse weakness analysis into structured format\n",
    "    # Output: JSON list of weaknesses\n",
    "    \"parse_weaknesses\": \"\"\"\n",
    "    Convert the following protocol weakness analysis into a structured JSON format:\n",
    "    \n",
    "    {weaknesses_text}\n",
    "    \n",
    "    Return ONLY a JSON array with this structure:\n",
    "    ```json\n",
    "    [\n",
    "      {{\n",
    "        \"component\": \"Component name (e.g., 'Sample Size', 'Randomization', 'Statistical Analysis')\",\n",
    "        \"description\": \"Description of the weakness\",\n",
    "        \"impact\": \"Potential impact on results or validity\",\n",
    "        \"improvement_type\": \"One of: statistical_power, bias_reduction, reproducibility, reporting, measurement, analysis, other\",\n",
    "        \"suggestion\": \"Specific suggestion for improvement\"\n",
    "      }}\n",
    "    ]\n",
    "    ```\n",
    "    \n",
    "    Focus on extracting clear, specific weaknesses with actionable suggestions.\n",
    "    \"\"\",\n",
    "    \n",
    "    # === PROTOCOL OPTIMIZATION ===\n",
    "    # Purpose: Generate optimized protocol with improvements\n",
    "    # Output: OptimizedProtocolOutput object\n",
    "    \"protocol_optimization\": \"\"\"\n",
    "    You are an experimental design optimization expert. Create an improved version of this \n",
    "    protocol based on the identified weaknesses and methodological standards.\n",
    "    \n",
    "    ORIGINAL PROTOCOL:\n",
    "    {protocol}\n",
    "    \n",
    "    IDENTIFIED WEAKNESSES:\n",
    "    {weaknesses}\n",
    "    \n",
    "    METHODOLOGICAL GUIDELINES:\n",
    "    {search_context}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Create an optimized version of the original protocol\n",
    "    2. Make specific improvements to address each weakness\n",
    "    3. Provide clear justification for each improvement\n",
    "    4. Ensure all changes are evidence-based\n",
    "    5. Maintain the core research question and design approach\n",
    "    \n",
    "    Return a comprehensive optimization result in this JSON structure:\n",
    "    ```json\n",
    "    {{\n",
    "      \"original_protocol\": <keep unchanged from input>,\n",
    "      \"optimized_protocol\": {{\n",
    "        \"protocol_id\": \"opt-<original_id>\",\n",
    "        \"study_design\": \"Original or improved study design\",\n",
    "        \"variables\": {{\n",
    "          \"independent\": [],\n",
    "          \"dependent\": [],\n",
    "          \"control\": [],\n",
    "          \"covariate\": []\n",
    "        }},\n",
    "        \"sample_size\": 0,\n",
    "        \"sample_size_justification\": \"Improved justification\",\n",
    "        \"inclusion_criteria\": [],\n",
    "        \"exclusion_criteria\": [],\n",
    "        \"randomization\": \"Improved randomization method\",\n",
    "        \"blinding\": \"Improved blinding procedure\",\n",
    "        \"controls\": [],\n",
    "        \"procedures\": [],\n",
    "        \"analysis_methods\": [],\n",
    "        \"limitations\": [],\n",
    "        \"source\": \"optimized\",\n",
    "        \"confidence_score\": 0.9\n",
    "      }},\n",
    "      \"improvements\": [\n",
    "        {{\n",
    "          \"component\": \"Component name\",\n",
    "          \"original_text\": \"Original protocol element\",\n",
    "          \"improved_text\": \"Improved protocol element\",\n",
    "          \"justification\": \"Evidence-based justification for change\",\n",
    "          \"evidence\": \"Supporting evidence from literature\",\n",
    "          \"improvement_type\": \"One of: statistical_power, bias_reduction, reproducibility, reporting, measurement, analysis, other\"\n",
    "        }}\n",
    "      ],\n",
    "      \"literature_references\": [\n",
    "        {{\n",
    "          \"title\": \"Title of reference\",\n",
    "          \"authors\": \"Authors of reference\",\n",
    "          \"url\": \"URL if available\",\n",
    "          \"year\": \"Year if available\",\n",
    "          \"journal\": \"Journal if available\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "    ```\n",
    "    \n",
    "    For each improvement, provide a strong, evidence-based justification referring to methodological standards \n",
    "    or research best practices in {study_design} studies.\n",
    "    \"\"\",\n",
    "    \n",
    "    # === PROTOCOL VALIDATION ===\n",
    "    # Purpose: Validate optimized protocol against standards\n",
    "    # Output: Validation assessment\n",
    "    \"protocol_validation\": \"\"\"\n",
    "    You are a protocol validation expert. Assess the quality and completeness of this\n",
    "    optimized experimental protocol against methodological standards.\n",
    "    \n",
    "    OPTIMIZED PROTOCOL:\n",
    "    {protocol}\n",
    "    \n",
    "    KEY IMPROVEMENTS:\n",
    "    {improvements}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Evaluate adherence to reporting guidelines for {study_design} studies\n",
    "    2. Assess statistical rigor and appropriateness\n",
    "    3. Verify completeness of all required protocol elements\n",
    "    4. Check for remaining methodological issues\n",
    "    5. Identify areas still needing human expert review\n",
    "    \n",
    "    Your assessment should cover these validation domains:\n",
    "    - Design validity (internal and external)\n",
    "    - Statistical validity\n",
    "    - Measurement validity\n",
    "    - Procedural completeness\n",
    "    - Reproducibility\n",
    "    - Transparency and reporting\n",
    "    \n",
    "    Provide specific recommendations for any remaining issues.\n",
    "    \"\"\",\n",
    "    \n",
    "    # === PARSE VALIDATION ===\n",
    "    # Purpose: Parse validation text to structured format\n",
    "    # Output: JSON validation result\n",
    "    \"parse_validation\": \"\"\"\n",
    "    Convert the following protocol validation assessment into a structured JSON format:\n",
    "    \n",
    "    {validation_text}\n",
    "    \n",
    "    Return ONLY a JSON object with this structure:\n",
    "    ```json\n",
    "    {{\n",
    "      \"overall_score\": 0.85,\n",
    "      \"validation_domains\": [\n",
    "        {{\n",
    "          \"domain\": \"Domain name (e.g., 'Design Validity', 'Statistical Validity')\",\n",
    "          \"score\": 0.9,\n",
    "          \"strengths\": [\"Strength 1\", \"Strength 2\"],\n",
    "          \"weaknesses\": [\"Weakness 1\", \"Weakness 2\"]\n",
    "        }}\n",
    "      ],\n",
    "      \"remaining_issues\": [\n",
    "        {{\n",
    "          \"issue\": \"Description of remaining issue\",\n",
    "          \"severity\": \"high|medium|low\",\n",
    "          \"recommendation\": \"Recommendation to address\"\n",
    "        }}\n",
    "      ],\n",
    "      \"expert_review_needed\": [\"Area 1\", \"Area 2\"],\n",
    "      \"overall_assessment\": \"Overall textual assessment\"\n",
    "    }}\n",
    "    ```\n",
    "    \n",
    "    Ensure scores are between 0.0 and 1.0, with higher scores indicating better quality.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# You can customize these prompts to better suit your specific research domain\n",
    "# Add field-specific terminology, criteria, or examples to improve protocol extraction\n",
    "# For medical research, emphasize regulatory compliance and patient safety\n",
    "# For psychology studies, focus on ethical considerations and measurement validity\n",
    "# For biological research, emphasize replication and control conditions\n",
    "\n",
    "show(\"Prompt library initialized with 7 specialized prompts for experimental protocol optimization\", \"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Core Functions\n",
    "\"\"\"\n",
    "This section contains all the core functionality for the Experimental Architect system.\n",
    "Each function is designed to be modular, well-documented, and easy to customize.\n",
    "\"\"\"\n",
    "\n",
    "import json, re, os, time, hashlib, uuid\n",
    "from typing import List, Dict, Any, Optional, Tuple, Union, Callable\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.tools import DuckDuckGoSearchRun, ArxivQueryRun, Tool\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "# ===== DOCUMENT PROCESSING =====\n",
    "# These functions handle loading documents and text processing\n",
    "\n",
    "def load_document(source_type: str, content: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load document from various sources (text or PDF)\n",
    "    \n",
    "    Args:\n",
    "        source_type: Type of document (\"text\" or \"pdf\")\n",
    "        content: Document content or file path\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with extracted text and metadata\n",
    "    \"\"\"\n",
    "    if source_type == \"text\":\n",
    "        return {\"text\": content, \"metadata\": {\"source_type\": \"text\", \"length\": len(content)}}\n",
    "    elif source_type == \"pdf\":\n",
    "        try:\n",
    "            from pypdf import PdfReader\n",
    "            reader = PdfReader(content)\n",
    "            text = \"\\n\\n\".join(page.extract_text() for page in reader.pages)\n",
    "            return {\"text\": text, \"metadata\": {\"source_type\": \"pdf\", \"filename\": os.path.basename(content), \"pages\": len(reader.pages)}}\n",
    "        except Exception as e:\n",
    "            return {\"text\": \"\", \"metadata\": {\"error\": str(e)}}\n",
    "    else:\n",
    "        return {\"text\": \"\", \"metadata\": {\"error\": \"Unsupported source type\"}}\n",
    "\n",
    "def chunk_text(text: str, config: ExpArchConfig) -> List[str]:\n",
    "    \"\"\"Split text into semantically coherent chunks optimized for scientific papers\n",
    "    \n",
    "    Args:\n",
    "        text: The text to chunk\n",
    "        config: Configuration with chunk_size and overlap parameters\n",
    "        \n",
    "    Returns:\n",
    "        List of text chunks optimized for scientific content\n",
    "    \"\"\"\n",
    "    if not text: \n",
    "        return []\n",
    "    \n",
    "    # Safety bounds for config values\n",
    "    chunk_size = min(max(config.text_chunk_size, 1000), 4000)\n",
    "    overlap = min(config.text_chunk_overlap, chunk_size // 4)\n",
    "    \n",
    "    # Scientific paper section headers (common patterns in papers)\n",
    "    section_headers = [\n",
    "        r'\\n+\\s*ABSTRACT\\s*\\n+',\n",
    "        r'\\n+\\s*INTRODUCTION\\s*\\n+', \n",
    "        r'\\n+\\s*METHODS?\\s*\\n+',\n",
    "        r'\\n+\\s*RESULTS\\s*\\n+',\n",
    "        r'\\n+\\s*DISCUSSION\\s*\\n+',\n",
    "        r'\\n+\\s*CONCLUSION\\s*\\n+',\n",
    "        r'\\n+\\s*REFERENCES\\s*\\n+'\n",
    "    ]\n",
    "    \n",
    "    # First try to split by major sections\n",
    "    section_splits = [0]\n",
    "    for pattern in section_headers:\n",
    "        for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "            section_splits.append(match.start())\n",
    "    section_splits.append(len(text))\n",
    "    section_splits = sorted(set(section_splits))\n",
    "    \n",
    "    # Generate base chunks from sections\n",
    "    base_chunks = []\n",
    "    if len(section_splits) > 2:  # More than just start and end\n",
    "        for i in range(len(section_splits) - 1):\n",
    "            start, end = section_splits[i], section_splits[i+1]\n",
    "            if end - start > 100:  # Avoid tiny sections\n",
    "                base_chunks.append(text[start:end].strip())\n",
    "    else:\n",
    "        base_chunks = [text]  # No clear sections, use whole text\n",
    "    \n",
    "    # Further split any chunks that exceed the max size\n",
    "    final_chunks = []\n",
    "    for chunk in base_chunks:\n",
    "        if len(chunk) <= chunk_size:\n",
    "            final_chunks.append(chunk)\n",
    "        else:\n",
    "            # Split large chunks by paragraphs or sentences\n",
    "            start = 0\n",
    "            while start < len(chunk):\n",
    "                end = min(start + chunk_size, len(chunk))\n",
    "                \n",
    "                if end < len(chunk):\n",
    "                    # Try paragraph boundaries\n",
    "                    para_end = chunk.rfind(\"\\n\\n\", start + (chunk_size // 2), end)\n",
    "                    if para_end > start + 200:\n",
    "                        end = para_end + 2\n",
    "                    else:\n",
    "                        # Fall back to sentence boundaries\n",
    "                        for sep in [\". \", \".\\n\", \"? \", \"! \"]:\n",
    "                            sent_end = chunk.rfind(sep, start + (chunk_size // 2), end)\n",
    "                            if sent_end > start + 200:\n",
    "                                end = sent_end + len(sep)\n",
    "                                break\n",
    "                \n",
    "                final_chunks.append(chunk[start:end].strip())\n",
    "                start = max(end - overlap, start + (chunk_size // 2))\n",
    "    \n",
    "    return final_chunks\n",
    "\n",
    "# ===== TOOL IMPLEMENTATIONS =====\n",
    "# Tools for the ReAct agent to search and retrieve information\n",
    "\n",
    "def get_web_search_tool() -> Tool:\n",
    "    \"\"\"Create web search tool for finding methodological guidelines and best practices.\"\"\"\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    \n",
    "    def web_search(query: str) -> str:\n",
    "        \"\"\"Search the web for methodological guidelines and best practices.\n",
    "        \n",
    "        This tool searches the web for information about experimental design best practices,\n",
    "        methodological standards, and scientific guidelines.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query specifically about experimental methodology\n",
    "            \n",
    "        Returns:\n",
    "            Formatted search results with titles and snippets\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = search.run(f\"experimental methodology {query}\")\n",
    "            \n",
    "            # Format and truncate results\n",
    "            if len(results) > 1000:\n",
    "                results = results[:1000] + \"...[truncated for readability]\"\n",
    "                \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            return f\"Error performing web search: {str(e)}\"\n",
    "    \n",
    "    return Tool(\n",
    "        name=\"web_search\",\n",
    "        func=web_search,\n",
    "        description=\"Search the web for experimental methodology guidelines and best practices\"\n",
    "    )\n",
    "\n",
    "def get_arxiv_search_tool() -> Tool:\n",
    "    \"\"\"Create arXiv search tool for finding academic papers with similar protocols.\"\"\"\n",
    "    arxiv = ArxivQueryRun()\n",
    "    \n",
    "    def arxiv_search(query: str) -> str:\n",
    "        \"\"\"Search academic papers on arXiv for experimental protocols and methods.\n",
    "        \n",
    "        This tool searches academic literature for similar experimental protocols,\n",
    "        methodological approaches, and experimental designs.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query about experimental protocols or methods\n",
    "            \n",
    "        Returns:\n",
    "            Formatted search results with titles, authors, and abstracts\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Add methodology-specific terms to improve results\n",
    "            enhanced_query = f\"methodology experimental_design protocol {query}\"\n",
    "            results = arxiv.run(enhanced_query)\n",
    "            \n",
    "            # Format and truncate results\n",
    "            if len(results) > 1500:\n",
    "                results = results[:1500] + \"...[truncated for readability]\"\n",
    "                \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            return f\"Error searching arXiv: {str(e)}\"\n",
    "    \n",
    "    return Tool(\n",
    "        name=\"arxiv_search\",\n",
    "        func=arxiv_search,\n",
    "        description=\"Search academic papers on arXiv for similar experimental protocols and methods\"\n",
    "    )\n",
    "\n",
    "def process_search_result(tool_name: str, query: str, result: str) -> SearchResult:\n",
    "    \"\"\"Process and structure a search tool result.\n",
    "    \n",
    "    Args:\n",
    "        tool_name: Name of the tool used (\"web_search\" or \"arxiv_search\")\n",
    "        query: Original search query\n",
    "        result: Raw search result text\n",
    "        \n",
    "    Returns:\n",
    "        Structured SearchResult object\n",
    "    \"\"\"\n",
    "    source_type = \"arxiv\" if tool_name == \"arxiv_search\" else \"web\"\n",
    "    \n",
    "    # Extract title, URL, and other metadata using regex patterns\n",
    "    title = \"\"\n",
    "    url = \"\"\n",
    "    date = \"\"\n",
    "    authors = []\n",
    "    \n",
    "    if source_type == \"arxiv\":\n",
    "        # Extract arXiv paper details\n",
    "        title_match = re.search(r'Title:(.*?)(?:Authors:|$)', result, re.DOTALL)\n",
    "        if title_match:\n",
    "            title = title_match.group(1).strip()\n",
    "            \n",
    "        author_match = re.search(r'Authors:(.*?)(?:Submitted:|$)', result, re.DOTALL)\n",
    "        if author_match:\n",
    "            author_text = author_match.group(1).strip()\n",
    "            authors = [a.strip() for a in author_text.split(',')]\n",
    "            \n",
    "        url_match = re.search(r'https://arxiv.org/\\S+', result)\n",
    "        if url_match:\n",
    "            url = url_match.group(0)\n",
    "            \n",
    "    else:\n",
    "        # Extract web search details\n",
    "        # Handle typical DuckDuckGo format\n",
    "        title_match = re.search(r'^(.*?)\\n', result)\n",
    "        if title_match:\n",
    "            title = title_match.group(1).strip()\n",
    "            \n",
    "        url_match = re.search(r'https?://\\S+', result)\n",
    "        if url_match:\n",
    "            url = url_match.group(0)\n",
    "    \n",
    "    # Create SearchResult with extracted information\n",
    "    return SearchResult(\n",
    "        query=query,\n",
    "        source=source_type,\n",
    "        title=title or \"Untitled result\",\n",
    "        content=result,\n",
    "        url=url,\n",
    "        date=date,\n",
    "        authors=authors,\n",
    "        relevance_score=0.7,  # Default relevance score\n",
    "        keywords=[]  # Could be extracted with additional processing\n",
    "    )\n",
    "\n",
    "# ===== LLM INTEGRATION =====\n",
    "# These functions manage LLM interactions with enhanced robustness\n",
    "\n",
    "def create_chain(prompt_name: str, output_model: Optional[Any] = None) -> Any:\n",
    "    \"\"\"Create an LCEL chain for a specific LLM task\n",
    "    \n",
    "    Args:\n",
    "        prompt_name: Name of the prompt from PROMPTS dictionary\n",
    "        output_model: Optional Pydantic model for structured output\n",
    "        \n",
    "    Returns:\n",
    "        LCEL chain configured for the specified task\n",
    "    \"\"\"\n",
    "    # Guard against missing prompts\n",
    "    if prompt_name not in PROMPTS:\n",
    "        show(f\"Prompt '{prompt_name}' not found in prompt library\", \"error\")\n",
    "        return None\n",
    "        \n",
    "    template = ChatPromptTemplate.from_template(PROMPTS[prompt_name])\n",
    "    \n",
    "    def parse_output(response):\n",
    "        \"\"\"Parse LLM response with multi-strategy approach\"\"\"\n",
    "        content = response.content if hasattr(response, 'content') else response\n",
    "        \n",
    "        # For text output (no model), return directly\n",
    "        if not output_model:\n",
    "            return content\n",
    "        \n",
    "        # For structured output, try multiple parsing strategies:\n",
    "        \n",
    "        # 1. Code block extraction\n",
    "        if isinstance(content, str) and \"```\" in content:\n",
    "            try:\n",
    "                # Handle ```json blocks\n",
    "                if \"```json\" in content:\n",
    "                    json_block = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "                    data = json.loads(json_block)\n",
    "                    # Handle both single object and list of objects\n",
    "                    if isinstance(data, list):\n",
    "                        return output_model(**data[0]) if len(data) == 1 else output_model(**data)\n",
    "                    else:\n",
    "                        return output_model(**data)\n",
    "                # Handle any other code blocks\n",
    "                else:\n",
    "                    code_block = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "                    if code_block.strip():\n",
    "                        try:\n",
    "                            data = json.loads(code_block)\n",
    "                            if isinstance(data, list):\n",
    "                                return output_model(**data[0]) if len(data) == 1 else output_model(**data)\n",
    "                            else:\n",
    "                                return output_model(**data)\n",
    "                        except:\n",
    "                            pass\n",
    "            except Exception as e:\n",
    "                show(f\"Code block parsing error: {str(e)}\", \"debug\")\n",
    "        \n",
    "        # 2. Direct JSON parsing\n",
    "        try:\n",
    "            data = json.loads(content if isinstance(content, str) else content.content)\n",
    "            if isinstance(data, list):\n",
    "                return output_model(**data[0]) if len(data) == 1 else output_model(**data)\n",
    "            else:\n",
    "                return output_model(**data)\n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "        # 3. Fallback regex extraction\n",
    "        try:\n",
    "            json_pattern = r'(\\{.*?\\})'\n",
    "            matches = re.findall(json_pattern, content, re.DOTALL)\n",
    "            if matches:\n",
    "                data = json.loads(max(matches, key=len))  # Use the longest match\n",
    "                return output_model(**data)\n",
    "        except Exception as e:\n",
    "            show(f\"All parsing methods failed: {str(e)}\", \"debug\")\n",
    "        \n",
    "        # Fallback: try to create an empty model instance with error info\n",
    "        try:\n",
    "            return output_model(error=f\"Failed to parse response: {content[:100]}...\")\n",
    "        except:\n",
    "            show(\"Could not create fallback model\", \"warning\")\n",
    "            return None\n",
    "    \n",
    "    # Create and return the chain\n",
    "    if \"llm\" in globals():\n",
    "        return template | llm | RunnableLambda(parse_output)\n",
    "    else:\n",
    "        show(\"Warning: No LLM configured. Using placeholder output.\", \"warning\")\n",
    "        return RunnableLambda(lambda _: \"LLM missing: output unavailable\")\n",
    "\n",
    "def cached_run(chain, inputs: Dict, key_prefix: str = \"\") -> Any:\n",
    "    \"\"\"Run chain with caching to minimize API calls\n",
    "    \n",
    "    Args:\n",
    "        chain: LCEL chain to run\n",
    "        inputs: Input parameters \n",
    "        key_prefix: Cache key prefix for identification\n",
    "        \n",
    "    Returns:\n",
    "        Chain output (cached or fresh)\n",
    "    \"\"\"\n",
    "    if not chain: \n",
    "        return None\n",
    "    \n",
    "    # Use the caching functions from Core Utilities\n",
    "    if 'CACHE_ENABLED' in globals() and CACHE_ENABLED:\n",
    "        # Prepare inputs for caching - limit text size for reasonable cache keys\n",
    "        cache_inputs = {}\n",
    "        for k, v in inputs.items():\n",
    "            if k == 'text' and isinstance(v, str) and len(v) > 500:\n",
    "                cache_inputs[k] = v[:500]  # Use first 500 chars of text for cache key\n",
    "            else:\n",
    "                cache_inputs[k] = v\n",
    "                \n",
    "        # Add prefix and timestamp to differentiate between similar calls\n",
    "        cache_inputs['_function'] = key_prefix\n",
    "        \n",
    "        # Try to get cached result\n",
    "        try:\n",
    "            key = cache_key(**cache_inputs)\n",
    "            cached_result = get_cache(key)\n",
    "            \n",
    "            if cached_result is not None:\n",
    "                show(f\"Using cached result for {key_prefix}\", \"debug\")\n",
    "                return cached_result\n",
    "        except Exception as e:\n",
    "            show(f\"Cache access error: {str(e)}\", \"debug\")\n",
    "    \n",
    "    # Run chain if not in cache or caching disabled\n",
    "    try:\n",
    "        result = chain.invoke(inputs)\n",
    "        \n",
    "        # Try to cache the result\n",
    "        if 'CACHE_ENABLED' in globals() and CACHE_ENABLED:\n",
    "            try:\n",
    "                set_cache(key, result)\n",
    "            except Exception as e:\n",
    "                show(f\"Cache storage error: {str(e)}\", \"debug\")\n",
    "                \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        show(f\"Error in {key_prefix}: {error_msg}\", \"error\")\n",
    "        return None\n",
    "\n",
    "# ===== AGENT IMPLEMENTATION =====\n",
    "# Create and manage the ReAct agent for protocol optimization\n",
    "\n",
    "def create_search_agent(config: ExpArchConfig = None) -> AgentExecutor:\n",
    "    \"\"\"Create a ReAct agent for searching and analyzing protocols.\"\"\"\n",
    "    config = config or ExpArchConfig()\n",
    "    \n",
    "    # Initialize tools\n",
    "    tools = [\n",
    "        get_web_search_tool(),\n",
    "        get_arxiv_search_tool()\n",
    "    ]\n",
    "    \n",
    "    # Extract tool names for the prompt\n",
    "    tool_names = \", \".join([tool.name for tool in tools])\n",
    "    \n",
    "    # Create the partial prompt with tool names already included\n",
    "    agent_prompt = ChatPromptTemplate.from_template(PROMPTS[\"search_agent\"])\n",
    "    \n",
    "    # Ensure we have LLM initialized\n",
    "    if \"llm\" not in globals() or not llm:\n",
    "        show(\"LLM not initialized, agent creation failed\", \"error\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Create the agent with tool names already in the prompt\n",
    "        agent = create_react_agent(\n",
    "            llm=llm,\n",
    "            tools=tools,\n",
    "            prompt=agent_prompt\n",
    "        )\n",
    "        \n",
    "        # Store the tool_names in the agent's metadata for later use\n",
    "        agent._tool_names = tool_names\n",
    "        \n",
    "        # Configure the agent executor\n",
    "        return AgentExecutor(\n",
    "            agent=agent,\n",
    "            tools=tools,\n",
    "            verbose=False,\n",
    "            handle_parsing_errors=True,\n",
    "            max_iterations=config.agent_max_iterations,\n",
    "            max_execution_time=config.search_timeout\n",
    "        )\n",
    "    except Exception as e:\n",
    "        show(f\"Agent creation failed: {str(e)}\", \"error\")\n",
    "        return None\n",
    "\n",
    "def run_agent_with_state(agent_executor: AgentExecutor, \n",
    "                        prompt_inputs: Dict[str, Any], \n",
    "                        agent_state: AgentState) -> Tuple[Any, AgentState]:\n",
    "    \"\"\"Run ReAct agent while tracking state for visualization.\n",
    "    \n",
    "    Args:\n",
    "        agent_executor: The configured agent executor\n",
    "        prompt_inputs: Inputs for the agent prompt\n",
    "        agent_state: Current agent state to update\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (result, updated_agent_state)\n",
    "    \"\"\"\n",
    "    if not agent_executor:\n",
    "        agent_state.add_thought(\"Agent not properly initialized\")\n",
    "        return None, agent_state\n",
    "    \n",
    "    # Create callback handler for state tracking\n",
    "    class StateTrackingCallbackHandler:\n",
    "        def __init__(self, state: AgentState):\n",
    "            self.state = state\n",
    "            self.current_step = None\n",
    "            \n",
    "        def on_llm_start(self, *args, **kwargs):\n",
    "            pass\n",
    "            \n",
    "        def on_llm_end(self, response, *args, **kwargs):\n",
    "            # Extract thought from response\n",
    "            thought = response.generations[0][0].text\n",
    "            self.state.add_thought(thought)\n",
    "            \n",
    "        def on_tool_start(self, serialized, input_str, **kwargs):\n",
    "            # Track tool usage\n",
    "            tool_name = serialized[\"name\"]\n",
    "            self.state.add_action(tool_name, input_str)\n",
    "            self.current_step = {\"tool\": tool_name, \"input\": input_str}\n",
    "            \n",
    "        def on_tool_end(self, output, **kwargs):\n",
    "            # Process tool output\n",
    "            if self.current_step:\n",
    "                tool_name = self.current_step[\"tool\"]\n",
    "                query = self.current_step[\"input\"]\n",
    "                self.state.add_observation(output)\n",
    "                \n",
    "                # Process search result if from search tools\n",
    "                if tool_name in [\"web_search\", \"arxiv_search\"]:\n",
    "                    result = process_search_result(tool_name, query, output)\n",
    "                    self.state.add_search_result(result)\n",
    "                \n",
    "                self.current_step = None\n",
    "    \n",
    "    # Create callback handler\n",
    "    callbacks = [StateTrackingCallbackHandler(agent_state)]\n",
    "    \n",
    "    try:\n",
    "        # Execute agent\n",
    "        start_time = time.time()\n",
    "        result = agent_executor.invoke(prompt_inputs, callbacks=callbacks)\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        # Update agent state with result\n",
    "        output = result.get(\"output\", \"No output generated\")\n",
    "        agent_state.add_final_answer(output)\n",
    "        \n",
    "        # Add execution metadata\n",
    "        agent_state.add_detail(\"execution_time\", execution_time)\n",
    "        \n",
    "        return result, agent_state\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Agent execution failed: {str(e)}\"\n",
    "        agent_state.add_thought(error_msg)\n",
    "        show(error_msg, \"error\")\n",
    "        return None, agent_state\n",
    "\n",
    "# ===== CORE PROTOCOL FUNCTIONS =====\n",
    "# These functions implement the main protocol processing capabilities\n",
    "\n",
    "def extract_protocol_chain(methods_text: str, config: ExpArchConfig = None) -> ExperimentalProtocol:\n",
    "    \"\"\"Extract experimental protocol from methods section text.\n",
    "    \n",
    "    Args:\n",
    "        methods_text: Methods section text to analyze\n",
    "        config: Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        Extracted ExperimentalProtocol with variables, steps, and analysis methods\n",
    "    \"\"\"\n",
    "    if not methods_text or len(methods_text.strip()) < 50:\n",
    "        show(\"Methods text too short for protocol extraction\", \"warning\")\n",
    "        return None\n",
    "    \n",
    "    config = config or ExpArchConfig()\n",
    "    show(f\"Extracting protocol from methods text ({len(methods_text)} chars)...\", \"info\")\n",
    "    \n",
    "    try:\n",
    "        # Create and run extraction chain\n",
    "        chain = create_chain(\"protocol_extraction\", ExperimentalProtocol)\n",
    "        protocol = cached_run(chain, {\n",
    "            \"text\": methods_text, \n",
    "            \"config\": config.model_dump()\n",
    "        }, \"protocol_extraction\")\n",
    "        \n",
    "        if not protocol:\n",
    "            show(\"Protocol extraction failed\", \"warning\")\n",
    "            return None\n",
    "        \n",
    "        # Validate extracted protocol\n",
    "        completeness = protocol.get_completeness_score()\n",
    "        protocol.confidence_score = completeness\n",
    "        \n",
    "        show(f\"Extracted protocol with {completeness:.1%} completeness score\", \n",
    "            \"success\" if completeness > 0.6 else \"warning\")\n",
    "        \n",
    "        return protocol\n",
    "        \n",
    "    except Exception as e:\n",
    "        show(f\"Error in protocol extraction: {str(e)}\", \"error\")\n",
    "        return None\n",
    "\n",
    "def search_related_protocols_agent(protocol: ExperimentalProtocol, \n",
    "                                 agent_state: AgentState,\n",
    "                                 config: ExpArchConfig = None) -> Tuple[Dict[str, Any], AgentState]:\n",
    "    \"\"\"Search for related protocols and methodological guidelines.\"\"\"\n",
    "    if not protocol:\n",
    "        show(\"No protocol provided for search\", \"warning\")\n",
    "        return {}, agent_state\n",
    "    \n",
    "    config = config or ExpArchConfig()\n",
    "    \n",
    "    # Create protocol summary for agent\n",
    "    protocol_summary = protocol.get_summary()\n",
    "    \n",
    "    # Create agent\n",
    "    agent_executor = create_search_agent(config)\n",
    "    \n",
    "    if not agent_executor:\n",
    "        agent_state.add_thought(\"Failed to create search agent\")\n",
    "        return {}, agent_state\n",
    "    \n",
    "    # Get tool names from the agent if available\n",
    "    tool_names = getattr(agent_executor.agent, \"_tool_names\", \"web_search, arxiv_search\")\n",
    "    \n",
    "    # Create prompt inputs with tool_names included\n",
    "    prompt_inputs = {\n",
    "        \"protocol\": protocol_summary,\n",
    "        \"study_design\": protocol.study_design,\n",
    "        \"variables\": \", \".join([v.name for vlist in protocol.variables.values() for v in vlist][:5]),\n",
    "        \"analysis_methods\": \", \".join([m.name for m in protocol.analysis_methods][:3]),\n",
    "        \"tool_names\": tool_names,  # Add tool names to inputs\n",
    "        \"agent_scratchpad\": \"\"  # Initialize empty scratchpad\n",
    "    }\n",
    "    \n",
    "    show(\"Searching for related protocols and methodological guidelines...\", \"info\")\n",
    "    \n",
    "    # Run agent with state tracking\n",
    "    result, updated_state = run_agent_with_state(agent_executor, prompt_inputs, agent_state)\n",
    "    \n",
    "    if not result:\n",
    "        show(\"Protocol search failed\", \"warning\")\n",
    "        return {}, updated_state\n",
    "    \n",
    "    show(f\"Search complete: found {len(updated_state.search_results)} relevant sources\", \"success\")\n",
    "    \n",
    "    return result, updated_state\n",
    "\n",
    "def analyze_protocol_weaknesses_chain(protocol: ExperimentalProtocol, \n",
    "                                     search_results: List[SearchResult],\n",
    "                                     config: ExpArchConfig = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Analyze protocol weaknesses based on methodological standards.\"\"\"\n",
    "    if not protocol:\n",
    "        show(\"No protocol provided for weakness analysis\", \"warning\")\n",
    "        return []\n",
    "    \n",
    "    config = config or ExpArchConfig()\n",
    "    \n",
    "    # Format protocol for prompt\n",
    "    protocol_json = protocol.model_dump_json()\n",
    "    \n",
    "    # Format search results for prompt - provide fallback for empty results\n",
    "    search_context = \"\"\n",
    "    if search_results:\n",
    "        for i, result in enumerate(search_results[:5], 1):\n",
    "            search_context += f\"{i}. {result.title} (from {result.source}):\\n\"\n",
    "            search_context += f\"{result.truncated_content(300)}\\n\\n\"\n",
    "    else:\n",
    "        search_context = \"No search results available. Analyzing protocol based on general methodological standards.\"\n",
    "    \n",
    "    # Create and run weakness analysis chain\n",
    "    chain = create_chain(\"protocol_weaknesses\", None)  # Returns text\n",
    "    weaknesses_text = cached_run(chain, {\n",
    "        \"protocol\": protocol_json,\n",
    "        \"search_context\": search_context,\n",
    "        \"study_design\": protocol.study_design\n",
    "    }, \"protocol_weaknesses\")\n",
    "    \n",
    "    if not weaknesses_text:\n",
    "        show(\"Protocol weakness analysis failed, using fallback analysis\", \"warning\")\n",
    "        # Provide fallback basic weaknesses for common issues\n",
    "        return [{\n",
    "            \"component\": \"General Methodology\",\n",
    "            \"description\": \"Unable to perform detailed analysis due to missing search context\",\n",
    "            \"impact\": \"Reduced ability to identify specific methodological improvements\",\n",
    "            \"improvement_type\": \"other\",\n",
    "            \"suggestion\": \"Consider reviewing protocol with domain experts\"\n",
    "        }]\n",
    "    \n",
    "    # Parse weaknesses text into structured format using LLM\n",
    "    parse_chain = create_chain(\"parse_weaknesses\", None)  # Returns JSON\n",
    "    weaknesses_json = cached_run(parse_chain, {\n",
    "        \"weaknesses_text\": weaknesses_text\n",
    "    }, \"parse_weaknesses\")\n",
    "    \n",
    "    try:\n",
    "        # Parse JSON string to Python object if needed\n",
    "        if isinstance(weaknesses_json, str):\n",
    "            weaknesses = json.loads(weaknesses_json)\n",
    "        else:\n",
    "            weaknesses = weaknesses_json\n",
    "            \n",
    "        if not isinstance(weaknesses, list):\n",
    "            weaknesses = [weaknesses]\n",
    "            \n",
    "        show(f\"Identified {len(weaknesses)} protocol weaknesses\", \"info\")\n",
    "        return weaknesses\n",
    "    except Exception as e:\n",
    "        show(f\"Error parsing weaknesses: {str(e)}. Using fallback analysis.\", \"error\")\n",
    "        # Provide fallback if JSON parsing fails\n",
    "        return [{\n",
    "            \"component\": \"JSON Parsing\",\n",
    "            \"description\": f\"Error parsing weakness analysis: {str(e)}\",\n",
    "            \"impact\": \"Unable to properly structure identified weaknesses\",\n",
    "            \"improvement_type\": \"other\",\n",
    "            \"suggestion\": \"Review raw weakness analysis and manually extract key points\"\n",
    "        }]\n",
    "\n",
    "def generate_optimized_protocol_chain(original_protocol: ExperimentalProtocol,\n",
    "                                    weaknesses: List[Dict[str, Any]],\n",
    "                                    search_results: List[SearchResult],\n",
    "                                    config: ExpArchConfig = None) -> OptimizedProtocolOutput:\n",
    "    \"\"\"Generate optimized protocol with improvements.\n",
    "    \n",
    "    Args:\n",
    "        original_protocol: Original experimental protocol\n",
    "        weaknesses: Identified weaknesses\n",
    "        search_results: Search results for methodological standards\n",
    "        config: Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        OptimizedProtocolOutput with improvements and justifications\n",
    "    \"\"\"\n",
    "    if not original_protocol:\n",
    "        show(\"No protocol provided for optimization\", \"warning\")\n",
    "        return None\n",
    "    \n",
    "    config = config or ExpArchConfig()\n",
    "    \n",
    "    # Format inputs for prompt\n",
    "    protocol_json = original_protocol.model_dump_json()\n",
    "    \n",
    "    weaknesses_text = \"\"\n",
    "    for i, weakness in enumerate(weaknesses[:5], 1):\n",
    "        weaknesses_text += f\"{i}. {weakness.get('component', 'Unknown component')}: \"\n",
    "        weaknesses_text += f\"{weakness.get('description', 'No description')}\\n\"\n",
    "    \n",
    "    # Format search results\n",
    "    search_context = \"\"\n",
    "    for i, result in enumerate(search_results[:5], 1):\n",
    "        search_context += f\"{i}. {result.title} (from {result.source}):\\n\"\n",
    "        search_context += f\"{result.truncated_content(300)}\\n\\n\"\n",
    "    \n",
    "    # Create and run optimization chain\n",
    "    chain = create_chain(\"protocol_optimization\", OptimizedProtocolOutput)\n",
    "    \n",
    "    show(\"Generating optimized protocol...\", \"info\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    optimized_result = cached_run(chain, {\n",
    "        \"protocol\": protocol_json,\n",
    "        \"weaknesses\": weaknesses_text,\n",
    "        \"search_context\": search_context,\n",
    "        \"study_design\": original_protocol.study_design\n",
    "    }, \"protocol_optimization\")\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    if not optimized_result:\n",
    "        show(\"Protocol optimization failed\", \"warning\")\n",
    "        return None\n",
    "    \n",
    "    # Set execution timing\n",
    "    if hasattr(optimized_result, 'optimization_time'):\n",
    "        optimized_result.optimization_time = execution_time\n",
    "    \n",
    "    # Make sure original protocol is correctly linked\n",
    "    if hasattr(optimized_result, 'original_protocol') and not optimized_result.original_protocol:\n",
    "        optimized_result.original_protocol = original_protocol\n",
    "    \n",
    "    show(f\"Protocol optimization complete with {len(optimized_result.improvements)} improvements\", \n",
    "         \"success\")\n",
    "    \n",
    "    return optimized_result\n",
    "\n",
    "def validation_summary_chain(optimized_output: OptimizedProtocolOutput,\n",
    "                          config: ExpArchConfig = None) -> Dict[str, Any]:\n",
    "    \"\"\"Generate validation summary for the optimized protocol.\n",
    "    \n",
    "    Args:\n",
    "        optimized_output: The optimized protocol output\n",
    "        config: Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        Validation summary with scores and recommendations\n",
    "    \"\"\"\n",
    "    if not optimized_output or not hasattr(optimized_output, 'optimized_protocol'):\n",
    "        show(\"No optimized protocol provided for validation\", \"warning\")\n",
    "        return {\"error\": \"Missing optimized protocol\"}\n",
    "    \n",
    "    config = config or ExpArchConfig()\n",
    "    \n",
    "    # Format optimized protocol for prompt\n",
    "    protocol_json = optimized_output.optimized_protocol.model_dump_json()\n",
    "    \n",
    "    # Format improvements\n",
    "    improvements_text = \"\"\n",
    "    for i, imp in enumerate(optimized_output.improvements[:5], 1):\n",
    "        improvements_text += f\"{i}. {imp.component}: {imp.justification[:100]}...\\n\"\n",
    "    \n",
    "    # Create and run validation chain\n",
    "    chain = create_chain(\"protocol_validation\", None)  # Returns text\n",
    "    \n",
    "    validation_text = cached_run(chain, {\n",
    "        \"protocol\": protocol_json,\n",
    "        \"improvements\": improvements_text,\n",
    "        \"study_design\": optimized_output.optimized_protocol.study_design\n",
    "    }, \"protocol_validation\")\n",
    "    \n",
    "    if not validation_text:\n",
    "        show(\"Protocol validation failed\", \"warning\")\n",
    "        return {\"error\": \"Validation failed\"}\n",
    "    \n",
    "    # Parse validation text to structured format\n",
    "    try:\n",
    "        validation_chain = create_chain(\"parse_validation\", None)  # Returns JSON\n",
    "        validation_json = cached_run(validation_chain, {\n",
    "            \"validation_text\": validation_text\n",
    "        }, \"parse_validation\")\n",
    "        \n",
    "        # Parse JSON if needed\n",
    "        if isinstance(validation_json, str):\n",
    "            validation = json.loads(validation_json)\n",
    "        else:\n",
    "            validation = validation_json\n",
    "            \n",
    "        show(\"Protocol validation complete\", \"success\")\n",
    "        return validation\n",
    "    except Exception as e:\n",
    "        show(f\"Error parsing validation: {str(e)}\", \"error\")\n",
    "        return {\"error\": str(e), \"raw_validation\": validation_text}\n",
    "\n",
    "# ===== ORCHESTRATION FUNCTION =====\n",
    "# Coordinates the entire workflow\n",
    "\n",
    "def experimental_design_orchestrator(methods_text: str, \n",
    "                                  config: ExpArchConfig = None) -> Tuple[OptimizedProtocolOutput, AgentState]:\n",
    "    \"\"\"End-to-end orchestration of experimental protocol optimization.\n",
    "    \n",
    "    Args:\n",
    "        methods_text: Methods section text to analyze\n",
    "        config: Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (optimized_protocol_output, agent_state)\n",
    "    \"\"\"\n",
    "    config = config or ExpArchConfig()\n",
    "    \n",
    "    # Apply settings based on optimization mode\n",
    "    config.apply_mode_settings()\n",
    "    \n",
    "    # Initialize agent state\n",
    "    agent_state = AgentState()\n",
    "    \n",
    "    show(f\"Starting experimental design optimization in {config.optimization_mode} mode...\", \"info\")\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    # Step 1: Extract protocol\n",
    "    show(\"Step 1/5: Extracting experimental protocol...\", \"info\")\n",
    "    protocol = extract_protocol_chain(methods_text, config)\n",
    "    \n",
    "    if not protocol:\n",
    "        show(\"Protocol extraction failed, aborting optimization\", \"error\")\n",
    "        agent_state.add_thought(\"Protocol extraction failed\")\n",
    "        return None, agent_state\n",
    "    \n",
    "    agent_state.extracted_protocol = protocol\n",
    "    \n",
    "    # Step 2: Search for related protocols and guidelines\n",
    "    show(\"Step 2/5: Searching for related protocols and guidelines...\", \"info\")\n",
    "    search_result, agent_state = search_related_protocols_agent(protocol, agent_state, config)\n",
    "    \n",
    "    if not search_result:\n",
    "        show(\"Protocol search completed with no results, continuing with limited context\", \"warning\")\n",
    "    \n",
    "    # Step 3: Analyze protocol weaknesses\n",
    "    show(\"Step 3/5: Analyzing protocol weaknesses...\", \"info\")\n",
    "    weaknesses = analyze_protocol_weaknesses_chain(protocol, agent_state.search_results, config)\n",
    "    \n",
    "    if not weaknesses:\n",
    "        show(\"Protocol weakness analysis failed, continuing with limited improvements\", \"warning\")\n",
    "        weaknesses = []  # Use empty list to continue\n",
    "    \n",
    "    # Step 4: Generate optimized protocol\n",
    "    show(\"Step 4/5: Generating optimized protocol...\", \"info\")\n",
    "    optimized_output = generate_optimized_protocol_chain(protocol, weaknesses, \n",
    "                                                       agent_state.search_results, config)\n",
    "    \n",
    "    if not optimized_output:\n",
    "        show(\"Protocol optimization failed, aborting\", \"error\")\n",
    "        return None, agent_state\n",
    "    \n",
    "    agent_state.optimized_protocol = optimized_output\n",
    "    \n",
    "    # Step 5: Validate optimized protocol\n",
    "    show(\"Step 5/5: Validating optimized protocol...\", \"info\")\n",
    "    validation = validation_summary_chain(optimized_output, config)\n",
    "    \n",
    "    if validation and \"error\" not in validation:\n",
    "        # Add validation results to output\n",
    "        optimized_output.validation = validation\n",
    "    \n",
    "    overall_execution_time = time.time() - overall_start_time\n",
    "    show(f\"Optimization complete in {overall_execution_time:.1f} seconds\", \"success\")\n",
    "    \n",
    "    return optimized_output, agent_state\n",
    "\n",
    "# Initialization complete\n",
    "show(\"Core functions initialized - ready for protocol optimization\", \"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Initialization\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # Initialize the Literature Synthesis System\n",
    "    class LitSynthSystem:\n",
    "        \"\"\"Main system class that coordinates all components of the Literature Synthesis system.\"\"\"\n",
    "        \n",
    "        def __init__(self, config=None):\n",
    "            \"\"\"Initialize the system with configuration and components.\"\"\"\n",
    "            # Use existing config or create new one\n",
    "            self.config = config or globals().get('config', LitSynthConfig())\n",
    "            \n",
    "            # No cache setup needed - already handled in Core Utilities\n",
    "        \n",
    "        def analyze_document(self, source_type, content):\n",
    "            \"\"\"Main entry point to analyze a document.\"\"\"\n",
    "            return analyze_document(source_type, content, self.config)\n",
    "        \n",
    "        def extract_concepts_from_text(self, text):\n",
    "            \"\"\"Extract concepts from text directly.\"\"\"\n",
    "            return extract_concepts(text, self.config)\n",
    "        \n",
    "        def identify_relationships_from_concepts(self, text, concepts):\n",
    "            \"\"\"Identify relationships between concepts.\"\"\"\n",
    "            return identify_relationships(text, concepts, self.config)\n",
    "        \n",
    "        def identify_gaps_from_concepts_relationships(self, text, concepts, relationships):\n",
    "            \"\"\"Identify research gaps from concepts and relationships.\"\"\"\n",
    "            return identify_research_gaps(text, concepts, relationships)\n",
    "        \n",
    "        def generate_synthesis_from_components(self, text, concepts, relationships, gaps):\n",
    "            \"\"\"Generate synthesis from all components.\"\"\"\n",
    "            return generate_synthesis(text, concepts, relationships, gaps)\n",
    "\n",
    "    # Initialize the system (connects previously defined components)\n",
    "    litsynth = LitSynthSystem()\n",
    "    \n",
    "    # Confirm successful initialization - using show_info correctly\n",
    "    show_info(\"Literature Synthesis System initialized successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # Use show from Core Utilities for error (with level parameter)\n",
    "    error_msg = f\"System failed to initialize: {str(e)}\"\n",
    "    show(f\"{error_msg}\\nPlease make sure you run the cells in order: Installation-Initialization-Data Models-Core Functions\", \"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI Structure\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_ui():\n",
    "    \"\"\"Create optimized Literature Synthesis UI.\"\"\"\n",
    "    \n",
    "    with gr.Blocks() as app:\n",
    "        gr.Markdown(\"# Literature Synthesis Expert System\")\n",
    "        \n",
    "        with gr.Tabs() as tabs:\n",
    "            # === INPUT TAB ===\n",
    "            with gr.Tab(\"Document Input\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        # PDF Upload (only option)\n",
    "                        pdf_input = gr.File(\n",
    "                            label=\"Upload Scientific PDF\", \n",
    "                            file_types=[\".pdf\"],\n",
    "                            file_count=\"single\"\n",
    "                        )\n",
    "                        \n",
    "                        with gr.Row():\n",
    "                            analysis_mode = gr.Radio(\n",
    "                                choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                                label=\"Analysis Mode\",\n",
    "                                value=\"quick\",\n",
    "                                info=\"Quick: 30-40s, Balanced: 1-2min, Thorough: 3-5min\"\n",
    "                            )\n",
    "                            analyze_btn = gr.Button(\"Analyze Document\", variant=\"primary\")\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        status_box = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                        progress_bar = gr.Slider(\n",
    "                            minimum=0, maximum=100, value=0, \n",
    "                            label=\"Processing Progress\",\n",
    "                            interactive=False\n",
    "                        )\n",
    "            \n",
    "            # === CONCEPTS TAB ===\n",
    "            with gr.Tab(\"Concepts & Relationships\"):\n",
    "                with gr.Row():\n",
    "                    # Add document metadata box at the top\n",
    "                    doc_info = gr.Markdown(\"*Upload and analyze a document to see results*\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        concepts_filter = gr.Radio(\n",
    "                            choices=[\"all\", \"high\", \"medium\", \"low\"],\n",
    "                            label=\"Filter by Importance\",\n",
    "                            value=\"all\"\n",
    "                        )\n",
    "                        concepts_table = gr.DataFrame(\n",
    "                            headers=[\"Concept\", \"Definition\", \"Importance\", \"Confidence\"]\n",
    "                        )\n",
    "                    \n",
    "                    with gr.Column():\n",
    "                        relationships_table = gr.DataFrame(\n",
    "                            headers=[\"Source\", \"Relationship\", \"Target\", \"Evidence\", \"Confidence\"]\n",
    "                        )\n",
    "            \n",
    "            # === VISUALIZATION TAB ===\n",
    "            with gr.Tab(\"Visualization\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        with gr.Row():\n",
    "                            min_confidence = gr.Slider(\n",
    "                                minimum=0.0, maximum=1.0, value=0.5, step=0.1,\n",
    "                                label=\"Minimum Confidence\"\n",
    "                            )\n",
    "                            layout_type = gr.Dropdown(\n",
    "                                choices=[\"Force-directed\", \"Circular\", \"Spectral\", \"Spring\"],\n",
    "                                label=\"Layout Type\",\n",
    "                                value=\"Force-directed\"\n",
    "                            )\n",
    "                            refresh_viz_btn = gr.Button(\"Refresh\")\n",
    "                        \n",
    "                        network_plot = gr.Plot(label=\"Concept Network\")\n",
    "                            \n",
    "            # === SYNTHESIS TAB ===\n",
    "            with gr.Tab(\"Research Synthesis\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        synthesis_output = gr.Markdown()\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        gr.Markdown(\"### Research Gaps\")\n",
    "                        gaps_table = gr.DataFrame(\n",
    "                            headers=[\"Description\", \"Related Concepts\", \"Importance\"]\n",
    "                        )\n",
    "                        \n",
    "                        with gr.Row():\n",
    "                            export_format = gr.Dropdown(\n",
    "                                choices=[\"Markdown\", \"Text\", \"JSON\"],\n",
    "                                label=\"Export Format\",\n",
    "                                value=\"Markdown\"\n",
    "                            )\n",
    "                            export_btn = gr.Button(\"Export\")\n",
    "                            \n",
    "            # === SETTINGS TAB ===\n",
    "            with gr.Tab(\"Settings\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        # Analysis mode\n",
    "                        gr.Markdown(\"#### Analysis Settings\")\n",
    "                        settings_analysis_mode = gr.Radio(\n",
    "                            choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                            label=\"Analysis Mode\",\n",
    "                            value=\"quick\",\n",
    "                            info=\"Affects document sampling and processing depth\"\n",
    "                        )\n",
    "                        \n",
    "                        # Text processing settings\n",
    "                        gr.Markdown(\"#### Text Processing\")\n",
    "                        chunk_size = gr.Slider(\n",
    "                            minimum=500, maximum=8000, value=2000, step=500,\n",
    "                            label=\"Chunk Size (chars)\",\n",
    "                            info=\"Larger chunks capture more context but process slower\"\n",
    "                        )\n",
    "                        chunk_overlap = gr.Slider(\n",
    "                            minimum=50, maximum=1000, value=200, step=50,\n",
    "                            label=\"Chunk Overlap\"\n",
    "                        )\n",
    "                        \n",
    "                        # Concept settings\n",
    "                        gr.Markdown(\"#### Concepts\")\n",
    "                        min_importance = gr.Dropdown(\n",
    "                            choices=[\"low\", \"medium\", \"high\"],\n",
    "                            label=\"Min Importance\",\n",
    "                            value=\"medium\"\n",
    "                        )\n",
    "                        max_concepts = gr.Slider(\n",
    "                            minimum=5, maximum=100, value=25, step=5,\n",
    "                            label=\"Max Concepts\"\n",
    "                        )\n",
    "                        \n",
    "                        # Relationship settings\n",
    "                        gr.Markdown(\"#### Relationships\")\n",
    "                        relationship_confidence = gr.Slider(\n",
    "                            minimum=0.0, maximum=1.0, value=0.6, step=0.1,\n",
    "                            label=\"Min Confidence\"\n",
    "                        )\n",
    "                        max_relationships = gr.Slider(\n",
    "                            minimum=10, maximum=200, value=50, step=10,\n",
    "                            label=\"Max Relationships\"\n",
    "                        )\n",
    "                        \n",
    "                        apply_settings_btn = gr.Button(\"Apply Settings\", variant=\"primary\")\n",
    "                        settings_status = gr.Textbox(label=\"Settings Status\", interactive=False)\n",
    "        \n",
    "        # === State Variables ===\n",
    "        results_state = gr.State(None)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create the UI\n",
    "ui = create_ui()\n",
    "\n",
    "# Display success message in notebook\n",
    "show_info(\"UI structure defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI Launch\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def launch_litsynth_ui():\n",
    "    \"\"\"Launch the Literature Synthesis Expert System UI.\"\"\"\n",
    "    \n",
    "    # Document Processing Functions\n",
    "    def smart_sample_document(text, sample_percentage=15, min_chars=4000, max_chars=15000):\n",
    "        \"\"\"Sample document to reduce processing time while keeping key sections.\"\"\"\n",
    "        if not text or len(text) <= min_chars:\n",
    "            return (text, 100) if text else (\"\", 0)\n",
    "            \n",
    "        target_size = max(min_chars, min(max_chars, int(len(text) * sample_percentage / 100)))\n",
    "        \n",
    "        # Extract document sections\n",
    "        import re\n",
    "        section_patterns = {\n",
    "            'abstract': r'(?i)abstract\\s*\\n',\n",
    "            'introduction': r'(?i)(introduction|background)\\s*\\n',\n",
    "            'methods': r'(?i)(methods|methodology|materials\\s+and\\s+methods)\\s*\\n',\n",
    "            'results': r'(?i)results\\s*\\n',\n",
    "            'discussion': r'(?i)discussion\\s*\\n',\n",
    "            'conclusion': r'(?i)(conclusion|conclusions|summary)\\s*\\n'\n",
    "        }\n",
    "        \n",
    "        sections = {}\n",
    "        for name, pattern in section_patterns.items():\n",
    "            matches = list(re.finditer(pattern, text))\n",
    "            if matches:\n",
    "                start = matches[0].end()\n",
    "                next_starts = [m.start() for m in re.finditer('|'.join(section_patterns.values()), text[start:])]\n",
    "                end = start + next_starts[0] if next_starts else len(text)\n",
    "                sections[name] = (start, end)\n",
    "        \n",
    "        # Prioritize sections or use beginning-middle-end approach\n",
    "        sampled_text = \"\"\n",
    "        if sections:\n",
    "            priority_order = ['abstract', 'introduction', 'conclusion', 'discussion', 'results', 'methods']\n",
    "            chars_remaining = target_size\n",
    "            \n",
    "            for section in priority_order:\n",
    "                if section in sections and chars_remaining > 0:\n",
    "                    start, end = sections[section]\n",
    "                    section_text = text[start:end]\n",
    "                    chars_to_take = min(len(section_text), chars_remaining)\n",
    "                    sampled_text += section_text[:chars_to_take] + \"\\n\\n\"\n",
    "                    chars_remaining -= chars_to_take\n",
    "        \n",
    "        if len(sampled_text) < min_chars or not sections:\n",
    "            sampled_text = \"\"\n",
    "            part_size = target_size // 3\n",
    "            \n",
    "            sampled_text += text[:part_size] + \"\\n\\n\"\n",
    "            if len(text) > part_size * 3:\n",
    "                middle_start = len(text) // 2 - part_size // 2\n",
    "                sampled_text += \"[...]\\n\\n\" + text[middle_start:middle_start + part_size] + \"\\n\\n\"\n",
    "            if len(text) > part_size * 2:\n",
    "                sampled_text += \"[...]\\n\\n\" + text[max(len(text) - part_size, part_size * 2)]\n",
    "        \n",
    "        coverage = min(100, round(len(sampled_text) / len(text) * 100))\n",
    "        return sampled_text, coverage\n",
    "    \n",
    "    def process_pdf_document(pdf_file, analysis_mode=\"quick\"):\n",
    "        \"\"\"Process PDF with staged concept extraction and relationship mapping.\"\"\"\n",
    "        if not pdf_file:\n",
    "            return \"Please upload a PDF file.\", None, 0\n",
    "        \n",
    "        try:\n",
    "            yield \"Loading PDF document...\", None, 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Process file upload\n",
    "            temp_path = Path(tempfile.mkdtemp()) / \"uploaded.pdf\"\n",
    "            if hasattr(pdf_file, 'name'):\n",
    "                with open(pdf_file.name, \"rb\") as src_file, open(temp_path, \"wb\") as dest_file:\n",
    "                    dest_file.write(src_file.read())\n",
    "            else:\n",
    "                with open(temp_path, \"wb\") as f:\n",
    "                    f.write(pdf_file)\n",
    "            \n",
    "            yield \"Extracting text...\", None, 10\n",
    "            doc_data = load_document(\"pdf\", str(temp_path))\n",
    "            text = doc_data.get(\"text\", \"\")\n",
    "            \n",
    "            if not text:\n",
    "                return \"Failed to extract text from PDF.\", None, 0\n",
    "            \n",
    "            # Sample text based on analysis mode\n",
    "            if len(text) <= 4000:\n",
    "                sampled_text, coverage = text, 100\n",
    "            else:\n",
    "                sample_percent = {\"quick\": 10, \"balanced\": 25, \"thorough\": 50}.get(analysis_mode, 10)\n",
    "                target_size = min(len(text), max(4000, int(len(text) * sample_percent / 100)))\n",
    "                \n",
    "                segment_size = min(target_size // 3, 3000)\n",
    "                start_text = text[:segment_size]\n",
    "                mid_point = len(text) // 2\n",
    "                mid_text = text[mid_point - segment_size//2:mid_point + segment_size//2]\n",
    "                end_text = text[max(0, len(text) - segment_size):]\n",
    "                \n",
    "                sampled_text = start_text + \"\\n\\n[...]\\n\\n\" + mid_text + \"\\n\\n[...]\\n\\n\" + end_text\n",
    "                coverage = round((len(sampled_text) / len(text)) * 100)\n",
    "            \n",
    "            yield f\"Processing document ({len(text)} characters, {coverage}% sample)...\", None, 20\n",
    "            doc_id = hashlib.md5(text[:1000].encode()).hexdigest()[:10]\n",
    "            \n",
    "            # Multi-stage analysis\n",
    "            concepts, relationships, gaps = [], [], []\n",
    "            synthesis = \"No synthesis generated.\"\n",
    "            \n",
    "            # 1. Extract concepts\n",
    "            try:\n",
    "                yield \"Extracting concepts...\", None, 30\n",
    "                current_config = config if 'config' in globals() else LitSynthConfig()\n",
    "                concepts = extract_concepts(sampled_text, current_config)\n",
    "                yield f\"Found {len(concepts)} concepts\", None, 50\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR in concept extraction: {str(e)}\")\n",
    "                yield f\"Error extracting concepts: {str(e)}\", None, 50\n",
    "            \n",
    "            if concepts:\n",
    "                # 2. Identify relationships\n",
    "                try:\n",
    "                    yield \"Identifying relationships...\", None, 60\n",
    "                    relationships = identify_relationships(sampled_text, concepts, current_config)\n",
    "                    yield f\"Found {len(relationships)} relationships\", None, 70\n",
    "                except Exception as e:\n",
    "                    yield f\"Error identifying relationships, continuing...\", None, 70\n",
    "                \n",
    "                # 3. Identify research gaps\n",
    "                try:\n",
    "                    yield \"Identifying research gaps...\", None, 80\n",
    "                    gaps = identify_research_gaps(sampled_text, concepts, relationships)\n",
    "                    yield f\"Found {len(gaps)} research gaps\", None, 90\n",
    "                except Exception as e:\n",
    "                    yield f\"Error identifying research gaps, continuing...\", None, 90\n",
    "                \n",
    "                # 4. Generate synthesis\n",
    "                try:\n",
    "                    yield \"Generating synthesis...\", None, 95\n",
    "                    synthesis = generate_synthesis(sampled_text, concepts, relationships, gaps)\n",
    "                except Exception as e:\n",
    "                    synthesis = \"Synthesis generation failed. Please check the extracted concepts and relationships.\"\n",
    "            else:\n",
    "                yield \"No concepts found, skipping further analysis...\", None, 95\n",
    "            \n",
    "            # Package results\n",
    "            results = LiteratureSynthesisOutput(\n",
    "                document_id=doc_id,\n",
    "                document_metadata={\n",
    "                    \"original_length\": len(text),\n",
    "                    \"processed_length\": len(sampled_text),\n",
    "                    \"coverage_percentage\": coverage,\n",
    "                    \"processing_time\": round(time.time() - start_time, 2),\n",
    "                    \"analysis_mode\": analysis_mode\n",
    "                },\n",
    "                concepts=concepts or [],\n",
    "                relationships=relationships or [],\n",
    "                research_gaps=gaps or [],\n",
    "                synthesis_text=synthesis or \"No synthesis available.\"\n",
    "            )\n",
    "            \n",
    "            processing_time = round(time.time() - start_time, 2)\n",
    "            status_msg = (f\"Analysis complete in {processing_time}s: {len(results.concepts)} concepts, \"\n",
    "                        f\"{len(results.relationships)} relationships, {len(results.research_gaps)} research gaps \"\n",
    "                        f\"({coverage}% of document processed)\")\n",
    "            \n",
    "            yield status_msg, results, 100\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error analyzing document: {str(e)}\", None, 0\n",
    "    \n",
    "    # Visualization Function\n",
    "    def create_network_visualization(concepts, relationships, min_confidence=0.5):\n",
    "        \"\"\"Create network visualization with improved readability.\"\"\"\n",
    "        if not concepts or len(concepts) < 2:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            ax.text(0.5, 0.5, \"Not enough concepts to create visualization\", \n",
    "                   ha='center', va='center', fontsize=12)\n",
    "            ax.axis('off')\n",
    "            return fig\n",
    "        \n",
    "        # Create directed graph\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes and edges\n",
    "        for concept in concepts:\n",
    "            G.add_node(concept.name, importance=concept.importance, definition=concept.definition)\n",
    "        \n",
    "        edge_count = 0\n",
    "        for rel in relationships:\n",
    "            if rel.confidence >= min_confidence and rel.source in G.nodes and rel.target in G.nodes:\n",
    "                G.add_edge(rel.source, rel.target, \n",
    "                          relationship=rel.relationship_type,\n",
    "                          evidence=rel.evidence,\n",
    "                          confidence=rel.confidence)\n",
    "                edge_count += 1\n",
    "        \n",
    "        # Enhanced visualization styling\n",
    "        plt.rcParams.update({'font.size': 12})\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        importance_colors = {\"high\": \"#e41a1c\", \"medium\": \"#377eb8\", \"low\": \"#4daf4a\"}\n",
    "        node_colors = [importance_colors.get(G.nodes[node][\"importance\"], \"#999999\") for node in G.nodes]\n",
    "        \n",
    "        centrality = nx.degree_centrality(G)\n",
    "        node_sizes = [3000 * (centrality[node] + 0.1) for node in G.nodes]\n",
    "        \n",
    "        pos = nx.spring_layout(G, k=0.4, seed=42)\n",
    "        \n",
    "        # Draw network with improved visibility\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, \n",
    "                              alpha=0.85, edgecolors='white', linewidths=1.5)\n",
    "        nx.draw_networkx_edges(G, pos, edge_color='#555555', width=2.0, alpha=0.7, \n",
    "                              arrows=True, arrowsize=20, node_size=node_sizes)\n",
    "        \n",
    "        # Improved label rendering\n",
    "        labels_pos = {node: (pos[node][0], pos[node][1] + 0.02) for node in G.nodes}\n",
    "        nx.draw_networkx_labels(G, labels_pos, font_size=12, font_weight='bold', \n",
    "                               bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', \n",
    "                                        boxstyle='round,pad=0.3'))\n",
    "        \n",
    "        # Add legend\n",
    "        legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                     markerfacecolor=color, markersize=12, \n",
    "                                     label=f\"{importance.capitalize()} Importance\") \n",
    "                          for importance, color in importance_colors.items()]\n",
    "        ax.legend(handles=legend_elements, loc='upper right', fontsize=11, \n",
    "                 frameon=True, facecolor='white', edgecolor='#cccccc')\n",
    "        \n",
    "        ax.axis('off')\n",
    "        plt.title(f\"Concept Relationship Network ({edge_count} connections at {min_confidence:.1f}+ confidence)\",\n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    # Display Helper Functions\n",
    "    def update_doc_info(results):\n",
    "        \"\"\"Format document metadata for display.\"\"\"\n",
    "        if not results:\n",
    "            return \"*No document analyzed yet*\"\n",
    "            \n",
    "        metadata = results.document_metadata\n",
    "        return (f\"### Document Analysis Details\\n\"\n",
    "                f\"**Coverage**: {metadata.get('coverage_percentage', 'Unknown')}% of document processed\\n\"\n",
    "                f\"**Processing Time**: {metadata.get('processing_time', 'Unknown')}s\\n\"\n",
    "                f\"**Analysis Mode**: {metadata.get('analysis_mode', 'Unknown')}\\n\"\n",
    "                f\"**Concepts**: {len(results.concepts)}, \"\n",
    "                f\"**Relationships**: {len(results.relationships)}, \"\n",
    "                f\"**Research Gaps**: {len(results.research_gaps)}\")\n",
    "    \n",
    "    def update_concepts_display(results, filter_type=\"all\"):\n",
    "        \"\"\"Format concepts data for display with optional filtering.\"\"\"\n",
    "        if not results or not hasattr(results, 'concepts') or not results.concepts:\n",
    "            return None\n",
    "        \n",
    "        filtered_concepts = results.concepts if filter_type == \"all\" else [c for c in results.concepts if c.importance == filter_type]\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            \"Concept\": [c.name for c in filtered_concepts],\n",
    "            \"Definition\": [c.definition for c in filtered_concepts],\n",
    "            \"Importance\": [c.importance.capitalize() for c in filtered_concepts],\n",
    "            \"Confidence\": [f\"{c.confidence:.2f}\" for c in filtered_concepts]\n",
    "        })\n",
    "    \n",
    "    def update_relationships_display(results):\n",
    "        \"\"\"Format relationships data for display.\"\"\"\n",
    "        if not results or not hasattr(results, 'relationships') or not results.relationships:\n",
    "            return None\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            \"Source\": [r.source for r in results.relationships],\n",
    "            \"Relationship\": [r.relationship_type for r in results.relationships],\n",
    "            \"Target\": [r.target for r in results.relationships],\n",
    "            \"Evidence\": [r.evidence or \"N/A\" for r in results.relationships],\n",
    "            \"Confidence\": [f\"{r.confidence:.2f}\" for r in results.relationships]\n",
    "        })\n",
    "    \n",
    "    def update_gaps_display(results):\n",
    "        \"\"\"Format research gaps data for display.\"\"\"\n",
    "        if not results or not hasattr(results, 'research_gaps') or not results.research_gaps:\n",
    "            return None\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            \"Description\": [g.description for g in results.research_gaps],\n",
    "            \"Related Concepts\": [\", \".join(g.related_concepts) for g in results.research_gaps],\n",
    "            \"Importance\": [g.importance.capitalize() for g in results.research_gaps]\n",
    "        })\n",
    "    \n",
    "    def update_visualization(results, min_confidence):\n",
    "        \"\"\"Update network visualization based on minimum confidence.\"\"\"\n",
    "        if not results or not hasattr(results, 'concepts') or len(results.concepts) < 2:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            ax.text(0.5, 0.5, \"Not enough concepts to create visualization\", \n",
    "                   ha='center', va='center', fontsize=12)\n",
    "            ax.axis('off')\n",
    "            return fig\n",
    "        \n",
    "        return create_network_visualization(results.concepts, results.relationships, min_confidence)\n",
    "    \n",
    "    def update_config(analysis_mode, chunk_size, chunk_overlap, min_importance, \n",
    "                     max_concepts, relationship_confidence, max_relationships):\n",
    "        \"\"\"Update system configuration.\"\"\"\n",
    "        try:\n",
    "            new_config = LitSynthConfig(\n",
    "                text_chunk_size=chunk_size,\n",
    "                text_chunk_overlap=chunk_overlap,\n",
    "                min_concept_importance=min_importance,\n",
    "                max_concepts=max_concepts,\n",
    "                relationship_confidence=relationship_confidence,\n",
    "                max_relationships=max_relationships\n",
    "            )\n",
    "            \n",
    "            litsynth.config = new_config\n",
    "            settings_summary = f\"Settings updated: {analysis_mode} mode, {chunk_size} chunk size, {min_importance} min importance\"\n",
    "            return new_config, settings_summary\n",
    "        except Exception as e:\n",
    "            return None, f\"Error updating configuration: {str(e)}\"\n",
    "    \n",
    "    # Create UI\n",
    "    with gr.Blocks(css=\"\"\"\n",
    "        /* Table cell wrapping */\n",
    "        table td {\n",
    "            white-space: normal !important;\n",
    "            word-wrap: break-word !important;\n",
    "            max-width: 300px !important;\n",
    "        }\n",
    "        \n",
    "        /* Clean styling */\n",
    "        .section-header {\n",
    "            font-weight: bold;\n",
    "            margin-top: 10px;\n",
    "            margin-bottom: 5px;\n",
    "            border-bottom: 1px solid rgba(128, 128, 128, 0.3);\n",
    "            padding-bottom: 3px;\n",
    "        }\n",
    "        \n",
    "        .info-text {\n",
    "            font-style: italic;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "    \"\"\") as app:\n",
    "        gr.Markdown(\"# Literature Synthesis Expert System\")\n",
    "        \n",
    "        # State variables\n",
    "        results_state = gr.State(None)\n",
    "        \n",
    "        with gr.Tabs() as tabs:\n",
    "            # INPUT TAB\n",
    "            with gr.Tab(\"Document Input\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        pdf_input = gr.File(\n",
    "                            label=\"Upload Scientific PDF\", \n",
    "                            file_types=[\".pdf\"],\n",
    "                            file_count=\"single\"\n",
    "                        )\n",
    "                        \n",
    "                        with gr.Row():\n",
    "                            analysis_mode = gr.Radio(\n",
    "                                choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                                label=\"Analysis Mode\",\n",
    "                                value=\"quick\",\n",
    "                                info=\"Quick: 30-40s, Balanced: 1-2min, Thorough: 3-5min\"\n",
    "                            )\n",
    "                            analyze_btn = gr.Button(\"Analyze Document\", variant=\"primary\")\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        status_box = gr.Textbox(\n",
    "                            label=\"Status\", \n",
    "                            interactive=False,\n",
    "                            value=\"Ready to analyze. Please upload a PDF document.\"\n",
    "                        )\n",
    "                        progress_bar = gr.Slider(\n",
    "                            minimum=0, maximum=100, value=0, \n",
    "                            label=\"Processing Progress\",\n",
    "                            interactive=False\n",
    "                        )\n",
    "            \n",
    "            # CONCEPTS TAB\n",
    "            with gr.Tab(\"Concepts & Relationships\"):\n",
    "                with gr.Row():\n",
    "                    doc_info = gr.Markdown(\"*Upload and analyze a document to see results*\")\n",
    "                \n",
    "                gr.Markdown(\"### Understanding the Concepts Table\")\n",
    "                gr.Markdown(\"This table shows key concepts extracted from the document. Use the filter to focus on specific importance levels.\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"#### Key Concepts\", elem_classes=[\"section-header\"])\n",
    "                        concepts_filter = gr.Radio(\n",
    "                            choices=[\"all\", \"high\", \"medium\", \"low\"],\n",
    "                            label=\"Filter by Importance\",\n",
    "                            value=\"all\"\n",
    "                        )\n",
    "                        concepts_table = gr.DataFrame(\n",
    "                            headers=[\"Concept\", \"Definition\", \"Importance\", \"Confidence\"]\n",
    "                        )\n",
    "                    \n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"#### Relationships Between Concepts\", elem_classes=[\"section-header\"])\n",
    "                        gr.Markdown(\"This table shows how concepts connect to each other.\", elem_classes=[\"info-text\"])\n",
    "                        relationships_table = gr.DataFrame(\n",
    "                            headers=[\"Source\", \"Relationship\", \"Target\", \"Evidence\", \"Confidence\"]\n",
    "                        )\n",
    "            \n",
    "            # VISUALIZATION TAB\n",
    "            with gr.Tab(\"Visualization\"):\n",
    "                gr.Markdown(\"### Network Visualization Guide\")\n",
    "                gr.Markdown(\"This visualization shows how concepts relate to each other:\")\n",
    "                gr.Markdown(\"- **Red nodes**: High importance concepts\")\n",
    "                gr.Markdown(\"- **Blue nodes**: Medium importance concepts\")\n",
    "                gr.Markdown(\"- **Green nodes**: Low importance concepts\")\n",
    "                gr.Markdown(\"- **Node size**: Larger nodes have more connections\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        with gr.Row():\n",
    "                            min_confidence = gr.Slider(\n",
    "                                minimum=0.0, maximum=1.0, value=0.5, step=0.1,\n",
    "                                label=\"Minimum Confidence\",\n",
    "                                info=\"Only show relationships with confidence above this threshold\"\n",
    "                            )\n",
    "                            refresh_viz_btn = gr.Button(\"Refresh Visualization\")\n",
    "                        \n",
    "                        network_plot = gr.Plot(label=\"Concept Network\")\n",
    "                            \n",
    "            # SYNTHESIS TAB\n",
    "            with gr.Tab(\"Research Synthesis\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        gr.Markdown(\"#### Overview & Key Findings\", elem_classes=[\"section-header\"])\n",
    "                        synthesis_output = gr.Markdown()\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        gr.Markdown(\"#### Research Gaps\", elem_classes=[\"section-header\"])\n",
    "                        gr.Markdown(\"These are potential areas for future research that weren't fully addressed.\", elem_classes=[\"info-text\"])\n",
    "                        gaps_table = gr.DataFrame(\n",
    "                            headers=[\"Description\", \"Related Concepts\", \"Importance\"]\n",
    "                        )\n",
    "                            \n",
    "            # SETTINGS TAB\n",
    "            with gr.Tab(\"Settings\"):\n",
    "                gr.Markdown(\"### Settings Guide\")\n",
    "                gr.Markdown(\"These settings control how document analysis works. For most users, the default settings work well.\", elem_classes=[\"info-text\"])\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"#### Analysis Settings\", elem_classes=[\"section-header\"])\n",
    "                        settings_analysis_mode = gr.Radio(\n",
    "                            choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                            label=\"Analysis Mode\",\n",
    "                            value=\"quick\",\n",
    "                            info=\"Quick (30-40s): Basic overview | Balanced (1-2min): Standard analysis | Thorough (3-5min): Deep analysis\"\n",
    "                        )\n",
    "                        \n",
    "                        gr.Markdown(\"#### Text Processing\", elem_classes=[\"section-header\"])\n",
    "                        chunk_size = gr.Slider(\n",
    "                            minimum=500, maximum=8000, value=2000, step=500,\n",
    "                            label=\"Chunk Size (chars)\",\n",
    "                            info=\"Larger = Better context but slower | Smaller = Faster but less context\"\n",
    "                        )\n",
    "                        chunk_overlap = gr.Slider(\n",
    "                            minimum=50, maximum=1000, value=200, step=50,\n",
    "                            label=\"Chunk Overlap\",\n",
    "                            info=\"Higher overlap maintains context between chunks\"\n",
    "                        )\n",
    "                        \n",
    "                        gr.Markdown(\"#### Concepts Settings\", elem_classes=[\"section-header\"])\n",
    "                        min_importance = gr.Dropdown(\n",
    "                            choices=[\"low\", \"medium\", \"high\"],\n",
    "                            label=\"Min Importance\",\n",
    "                            value=\"medium\",\n",
    "                            info=\"Only include concepts above this importance level\"\n",
    "                        )\n",
    "                        max_concepts = gr.Slider(\n",
    "                            minimum=5, maximum=100, value=25, step=5,\n",
    "                            label=\"Max Concepts\",\n",
    "                            info=\"Maximum number of concepts to extract\"\n",
    "                        )\n",
    "                        \n",
    "                        gr.Markdown(\"#### Relationships Settings\", elem_classes=[\"section-header\"])\n",
    "                        relationship_confidence = gr.Slider(\n",
    "                            minimum=0.0, maximum=1.0, value=0.6, step=0.1,\n",
    "                            label=\"Min Confidence\",\n",
    "                            info=\"Only include relationships with confidence above this threshold\"\n",
    "                        )\n",
    "                        max_relationships = gr.Slider(\n",
    "                            minimum=10, maximum=200, value=50, step=10,\n",
    "                            label=\"Max Relationships\",\n",
    "                            info=\"Maximum number of relationships to identify\"\n",
    "                        )\n",
    "                        \n",
    "                        apply_settings_btn = gr.Button(\"Apply Settings\", variant=\"primary\")\n",
    "                        settings_status = gr.Textbox(label=\"Settings Status\", interactive=False)\n",
    "        \n",
    "        # Event Handlers\n",
    "        analyze_btn.click(\n",
    "            fn=process_pdf_document,\n",
    "            inputs=[pdf_input, analysis_mode],\n",
    "            outputs=[status_box, results_state, progress_bar]\n",
    "        ).then(\n",
    "            fn=update_doc_info,\n",
    "            inputs=[results_state],\n",
    "            outputs=[doc_info]\n",
    "        ).then(\n",
    "            fn=update_concepts_display,\n",
    "            inputs=[results_state, gr.State(\"all\")],\n",
    "            outputs=[concepts_table]\n",
    "        ).then(\n",
    "            fn=update_relationships_display,\n",
    "            inputs=[results_state],\n",
    "            outputs=[relationships_table]\n",
    "        ).then(\n",
    "            fn=update_gaps_display,\n",
    "            inputs=[results_state],\n",
    "            outputs=[gaps_table]\n",
    "        ).then(\n",
    "            fn=lambda x: x.synthesis_text if x and hasattr(x, 'synthesis_text') else \"No synthesis available.\",\n",
    "            inputs=[results_state],\n",
    "            outputs=[synthesis_output]\n",
    "        ).then(\n",
    "            fn=update_visualization,\n",
    "            inputs=[results_state, min_confidence],\n",
    "            outputs=[network_plot]\n",
    "        )\n",
    "        \n",
    "        # Filter concepts by importance\n",
    "        concepts_filter.change(\n",
    "            fn=update_concepts_display,\n",
    "            inputs=[results_state, concepts_filter],\n",
    "            outputs=[concepts_table]\n",
    "        )\n",
    "        \n",
    "        # Refresh visualization\n",
    "        refresh_viz_btn.click(\n",
    "            fn=update_visualization,\n",
    "            inputs=[results_state, min_confidence],\n",
    "            outputs=[network_plot]\n",
    "        )\n",
    "        \n",
    "        # Update system settings\n",
    "        apply_settings_btn.click(\n",
    "            fn=update_config,\n",
    "            inputs=[\n",
    "                settings_analysis_mode, chunk_size, chunk_overlap, \n",
    "                min_importance, max_concepts, relationship_confidence, max_relationships\n",
    "            ],\n",
    "            outputs=[results_state, settings_status]\n",
    "        )\n",
    "    \n",
    "    # Launch the app\n",
    "    app.launch(inline=True, share=True, inbrowser=True, debug=True)\n",
    "\n",
    "# Launch with error handling\n",
    "try:\n",
    "    launch_litsynth_ui()\n",
    "    show(\"UI launched successfully\", \"success\")\n",
    "except Exception as e:\n",
    "    show(\"UI launch failed: \" + str(e), \"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Temp] Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Protocol Extraction Diagnostic\n",
    "\n",
    "# 1. Simple test data\n",
    "test_text = \"We conducted a randomized controlled trial with 60 participants. Participants were randomly assigned to mindfulness intervention or wait-list control. Intervention: 8 weekly 90-minute sessions. Measured at baseline and post-intervention using BDI-II and PSS. Analysis: repeated measures ANOVA.\"\n",
    "\n",
    "# 2. Check basic LLM functionality\n",
    "print(\"== BASIC LLM TEST ==\")\n",
    "try:\n",
    "    test_response = llm.invoke(\"Say 'TEST OK'\")\n",
    "    print(f\"LLM response: {test_response.content if hasattr(test_response, 'content') else test_response}\")\n",
    "except Exception as e:\n",
    "    print(f\"LLM ERROR: {str(e)}\")\n",
    "\n",
    "# 3. Check prompt formatting\n",
    "print(\"\\n== PROMPT TEST ==\")\n",
    "try:\n",
    "    protocol_prompt = PROMPTS[\"protocol_extraction\"].format(text=test_text)\n",
    "    print(f\"Prompt formatting OK - Length: {len(protocol_prompt)} chars\")\n",
    "except Exception as e:\n",
    "    print(f\"PROMPT ERROR: {str(e)}\")\n",
    "    print(\"First 200 chars of prompt template:\")\n",
    "    print(PROMPTS[\"protocol_extraction\"][:200])\n",
    "\n",
    "# 4. Test raw LLM response to protocol prompt\n",
    "print(\"\\n== RAW LLM RESPONSE ==\")\n",
    "try:\n",
    "    raw_response = llm.invoke(protocol_prompt)\n",
    "    print(f\"LLM responded - Response type: {type(raw_response)}\")\n",
    "    raw_content = raw_response.content if hasattr(raw_response, 'content') else str(raw_response)\n",
    "    print(f\"First 500 chars:\\n{raw_content[:500]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"LLM RESPONSE ERROR: {str(e)}\")\n",
    "\n",
    "# 5. Test parsing function directly\n",
    "print(\"\\n== PARSING TEST ==\")\n",
    "try:\n",
    "    from pydantic import ValidationError\n",
    "    # Get the raw parsing function logic from create_chain\n",
    "    def try_parse(content):\n",
    "        # Try direct JSON parsing first\n",
    "        try:\n",
    "            if \"```json\" in content:\n",
    "                json_block = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "                data = json.loads(json_block)\n",
    "                return \"JSON block extracted and parsed\", data\n",
    "            # Try regex\n",
    "            import re\n",
    "            json_pattern = r'(\\{.*?\\})'\n",
    "            matches = re.findall(json_pattern, content, re.DOTALL)\n",
    "            if matches:\n",
    "                data = json.loads(max(matches, key=len))\n",
    "                return \"Regex extraction successful\", data\n",
    "            return \"No JSON found\", None\n",
    "        except Exception as e:\n",
    "            return f\"Parsing error: {str(e)}\", None\n",
    "    \n",
    "    parse_result, data = try_parse(raw_content)\n",
    "    print(f\"Parse result: {parse_result}\")\n",
    "    if data:\n",
    "        print(f\"Found data with keys: {list(data.keys())}\")\n",
    "        # Try constructing model\n",
    "        try:\n",
    "            protocol = ExperimentalProtocol(**data)\n",
    "            print(f\"Model creation SUCCESS: {protocol.protocol_id}\")\n",
    "        except ValidationError as ve:\n",
    "            print(f\"Validation errors: {ve}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model creation failed: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"PARSING TEST ERROR: {str(e)}\")\n",
    "\n",
    "print(\"\\n== DIAGNOSTIC COMPLETE ==\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 Testing & Validation\n",
    "\"\"\"\n",
    "This condensed testing framework validates the Experimental Architect system.\n",
    "It tests data models, core functions, and UI rendering in a single workflow.\n",
    "\n",
    "Run this cell to verify that all components are working as expected before \n",
    "implementing the full UI.\n",
    "\"\"\"\n",
    "\n",
    "import gradio as gr\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "# === METRICS TRACKING ===\n",
    "class ExpArchMetrics:\n",
    "    \"\"\"Tracks performance metrics for ExpArch function calls\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset all metrics\"\"\"\n",
    "        self.steps = []\n",
    "        self.start_time = time.time()\n",
    "        self.total_tokens = 0\n",
    "        self.total_time = 0\n",
    "    \n",
    "    def record_step(self, name: str, duration: float, tokens: int = 0, error: Optional[str] = None):\n",
    "        \"\"\"Record a processing step with metrics\"\"\"\n",
    "        self.steps.append({\n",
    "            \"name\": name,\n",
    "            \"duration\": duration,\n",
    "            \"tokens\": tokens,\n",
    "            \"timestamp\": time.time() - self.start_time,\n",
    "            \"error\": error\n",
    "        })\n",
    "        self.total_tokens += tokens\n",
    "        self.total_time += duration\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get summary statistics\"\"\"\n",
    "        if not self.steps:\n",
    "            return {\"total_time\": 0, \"total_tokens\": 0, \"steps\": 0, \"est_cost\": \"$0.00\"}\n",
    "        \n",
    "        # Calculate estimated cost (rough approximation)\n",
    "        est_cost = self.total_tokens * 0.00001  # $0.01 per 1K tokens\n",
    "        \n",
    "        return {\n",
    "            \"total_time\": self.total_time,\n",
    "            \"total_tokens\": self.total_tokens,\n",
    "            \"steps\": len(self.steps),\n",
    "            \"steps_data\": self.steps,\n",
    "            \"est_cost\": f\"${est_cost:.4f}\"\n",
    "        }\n",
    "    \n",
    "    def format_summary(self) -> str:\n",
    "        \"\"\"Format metrics as plain text for display\"\"\"\n",
    "        summary = self.get_summary()\n",
    "        \n",
    "        text = f\"ExpArch System Test Results\\n\\n\"\n",
    "        text += f\"Total Time: {summary['total_time']:.2f}s\\n\"\n",
    "        text += f\"Total Tokens: {summary['total_tokens']:,}\\n\"\n",
    "        text += f\"Steps: {summary['steps']}\\n\"\n",
    "        text += f\"Est. Cost: {summary['est_cost']}\\n\\n\"\n",
    "        \n",
    "        text += \"Step Details:\\n\"\n",
    "        for step in self.steps:\n",
    "            status = f\"Error: {step['error']}\" if step[\"error\"] else \"Success\"\n",
    "            text += f\"- {step['name']}: {step['duration']:.2f}s, {step['tokens']:,} tokens, {status}\\n\"\n",
    "        \n",
    "        return text\n",
    "\n",
    "# Initialize metrics\n",
    "metrics = ExpArchMetrics()\n",
    "\n",
    "# === TEST WORKFLOW ===\n",
    "def test_exparch_workflow(methods_text: str, config: Optional[ExpArchConfig] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Run a complete ExpArch workflow test with metrics tracking.\n",
    "    \n",
    "    Args:\n",
    "        methods_text: Method section text to analyze\n",
    "        config: Optional configuration override\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with test results and metrics\n",
    "    \"\"\"\n",
    "    if not methods_text or len(methods_text.strip()) < 100:\n",
    "        return {\n",
    "            \"error\": \"Method text too short for meaningful testing. Please provide a longer methods section.\",\n",
    "            \"metrics\": metrics.get_summary()\n",
    "        }\n",
    "    \n",
    "    # Reset metrics\n",
    "    metrics.reset()\n",
    "    \n",
    "    # Use default config if none provided\n",
    "    config = config or ExpArchConfig(\n",
    "        optimization_mode=\"quick\",  # Use quick mode for testing\n",
    "        agent_max_iterations=3      # Limit iterations for faster testing\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test 1: Protocol Extraction\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        protocol = extract_protocol_chain(methods_text, config)\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if protocol:\n",
    "            results[\"protocol\"] = protocol\n",
    "            # Estimate tokens based on protocol complexity\n",
    "            tokens = len(methods_text) // 4  # Rough estimate\n",
    "            metrics.record_step(\"Protocol Extraction\", duration, tokens)\n",
    "        else:\n",
    "            metrics.record_step(\"Protocol Extraction\", duration, 0, \"Failed to extract protocol\")\n",
    "            return {\n",
    "                \"error\": \"Protocol extraction failed. Please check the methods text and try again.\",\n",
    "                \"metrics\": metrics.get_summary()\n",
    "            }\n",
    "    except Exception as e:\n",
    "        metrics.record_step(\"Protocol Extraction\", time.time() - start_time, 0, str(e))\n",
    "        return {\n",
    "            \"error\": f\"Protocol extraction error: {str(e)}\",\n",
    "            \"metrics\": metrics.get_summary()\n",
    "        }\n",
    "    \n",
    "    # Test 2: Agent State Initialization and Search\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        agent_state = AgentState()\n",
    "        agent_state.extracted_protocol = protocol\n",
    "        \n",
    "        # Simplified search to avoid long waits during testing\n",
    "        search_result, agent_state = search_related_protocols_agent(\n",
    "            protocol, \n",
    "            agent_state, \n",
    "            config\n",
    "        )\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        results[\"agent_state\"] = agent_state\n",
    "        # Estimate tokens for search based on number of results and steps\n",
    "        search_tokens = sum(len(res.content) // 4 for res in agent_state.search_results)\n",
    "        metrics.record_step(\"Protocol Search\", duration, search_tokens)\n",
    "    except Exception as e:\n",
    "        metrics.record_step(\"Protocol Search\", time.time() - start_time, 0, str(e))\n",
    "        results[\"search_error\"] = str(e)\n",
    "        # Continue even if search fails\n",
    "    \n",
    "    # Test 3: Weakness Analysis\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        weaknesses = analyze_protocol_weaknesses_chain(\n",
    "            protocol, \n",
    "            agent_state.search_results if \"agent_state\" in results else [],\n",
    "            config\n",
    "        )\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        results[\"weaknesses\"] = weaknesses\n",
    "        # Estimate tokens based on results size\n",
    "        weakness_tokens = len(str(weaknesses)) // 2\n",
    "        metrics.record_step(\"Weakness Analysis\", duration, weakness_tokens)\n",
    "    except Exception as e:\n",
    "        metrics.record_step(\"Weakness Analysis\", time.time() - start_time, 0, str(e))\n",
    "        results[\"weakness_error\"] = str(e)\n",
    "        # Continue with empty weaknesses if analysis fails\n",
    "        results[\"weaknesses\"] = []\n",
    "    \n",
    "    # Test 4: Protocol Optimization\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        optimized_output = generate_optimized_protocol_chain(\n",
    "            protocol,\n",
    "            results.get(\"weaknesses\", []),\n",
    "            agent_state.search_results if \"agent_state\" in results else [],\n",
    "            config\n",
    "        )\n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        if optimized_output:\n",
    "            results[\"optimized_output\"] = optimized_output\n",
    "            # Estimate tokens based on output complexity\n",
    "            optimization_tokens = len(str(optimized_output.model_dump())) // 2\n",
    "            metrics.record_step(\"Protocol Optimization\", duration, optimization_tokens)\n",
    "        else:\n",
    "            metrics.record_step(\"Protocol Optimization\", duration, 0, \"Failed to generate optimized protocol\")\n",
    "    except Exception as e:\n",
    "        metrics.record_step(\"Protocol Optimization\", time.time() - start_time, 0, str(e))\n",
    "        results[\"optimization_error\"] = str(e)\n",
    "    \n",
    "    # Test 5: Validation (if optimization succeeded)\n",
    "    if \"optimized_output\" in results:\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            validation = validation_summary_chain(\n",
    "                results[\"optimized_output\"],\n",
    "                config\n",
    "            )\n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            results[\"validation\"] = validation\n",
    "            # Estimate tokens for validation\n",
    "            validation_tokens = len(str(validation)) // 2\n",
    "            metrics.record_step(\"Protocol Validation\", duration, validation_tokens)\n",
    "        except Exception as e:\n",
    "            metrics.record_step(\"Protocol Validation\", time.time() - start_time, 0, str(e))\n",
    "            results[\"validation_error\"] = str(e)\n",
    "    \n",
    "    # Add metrics to results\n",
    "    results[\"metrics\"] = metrics.get_summary()\n",
    "    \n",
    "    # Add test status\n",
    "    if \"optimized_output\" in results:\n",
    "        results[\"status\"] = \"success\"\n",
    "    elif \"protocol\" in results:\n",
    "        results[\"status\"] = \"partial\"\n",
    "    else:\n",
    "        results[\"status\"] = \"failed\"\n",
    "    \n",
    "    return results\n",
    "\n",
    "# === SIMPLIFIED VISUALIZATION HELPERS ===\n",
    "\n",
    "def format_protocol_text(protocol):\n",
    "    \"\"\"Format protocol as plain text for display\"\"\"\n",
    "    if not protocol:\n",
    "        return \"No protocol available\"\n",
    "    \n",
    "    text = f\"Study Design: {protocol.study_design}\\n\"\n",
    "    text += f\"Sample Size: {protocol.sample_size or 'Not specified'}\\n\\n\"\n",
    "    \n",
    "    # Add variables by type\n",
    "    text += \"Variables:\\n\"\n",
    "    for var_type, variables in protocol.variables.items():\n",
    "        if variables:\n",
    "            text += f\"- {var_type.capitalize()} Variables:\\n\"\n",
    "            for var in variables:\n",
    "                text += f\"  * {var.name}: {var.description}\\n\"\n",
    "    \n",
    "    # Add analysis methods\n",
    "    if protocol.analysis_methods:\n",
    "        text += \"\\nAnalysis Methods:\\n\"\n",
    "        for method in protocol.analysis_methods:\n",
    "            text += f\"- {method.name}: {method.description}\\n\"\n",
    "    \n",
    "    # Add procedures summary\n",
    "    if protocol.procedures:\n",
    "        text += f\"\\nProcedures ({len(protocol.procedures)} steps):\\n\"\n",
    "        text += \"First 3 steps:\\n\"\n",
    "        for i, step in enumerate(protocol.procedures[:3], 1):\n",
    "            text += f\"{i}. {step.description}\\n\"\n",
    "        if len(protocol.procedures) > 3:\n",
    "            text += f\"... {len(protocol.procedures) - 3} more steps ...\\n\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "def format_improvements_text(optimized_output):\n",
    "    \"\"\"Format improvements as plain text for display\"\"\"\n",
    "    if not optimized_output:\n",
    "        return \"No optimization results available\"\n",
    "    \n",
    "    text = \"Protocol Improvements:\\n\\n\"\n",
    "    \n",
    "    # Add improvements\n",
    "    if optimized_output.improvements:\n",
    "        for i, imp in enumerate(optimized_output.improvements, 1):\n",
    "            text += f\"Improvement {i}: {imp.component}\\n\"\n",
    "            text += f\"Original: {imp.original_text[:80]}...\\n\"\n",
    "            text += f\"Improved: {imp.improved_text[:80]}...\\n\"\n",
    "            text += f\"Justification: {imp.justification[:150]}...\\n\\n\"\n",
    "    else:\n",
    "        text += \"No specific improvements identified.\\n\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "def format_agent_reasoning_text(agent_state):\n",
    "    \"\"\"Format agent reasoning as plain text for display\"\"\"\n",
    "    if not agent_state or not agent_state.steps:\n",
    "        return \"No agent reasoning available\"\n",
    "    \n",
    "    text = \"Agent Reasoning Process:\\n\\n\"\n",
    "    \n",
    "    # Format steps\n",
    "    for step in agent_state.steps:\n",
    "        if step.step_type == \"thought\":\n",
    "            text += f\"THOUGHT:\\n{step.content}\\n\\n\"\n",
    "        elif step.step_type == \"action\":\n",
    "            text += f\"ACTION: {step.tool_name}\\nINPUT: {step.tool_input}\\n\\n\"\n",
    "        elif step.step_type == \"observation\":\n",
    "            observation = step.content[:300] + ('...' if len(step.content) > 300 else '')\n",
    "            text += f\"OBSERVATION:\\n{observation}\\n\\n\"\n",
    "        elif step.step_type == \"final_answer\":\n",
    "            text += f\"FINAL ANSWER:\\n{step.content}\\n\\n\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# === TESTING INTERFACE ===\n",
    "\n",
    "def create_test_interface():\n",
    "    \"\"\"Create Gradio interface for testing the ExpArch system\"\"\"\n",
    "    \n",
    "    # Sample methods text for quick testing\n",
    "    sample_methods = \"\"\"\n",
    "    We conducted a randomized controlled trial with 60 participants (30 experimental, 30 control).\n",
    "    Participants were randomly assigned to either the mindfulness meditation intervention or a wait-list control.\n",
    "    The intervention group received 8 weekly 90-minute sessions of mindfulness training.\n",
    "    Outcomes were measured at baseline and post-intervention (8 weeks) using the Beck Depression Inventory (BDI-II)\n",
    "    and the Perceived Stress Scale (PSS). Analysis was performed using repeated measures ANOVA.\n",
    "    \"\"\"\n",
    "    \n",
    "    def run_exparch_test(methods_text, optimization_mode):\n",
    "        \"\"\"Run ExpArch pipeline test with the provided methods text\"\"\"\n",
    "        if not methods_text or len(methods_text.strip()) < 100:\n",
    "            return \"Methods text too short. Please provide a complete methods section.\", \"\", \"\", \"\", \"\"\n",
    "        \n",
    "        # Configure test settings\n",
    "        config = ExpArchConfig(\n",
    "            optimization_mode=optimization_mode,\n",
    "            agent_max_iterations=5 if optimization_mode == \"quick\" else 8\n",
    "        )\n",
    "        \n",
    "        # Run test workflow\n",
    "        results = test_exparch_workflow(methods_text, config)\n",
    "        \n",
    "        if \"error\" in results:\n",
    "            return results[\"error\"], \"\", \"\", metrics.format_summary(), \"\"\n",
    "        \n",
    "        # Prepare text outputs\n",
    "        protocol_text = format_protocol_text(results.get(\"protocol\"))\n",
    "        agent_text = format_agent_reasoning_text(results.get(\"agent_state\"))\n",
    "        \n",
    "        if \"optimized_output\" in results:\n",
    "            improvements_text = format_improvements_text(results[\"optimized_output\"])\n",
    "        else:\n",
    "            improvements_text = \"Optimization did not complete successfully.\"\n",
    "        \n",
    "        metrics_text = metrics.format_summary()\n",
    "        \n",
    "        # Return all text outputs\n",
    "        status = f\"Test completed with status: {results['status'].upper()}\"\n",
    "        return status, protocol_text, improvements_text, metrics_text, agent_text\n",
    "    \n",
    "    def process_pdf(pdf_file):\n",
    "        \"\"\"Extract text from PDF for testing\"\"\"\n",
    "        if not pdf_file:\n",
    "            return \"Please upload a PDF file.\"\n",
    "        \n",
    "        try:\n",
    "            # Extract text from PDF\n",
    "            doc_data = load_document(\"pdf\", pdf_file.name)\n",
    "            text = doc_data.get(\"text\", \"\")\n",
    "            \n",
    "            if not text:\n",
    "                return \"Failed to extract text from PDF.\"\n",
    "            \n",
    "            # Focus on methods section if possible\n",
    "            methods_section = \"\"\n",
    "            \n",
    "            # Try to find methods section using common headings\n",
    "            patterns = [\n",
    "                r\"(?i)methods\\s*\\n(.*?)(?:\\n\\s*(?:results|discussion)|\\Z)\",\n",
    "                r\"(?i)methodology\\s*\\n(.*?)(?:\\n\\s*(?:results|discussion)|\\Z)\",\n",
    "                r\"(?i)experimental design\\s*\\n(.*?)(?:\\n\\s*(?:results|discussion)|\\Z)\"\n",
    "            ]\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, text, re.DOTALL)\n",
    "                if match:\n",
    "                    methods_section = match.group(1).strip()\n",
    "                    break\n",
    "            \n",
    "            if methods_section and len(methods_section) > 200:\n",
    "                return methods_section\n",
    "            else:\n",
    "                # No clear methods section, return first 2000 chars\n",
    "                return text[:2000]\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error processing PDF: {str(e)}\"\n",
    "    \n",
    "    # Create the interface\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# 🧪 ExpArch System Test\")\n",
    "        gr.Markdown(\"Test the Experimental Architect system with a methods section from a scientific paper.\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Input Options\")\n",
    "                pdf_input = gr.File(label=\"Upload PDF (Optional)\", file_types=[\".pdf\"])\n",
    "                extract_btn = gr.Button(\"Extract Methods\")\n",
    "                \n",
    "                methods_text = gr.Textbox(\n",
    "                    value=sample_methods, \n",
    "                    label=\"Methods Section Text\",\n",
    "                    lines=8, \n",
    "                    placeholder=\"Paste methods section or use PDF extraction\"\n",
    "                )\n",
    "                \n",
    "                optimization_mode = gr.Radio(\n",
    "                    choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                    value=\"quick\",\n",
    "                    label=\"Optimization Mode\",\n",
    "                    info=\"Quick is fastest but less comprehensive\"\n",
    "                )\n",
    "                \n",
    "                test_btn = gr.Button(\"Run System Test\", variant=\"primary\")\n",
    "                status_box = gr.Textbox(label=\"Status\")\n",
    "            \n",
    "        with gr.Tabs() as tabs:\n",
    "            with gr.TabItem(\"Protocol\"):\n",
    "                protocol_display = gr.Textbox(label=\"Extracted Protocol\", lines=15)\n",
    "            \n",
    "            with gr.TabItem(\"Improvements\"):\n",
    "                improvements_display = gr.Textbox(label=\"Protocol Improvements\", lines=15)\n",
    "            \n",
    "            with gr.TabItem(\"Agent Reasoning\"):\n",
    "                agent_display = gr.Textbox(label=\"Agent Reasoning Process\", lines=15)\n",
    "                \n",
    "            with gr.TabItem(\"Metrics\"):\n",
    "                metrics_display = gr.Textbox(label=\"System Metrics\", lines=15)\n",
    "        \n",
    "        # Set up event handlers\n",
    "        pdf_input.change(\n",
    "            fn=lambda x: None,  # Clear methods text when PDF uploaded\n",
    "            inputs=[],\n",
    "            outputs=[methods_text]\n",
    "        )\n",
    "        \n",
    "        extract_btn.click(\n",
    "            fn=process_pdf,\n",
    "            inputs=[pdf_input],\n",
    "            outputs=[methods_text]\n",
    "        )\n",
    "        \n",
    "        test_btn.click(\n",
    "            fn=run_exparch_test,\n",
    "            inputs=[methods_text, optimization_mode],\n",
    "            outputs=[status_box, protocol_display, improvements_display, metrics_display, agent_display]\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Create and launch test interface\n",
    "test_interface = create_test_interface()\n",
    "test_interface.launch(inline=True, share=False)\n",
    "\n",
    "# Show confirmation\n",
    "show(\"ExpArch testing framework initialized - Use the interface to test the system\", \"success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
