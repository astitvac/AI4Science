{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔬 Aavishkar.ai Expert System Notebook\n",
    "\n",
    "<img src=\"https://github.com/astitvac/AI4Science/raw/main/assets/AA_Main_Banner.jpg\" alt=\"Aavishkar.ai Banner\" width=\"600\"/>\n",
    "\n",
    "### <span style=\"color:#6C5CE7;\">AI for Science</span>\n",
    "<small><i>Democratizing advanced AI capabilities for scientific research</i></small>\n",
    "\n",
    "---\n",
    "\n",
    "## 👋 Welcome to Aavishkar.ai Expert Systems!\n",
    "\n",
    "<small>This notebook is part of the <b>Aavishkar.ai AI4Science</b> initiative, which develops LLM-based expert systems to enhance scientific research workflows. Our expert systems formalize scientific cognitive processes using Large Language Models, structured knowledge representations, and interactive interfaces.</small>\n",
    "\n",
    "### 🧠 About This Expert System\n",
    "\n",
    "<small>This notebook implements one of the five scientific cognitive archetypes developed by Aavishkar.ai:</small>\n",
    "\n",
    "<small>\n",
    "1. 📚 <b>Literature Synthesist</b>: Identifies patterns, contradictions, and knowledge gaps across research corpora<br>\n",
    "2. 🧪 <b>Experimental Architect</b>: Translates abstract hypotheses into methodologically sound experimental designs<br>\n",
    "3. 📊 <b>Analytical Navigator</b>: Constructs adaptive analytical pathways through complex datasets<br>\n",
    "4. 📝 <b>Research Documentarian</b>: Structures and articulates scientific findings and methodologies<br>\n",
    "5. 🔄 <b>Interdisciplinary Translator</b>: Establishes conceptual bridges between disparate knowledge domains\n",
    "</small>\n",
    "\n",
    "### 👥 Who Can Use This?\n",
    "\n",
    "<small>\n",
    "Aavishkar.ai tools are designed for all practitioners of hypothesis-driven science:<br>\n",
    "• 🎓 Academic researchers and students<br>\n",
    "• 🏢 Commercial/industrial researchers<br>\n",
    "• 🏛️ Government scientists<br>\n",
    "• 🔭 Citizen scientists<br>\n",
    "• 🧩 Independent researchers\n",
    "</small>\n",
    "\n",
    "<small>No matter your technical background or institutional affiliation, this notebook provides accessible AI capabilities for rigorous scientific work.</small>\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ Setup Instructions\n",
    "\n",
    "<small>\n",
    "\n",
    "**Google Colab**\n",
    "* Click on \"Runtime\" in the menu\n",
    "* Select \"Run all\" to install dependencies and initialize the system\n",
    "* Ensure you have your API keys ready for the LLM provider\n",
    "\n",
    "**Local Environment**\n",
    "* Ensure you have Python 3.8+ installed\n",
    "* Install dependencies by running the installation cell below\n",
    "* Set up your API keys as instructed in the initialization section\n",
    "\n",
    "**Prerequisites**\n",
    "* Python 3.8+\n",
    "* API key for OpenAI or Google Vertex AI\n",
    "* Basic familiarity with Jupyter notebooks\n",
    "\n",
    "</small>\n",
    "\n",
    "---\n",
    "\n",
    "### 📜 License\n",
    "\n",
    "<small>This project is licensed under the <b>MIT License</b></small>\n",
    "\n",
    "<small>\n",
    "<details>\n",
    "<summary>View License Text</summary>\n",
    "MIT License<br><br>\n",
    "Copyright (c) 2023-2024 Aavishkar.ai<br><br>\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:<br><br>\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "</details>\n",
    "</small>\n",
    "\n",
    "<small>\n",
    "\n",
    "### 🔗 Connect with Aavishkar.ai\n",
    "* 📦 **GitHub**: [github.com/astitvac/AI4Science](https://github.com/astitvac/AI4Science)\n",
    "* 🌐 **Website**: [aavishkar.ai](https://aavishkar.ai)\n",
    "* 💬 **Community**: [Discord](https://discord.gg/aavishkar)\n",
    "* 🤝 **Contribute**: [Contribution Guidelines](https://github.com/astitvac/AI4Science/tree/main/Contributing)\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️ Installation\n",
    "<small>\n",
    "This cell installs all required dependencies for this expert system notebook. The installation process uses uv for faster package management when available, with automatic fallback to standard pip.\n",
    "Key components being installed:\n",
    "LLM frameworks: LangChain and provider-specific libraries\n",
    "Data modeling: Pydantic\n",
    "UI: Gradio\n",
    "Core utilities: Data processing and visualization libraries\n",
    "Troubleshooting tips:\n",
    "If you encounter errors, try running the cell again\n",
    "For persistent issues, check your Python version (3.8+ required)\n",
    "In Colab, restart the runtime if packages aren't recognized after installation\n",
    "Note: Initial installation may take 1-2 minutes to complete. A confirmation message will appear when successful.\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "import sys, os, subprocess, time\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# All required packages (no version constraints for better future-proofing)\n",
    "ALL_PACKAGES = {\n",
    "    \"core\": \"langchain pydantic python-dotenv\",\n",
    "    \"providers\": \"langchain-openai langchain-google-vertexai\",\n",
    "    \"ui\": \"gradio\",\n",
    "    \"data\": \"numpy pandas matplotlib plotly\",\n",
    "    \"documents\": \"PyPDF2 pillow\",\n",
    "    \"vectors\": \"chromadb sentence-transformers\"\n",
    "}\n",
    "\n",
    "# Environment detection\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "def show(msg, type=\"info\"):\n",
    "    \"\"\"Display styled message\"\"\"\n",
    "    colors = {\"info\": \"#3a7bd5\", \"success\": \"#00c853\", \"warning\": \"#f57c00\", \"error\": \"#d50000\"}\n",
    "    icons = {\"info\": \"ℹ️\", \"success\": \"✅\", \"warning\": \"⚠️\", \"error\": \"❌\"}\n",
    "    display(HTML(f\"<div style='color:white; background:{colors[type]}; padding:5px; margin:2px 0; border-radius:3px'>{icons[type]} {msg}</div>\"))\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install all packages using uv when possible, with minimal messaging\"\"\"\n",
    "    start = time.time()\n",
    "    show(\"Starting installation...\", \"info\")\n",
    "    \n",
    "    # Try to use uv for faster installation\n",
    "    try:\n",
    "        subprocess.run(\"pip install -q uv\", shell=True, check=True, timeout=30)\n",
    "        installer = \"uv pip\"\n",
    "    except:\n",
    "        installer = \"pip\"\n",
    "    \n",
    "    # Install each category\n",
    "    success_count = 0\n",
    "    total_categories = len(ALL_PACKAGES)\n",
    "    \n",
    "    for category, packages in ALL_PACKAGES.items():\n",
    "        try:\n",
    "            # Install entire category at once for speed\n",
    "            cmd = f\"{installer} install -q {packages}\"\n",
    "            result = subprocess.run(cmd, shell=True, capture_output=True, timeout=120)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                success_count += 1\n",
    "        except Exception:\n",
    "            pass  # Silent failure, will be reflected in final success rate\n",
    "    \n",
    "    # Simple verification of core packages\n",
    "    try:\n",
    "        import langchain\n",
    "        import pydantic\n",
    "        import gradio\n",
    "        verification = \"with verification\"\n",
    "    except ImportError:\n",
    "        verification = \"with partial verification failures\"\n",
    "    \n",
    "    # Single completion message with success rate\n",
    "    elapsed = time.time() - start\n",
    "    success_rate = int((success_count / total_categories) * 100)\n",
    "    show(f\"Installation completed in {elapsed:.1f}s ({success_rate}% success) {verification}\", \n",
    "         \"success\" if success_rate > 80 else \"warning\")\n",
    "    \n",
    "    return success_rate > 80\n",
    "\n",
    "# Run installation\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Initialization\n",
    "\n",
    "<small>This section configures the LLM provider, API keys, and core components needed for this expert system. The implementation follows a modular architecture that supports multiple AI providers and environments.</small>\n",
    "\n",
    "## Purpose\n",
    "\n",
    "<small>The initialization process:\n",
    "1. **Sets up environment variables** including API keys\n",
    "2. **Configures the LLM provider** with appropriate models and settings\n",
    "3. **Initializes specialized capabilities** when needed (e.g., vision, embedding)\n",
    "4. **Validates the environment** to ensure all requirements are met\n",
    "</small>\n",
    "\n",
    "## Configuration Options\n",
    "\n",
    "<small>\n",
    "You can customize the initialization by adjusting these parameters:\n",
    "\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| **Provider** | AI service to use (OpenAI, Google, etc.) | OpenAI |\n",
    "| **Model** | Specific model name | Depends on provider |\n",
    "| **Temperature** | Creativity level (0.0-1.0) | 0.7 |\n",
    "| **Features** | Additional capabilities to enable | None |\n",
    "\n",
    "**💡 Tip**: For reproducible results, use lower temperature values (0.0-0.3).\n",
    "</small>\n",
    "\n",
    "## Provider Support\n",
    "\n",
    "<small>\n",
    "This notebook supports these LLM providers:\n",
    "\n",
    "- **OpenAI**: GPT-4, GPT-3.5-Turbo\n",
    "- **Google**: Gemini Pro, PaLM\n",
    "- **Anthropic**: Claude (optional)\n",
    "- **Local**: Ollama with various models (optional)\n",
    "\n",
    "**Note**: Different providers may have varying capabilities and pricing structures.\n",
    "</small>\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "<small>\n",
    "**For Google Colab:**\n",
    "1. Store your API keys in Colab Secrets\n",
    "2. Select your provider from the dropdown\n",
    "3. Run the initialization cell\n",
    "\n",
    "**For Local Environment:**\n",
    "1. Create a `.env` file with your API keys\n",
    "2. Select your provider\n",
    "3. Run the initialization cell\n",
    "\n",
    "**API Key Variables:**\n",
    "- OpenAI: `OPENAI_API_KEY`\n",
    "- Google: `GOOGLE_API_KEY`\n",
    "- Anthropic: `ANTHROPIC_API_KEY`\n",
    "</small>\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "<small>\n",
    "Common issues:\n",
    "- **Authentication errors**: Check your API key is correctly set\n",
    "- **Model unavailability**: Ensure you have access to the specified model\n",
    "- **Import errors**: Run the installation cell first\n",
    "- **Memory issues**: Select a smaller model or reduce context length\n",
    "\n",
    "The initialization cell includes diagnostics that will help identify any configuration problems.\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔧 LLM Setup\n",
    "import os, sys\n",
    "from IPython.display import Markdown, display\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "\n",
    "# Colab form fields for configuration\n",
    "# @title LLM Configuration\n",
    "api_key = \"\" # @param {type:\"string\"}\n",
    "model = \"gpt-4o\" # @param [\"gpt-4o\", \"gpt-4-turbo\", \"gpt-4\", \"gpt-3.5-turbo\"]\n",
    "embedding_model = \"text-embedding-3-small\" # @param [\"text-embedding-3-small\", \"text-embedding-3-large\", \"text-embedding-ada-002\"]\n",
    "temperature = 0.7 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "debug = True # @param {type:\"boolean\"}\n",
    "\n",
    "# Environment detection\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "def show(msg, type=\"info\"):\n",
    "    \"\"\"Display styled message\"\"\"\n",
    "    if type == \"debug\" and not debug:\n",
    "        return\n",
    "    colors = {\"success\": \"#00C853\", \"info\": \"#2196F3\", \"warning\": \"#FF9800\", \"error\": \"#F44336\", \"debug\": \"#9C27B0\"}\n",
    "    icons = {\"success\": \"✅\", \"info\": \"ℹ️\", \"warning\": \"⚠️\", \"error\": \"❌\", \"debug\": \"🔍\"}\n",
    "    display(Markdown(f\"<div style='padding:8px;border-radius:4px;background:{colors[type]};color:white'>{icons[type]} {msg}</div>\"))\n",
    "\n",
    "def get_api_key() -> Optional[str]:\n",
    "    \"\"\"Get API key from various possible sources\"\"\"\n",
    "    # Check form input first\n",
    "    key = api_key\n",
    "    \n",
    "    # Try Colab secret if empty and in Colab\n",
    "    if not key and IN_COLAB:\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            key = userdata.get('openai_api_key')\n",
    "            if key:\n",
    "                show(\"API key loaded from Colab secret\", \"success\")\n",
    "        except Exception as e:\n",
    "            show(f\"Error accessing Colab secrets: {e}\", \"debug\")\n",
    "    \n",
    "    # Try environment variable\n",
    "    if not key:\n",
    "        key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "        if key:\n",
    "            show(\"API key loaded from environment variable\", \"debug\")\n",
    "    \n",
    "    # Try .env file\n",
    "    if not key:\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "            key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "            if key:\n",
    "                show(\"API key loaded from .env file\", \"debug\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Final check and request if needed\n",
    "    if not key:\n",
    "        if IN_COLAB:\n",
    "            show(\"\"\"\n",
    "            No API key found. Either:\n",
    "            1. Add it in the form field above\n",
    "            2. Set a Colab secret named 'openai_api_key'\n",
    "            \"\"\", \"warning\")\n",
    "        else:\n",
    "            show(\"No API key found. Add it in the form field or set OPENAI_API_KEY environment variable\", \"warning\")\n",
    "        return None\n",
    "        \n",
    "    return key\n",
    "\n",
    "# === PROVIDER-SPECIFIC: OPENAI ===\n",
    "def initialize_models(api_key: str) -> Tuple[Optional[Any], Optional[Any]]:\n",
    "    \"\"\"Initialize OpenAI models with the provided API key\"\"\"\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    \n",
    "    # Set environment variable for consistency\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    \n",
    "    try:\n",
    "        llm = ChatOpenAI(\n",
    "            model_name=model,\n",
    "            temperature=temperature,\n",
    "            openai_api_key=api_key\n",
    "        )\n",
    "        \n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=embedding_model,\n",
    "            openai_api_key=api_key\n",
    "        )\n",
    "        \n",
    "        show(f\"OpenAI initialized with {model} and {embedding_model}\", \"success\")\n",
    "        return llm, embeddings\n",
    "        \n",
    "    except Exception as e:\n",
    "        show(f\"Error initializing OpenAI: {e}\", \"error\")\n",
    "        return None, None\n",
    "# === END PROVIDER-SPECIFIC ===\n",
    "\n",
    "def initialize_llm() -> Tuple[Optional[Any], Optional[Any]]:\n",
    "    \"\"\"Main function to set up and initialize LLM\"\"\"\n",
    "    show(\"Initializing LLM...\", \"info\")\n",
    "    \n",
    "    # Get API key\n",
    "    key = get_api_key()\n",
    "    if not key:\n",
    "        return None, None\n",
    "    \n",
    "    # Initialize models\n",
    "    llm, embeddings = initialize_models(key)\n",
    "    \n",
    "    if llm and embeddings:\n",
    "        show(\"Initialization complete! LLM and embeddings ready to use.\", \"success\")\n",
    "    \n",
    "    return llm, embeddings\n",
    "\n",
    "# Run initialization\n",
    "llm, embeddings = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ Core Utilities\n",
    "\"\"\"\n",
    "Core utilities for Aavishkar.ai expert systems.\n",
    "Includes logging, caching, error handling, and JSON parsing.\n",
    "\"\"\"\n",
    "\n",
    "import os, json, time, hashlib, functools\n",
    "from typing import Dict, Any, Optional, Callable, Union\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# === GLOBAL SETTINGS ===\n",
    "DEBUG_MODE = False\n",
    "CACHE_ENABLED = True\n",
    "CACHE_DIR = \"./cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# === DISPLAY & ERROR HANDLING ===\n",
    "def show(msg: str, level: str = \"info\") -> None:\n",
    "    \"\"\"Display formatted message with appropriate styling.\n",
    "    \n",
    "    Args:\n",
    "        msg: Message to display\n",
    "        level: Message level (success, info, warning, error, debug)\n",
    "    \"\"\"\n",
    "    colors = {\"success\": \"#00C853\", \"info\": \"#2196F3\", \"warning\": \"#FF9800\", \"error\": \"#F44336\", \"debug\": \"#9C27B0\"}\n",
    "    icons = {\"success\": \"✅\", \"info\": \"ℹ️\", \"warning\": \"⚠️\", \"error\": \"❌\", \"debug\": \"🔍\"}\n",
    "    \n",
    "    if level == \"debug\" and not DEBUG_MODE:\n",
    "        return\n",
    "        \n",
    "    color = colors.get(level, colors[\"info\"])\n",
    "    icon = icons.get(level, icons[\"info\"])\n",
    "    display(Markdown(f\"<div style='padding:6px;border-radius:4px;background:{color};color:white'>{icon} {msg}</div>\"))\n",
    "\n",
    "def retry(max_attempts: int = 3, delay: float = 1.0) -> Callable:\n",
    "    \"\"\"Decorator for retrying functions with exponential backoff.\"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for attempt in range(1, max_attempts + 1):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    if attempt == max_attempts:\n",
    "                        raise\n",
    "                    wait = delay * (2 ** (attempt - 1))\n",
    "                    show(f\"Attempt {attempt} failed: {str(e)}. Retrying in {wait:.1f}s...\", \"warning\")\n",
    "                    time.sleep(wait)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# === CACHE SYSTEM ===\n",
    "def cache_key(**kwargs) -> str:\n",
    "    \"\"\"Generate a cache key from input parameters.\"\"\"\n",
    "    serialized = json.dumps({k: v for k, v in kwargs.items() if v is not None}, sort_keys=True)\n",
    "    return hashlib.md5(serialized.encode()).hexdigest()\n",
    "\n",
    "def get_cache(key: str) -> Optional[Any]:\n",
    "    \"\"\"Get item from cache if available and not expired.\"\"\"\n",
    "    if not CACHE_ENABLED:\n",
    "        return None\n",
    "        \n",
    "    path = os.path.join(CACHE_DIR, f\"{key}.json\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Check if expired (default: 1 day)\n",
    "        if time.time() - data.get(\"timestamp\", 0) > 86400:\n",
    "            return None\n",
    "            \n",
    "        return data.get(\"value\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def set_cache(key, value):\n",
    "    \"\"\"Store value in cache with current timestamp.\"\"\"\n",
    "    if not CACHE_ENABLED:\n",
    "        return\n",
    "        \n",
    "    path = os.path.join(CACHE_DIR, f\"{key}.json\")\n",
    "    try:\n",
    "        # Handle Pydantic models by converting to dictionaries\n",
    "        def serialize_pydantic(obj):\n",
    "            if hasattr(obj, 'model_dump'):  # Pydantic v2 models use model_dump\n",
    "                return obj.model_dump()\n",
    "            elif hasattr(obj, 'dict'):      # Older Pydantic models use dict()\n",
    "                return obj.dict()\n",
    "            elif isinstance(obj, list):\n",
    "                return [serialize_pydantic(item) for item in obj]\n",
    "            elif isinstance(obj, dict):\n",
    "                return {k: serialize_pydantic(v) for k, v in obj.items()}\n",
    "            return obj\n",
    "            \n",
    "        serialized_value = serialize_pydantic(value)\n",
    "        \n",
    "        with open(path, 'w') as f:\n",
    "            json.dump({\"timestamp\": time.time(), \"value\": serialized_value}, f)\n",
    "            \n",
    "    except Exception as e:\n",
    "        show(f\"Cache write error: {str(e)}\", \"debug\")\n",
    "\n",
    "def clear_cache(older_than: Optional[int] = None) -> int:\n",
    "    \"\"\"Clear cache entries, optionally only those older than specified seconds.\n",
    "    \n",
    "    Returns:\n",
    "        Number of entries cleared\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CACHE_DIR):\n",
    "        return 0\n",
    "        \n",
    "    count = 0\n",
    "    for filename in os.listdir(CACHE_DIR):\n",
    "        if not filename.endswith('.json'):\n",
    "            continue\n",
    "            \n",
    "        path = os.path.join(CACHE_DIR, filename)\n",
    "        \n",
    "        if older_than:\n",
    "            try:\n",
    "                with open(path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                if time.time() - data.get(\"timestamp\", 0) <= older_than:\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            os.remove(path)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return count\n",
    "\n",
    "# === LLM & JSON HELPERS ===\n",
    "def call_llm_with_cache(llm, prompt: str, **kwargs) -> Any:\n",
    "    \"\"\"Call LLM with caching to avoid redundant API calls.\"\"\"\n",
    "    if CACHE_ENABLED:\n",
    "        key = cache_key(prompt=prompt, **kwargs)\n",
    "        cached = get_cache(key)\n",
    "        if cached:\n",
    "            show(\"Using cached response\", \"debug\")\n",
    "            return cached\n",
    "    \n",
    "    response = llm.invoke(prompt, **kwargs)\n",
    "    \n",
    "    if CACHE_ENABLED:\n",
    "        set_cache(key, response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "def parse_json_safely(text: str, default: Any = None) -> Any:\n",
    "    \"\"\"Extract and parse JSON from text with multiple fallback strategies.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Try direct parsing first\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try to extract JSON blocks\n",
    "    try:\n",
    "        # Try code blocks with JSON\n",
    "        if \"```json\" in text:\n",
    "            json_block = text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "            return json.loads(json_block)\n",
    "            \n",
    "        # Try any code blocks\n",
    "        if \"```\" in text:\n",
    "            code_block = text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "            if code_block.strip().startswith((\"{\", \"[\")):\n",
    "                return json.loads(code_block)\n",
    "        \n",
    "        # Try regex patterns for JSON objects/arrays\n",
    "        patterns = [\n",
    "            r'\\{[\\s\\S]*?\\}',  # JSON objects\n",
    "            r'\\[[\\s\\S]*?\\]'   # JSON arrays\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    return json.loads(match)\n",
    "                except:\n",
    "                    continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return default\n",
    "\n",
    "# Initialization\n",
    "show(\"Core utilities initialized\", \"debug\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Literature Synthesis: Single Document Analysis\n",
    "\n",
    "## Purpose\n",
    "Extracts structured knowledge from individual scientific papers to facilitate comprehension and identify research opportunities.\n",
    "\n",
    "## Core Functions\n",
    "\n",
    "* **Information Extraction**\n",
    "  * Identifies key concepts, methods, findings, and claims\n",
    "  * Extracts experimental parameters and statistical results\n",
    "  * Maps cited literature references\n",
    "\n",
    "* **Knowledge Structure**\n",
    "  * Creates concept hierarchies and relationships\n",
    "  * Links methods to findings with evidence strength\n",
    "  * Generates machine-readable knowledge representation\n",
    "\n",
    "* **Research Gap Detection**\n",
    "  * Identifies limitations acknowledged by authors\n",
    "  * Highlights unanswered questions\n",
    "  * Suggests logical extensions to the work\n",
    "\n",
    "* **Visualization**\n",
    "  * Generates concept relationship networks\n",
    "  * Creates hierarchical representation of findings\n",
    "  * Supports interactive exploration\n",
    "\n",
    "## Input\n",
    "\n",
    "* PDF upload, plain text, DOI, or ArXiv ID\n",
    "* Best results with complete papers containing clear section structure\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Run setup cells (installation and initialization)\n",
    "2. Upload or identify a single scientific paper\n",
    "3. Review the extracted knowledge structure\n",
    "\n",
    "**Note**: This single-document analyzer precedes multi-document synthesis capabilities.\n",
    "\n",
    "---\n",
    "\n",
    "*Implementation of the Literature Synthesist cognitive archetype from Aavishkar.ai*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models\n",
    "\n",
    "## Purpose\n",
    "\n",
    "<small>\n",
    "This section defines the structured data representations that power our Literature Synthesis system. These Pydantic models perform two essential functions:\n",
    "\n",
    "1. **Represent Knowledge**: Define how scientific concepts, relationships, and documents are structured\n",
    "2. **Control System Behavior**: Configure how the system processes and analyzes content\n",
    "</small>\n",
    "\n",
    "## How It Works\n",
    "\n",
    "<small>\n",
    "Our system uses Pydantic models to ensure data validation and clear structure. Think of these models as \"smart containers\" that:\n",
    "\n",
    "- Validate data to prevent errors\n",
    "- Provide helpful error messages when something is wrong\n",
    "- Include documentation for each field\n",
    "- Support extensibility for specialized needs\n",
    "</small>\n",
    "\n",
    "## Core Models\n",
    "\n",
    "<small>\n",
    "Our implementation uses these key models:\n",
    "\n",
    "| Model | Purpose |\n",
    "|-------|---------|\n",
    "| **LitSynthConfig** | Consolidated configuration for all system parameters |\n",
    "| **Concept** | Scientific concepts extracted from literature |\n",
    "| **Relationship** | Connections between scientific concepts |\n",
    "| **ResearchGap** | Identified research gaps and opportunities |\n",
    "| **LiteratureSynthesisOutput** | Complete analysis results container |\n",
    "\n",
    "We've simplified the configuration into a single model (`LitSynthConfig`) to make customization easier. You can adjust parameters by modifying the `config` variable in the code cell.\n",
    "</small>\n",
    "\n",
    "## Customization\n",
    "\n",
    "<small>\n",
    "To customize the system behavior, simply modify the config variable:\n",
    "\n",
    "```python\n",
    "# Example: Increase sensitivity to detect more concepts\n",
    "config.extraction_confidence = 0.6\n",
    "config.max_concepts = 40\n",
    "\n",
    "# Example: Focus only on high-importance concepts\n",
    "config.min_concept_importance = \"high\"\n",
    "```\n",
    "\n",
    "This approach allows you to tune the system's behavior without changing the core models or implementation.\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 Data Models\n",
    "\"\"\"\n",
    "This section defines the data structures used throughout the Literature Synthesis system.\n",
    "You can customize these models to better match your scientific domain or analysis needs.\n",
    "\n",
    "CUSTOMIZATION TIPS:\n",
    "1. Update field descriptions to match your domain terminology\n",
    "2. Adjust default values to better suit your analysis preferences\n",
    "3. Add domain-specific fields to capture additional information\n",
    "4. Modify validators to enforce domain-specific rules\n",
    "\n",
    "Each model includes validators to ensure data integrity.\n",
    "\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List, Dict, Optional, Literal, Any\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def show_info(message):\n",
    "    \"\"\"Display styled info message.\"\"\"\n",
    "    display(Markdown(f\"<div style='padding:5px;border-radius:3px;background:#2196F3;color:white'>ℹ️ {message}</div>\"))\n",
    "\n",
    "# ===== INPUT MODELS =====\n",
    "# Models for document input and configuration\n",
    "\n",
    "class DocumentSource(BaseModel):\n",
    "    \"\"\"Input document source with type and content.\n",
    "    \n",
    "    This model represents an input document to be analyzed.\n",
    "    It supports multiple source types and includes metadata.\n",
    "    \n",
    "    Attributes:\n",
    "        source_type: The type of document source (pdf, text, etc.)\n",
    "        content: The document content or file path\n",
    "        metadata: Additional information about the document\n",
    "    \"\"\"\n",
    "    source_type: Literal[\"pdf\", \"text\", \"url\", \"doi\", \"arxiv\"]\n",
    "    content: str\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "    \n",
    "    # You can add custom validation methods here if needed\n",
    "    # Example:\n",
    "    # @field_validator('content')\n",
    "    # @classmethod\n",
    "    # def validate_content(cls, v):\n",
    "    #     if len(v) < 10:  # Enforce minimum content length\n",
    "    #         raise ValueError(\"Document content too short\")\n",
    "    #     return v\n",
    "\n",
    "# ===== KNOWLEDGE REPRESENTATION MODELS =====\n",
    "# Models for representing extracted knowledge\n",
    "\n",
    "class Concept(BaseModel):\n",
    "    \"\"\"Scientific concept extracted from literature.\n",
    "    \n",
    "    This model represents a key scientific concept identified in the text.\n",
    "    Each concept has a name, definition, and importance rating.\n",
    "    \n",
    "    Customization:\n",
    "    - Add domain-specific concept types\n",
    "    - Adjust default importance level\n",
    "    - Add additional fields for your domain\n",
    "    \n",
    "    Attributes:\n",
    "        name: The concept name or term\n",
    "        definition: Clear definition of the concept\n",
    "        importance: How important this concept is (high, medium, low)\n",
    "        concept_type: Classification of the concept (term, method, theory, etc.)\n",
    "        sources: List of sources where concept was found\n",
    "        related_terms: List of related concepts\n",
    "        confidence: Confidence score for extraction (0-1)\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    definition: str\n",
    "    importance: Literal[\"high\", \"medium\", \"low\"] = \"medium\"\n",
    "    concept_type: str = \"term\"\n",
    "    sources: List[str] = Field(default_factory=list)\n",
    "    related_terms: List[str] = Field(default_factory=list)\n",
    "    confidence: float = Field(default=0.8, ge=0.0, le=1.0)\n",
    "    \n",
    "    # Example custom validator (commented out)\n",
    "    # @field_validator('name')\n",
    "    # @classmethod\n",
    "    # def normalize_name(cls, v):\n",
    "    #     \"\"\"Normalize concept names to title case\"\"\"\n",
    "    #     return v.strip().title()\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    \"\"\"Connection between scientific concepts.\n",
    "    \n",
    "    This model represents how concepts relate to each other in the text.\n",
    "    Each relationship connects two concepts with a specific relationship type.\n",
    "    \n",
    "    Customization:\n",
    "    - Add domain-specific relationship types\n",
    "    - Adjust confidence thresholds\n",
    "    - Add fields for relationship strength or context\n",
    "    \n",
    "    Attributes:\n",
    "        source: The source concept name\n",
    "        target: The target concept name\n",
    "        relationship_type: Type of relationship (causes, influences, etc.)\n",
    "        evidence: Text evidence supporting this relationship\n",
    "        confidence: Confidence score for extraction (0-1)\n",
    "        bidirectional: Whether the relationship applies in both directions\n",
    "    \"\"\"\n",
    "    source: str\n",
    "    target: str\n",
    "    relationship_type: str\n",
    "    evidence: Optional[str] = None\n",
    "    confidence: float = Field(default=0.7, ge=0.0, le=1.0)\n",
    "    bidirectional: bool = False\n",
    "    \n",
    "    # Example of domain-specific validation (uncomment and customize)\n",
    "    # @field_validator('relationship_type')\n",
    "    # @classmethod\n",
    "    # def validate_relationship_type(cls, v):\n",
    "    #     \"\"\"Validate relationship types match domain expectations\"\"\"\n",
    "    #     valid_types = [\"causes\", \"influences\", \"measures\", \"contains\", \"precedes\"]\n",
    "    #     if v.lower() not in valid_types:\n",
    "    #         raise ValueError(f\"Relationship type must be one of: {', '.join(valid_types)}\")\n",
    "    #     return v\n",
    "\n",
    "class ResearchGap(BaseModel):\n",
    "    \"\"\"Identified research gap or opportunity.\n",
    "    \n",
    "    This model represents potential areas for future research,\n",
    "    based on limitations or unexplored connections in the literature.\n",
    "    \n",
    "    Customization:\n",
    "    - Adjust importance criteria\n",
    "    - Add fields for research difficulty or potential impact\n",
    "    - Add categorization for types of research gaps\n",
    "    \n",
    "    Attributes:\n",
    "        description: Clear description of the research gap\n",
    "        related_concepts: List of concepts related to this gap\n",
    "        evidence: Text evidence supporting this gap\n",
    "        importance: How significant this gap is (high, medium, low)\n",
    "        confidence: Confidence score for extraction (0-1)\n",
    "    \"\"\"\n",
    "    description: str\n",
    "    related_concepts: List[str] = Field(default_factory=list)\n",
    "    evidence: Optional[str] = None\n",
    "    importance: Literal[\"high\", \"medium\", \"low\"] = \"medium\"\n",
    "    confidence: float = Field(default=0.7, ge=0.0, le=1.0)\n",
    "\n",
    "class LiteratureSynthesisOutput(BaseModel):\n",
    "    \"\"\"Complete output from literature synthesis process.\n",
    "    \n",
    "    This model represents the complete results of analyzing a document,\n",
    "    including concepts, relationships, research gaps, and a synthesis.\n",
    "    \n",
    "    Customization:\n",
    "    - Add domain-specific metadata fields\n",
    "    - Add fields for additional analysis artifacts\n",
    "    \n",
    "    Attributes:\n",
    "        document_id: Unique identifier for the document\n",
    "        document_metadata: Additional information about the document\n",
    "        concepts: List of extracted concepts\n",
    "        relationships: List of identified relationships\n",
    "        research_gaps: List of potential research gaps\n",
    "        synthesis_text: Comprehensive synthesis text\n",
    "        timestamp: When the analysis was performed\n",
    "    \"\"\"\n",
    "    document_id: str\n",
    "    document_metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "    concepts: List[Concept] = Field(default_factory=list)\n",
    "    relationships: List[Relationship] = Field(default_factory=list)\n",
    "    research_gaps: List[ResearchGap] = Field(default_factory=list)\n",
    "    synthesis_text: Optional[str] = None\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "    \n",
    "    # You could add methods for analyzing results\n",
    "    # Example:\n",
    "    # def get_central_concepts(self, top_n=5):\n",
    "    #     \"\"\"Return the most connected concepts\"\"\"\n",
    "    #     concept_connections = {}\n",
    "    #     for rel in self.relationships:\n",
    "    #         concept_connections[rel.source] = concept_connections.get(rel.source, 0) + 1\n",
    "    #         concept_connections[rel.target] = concept_connections.get(rel.target, 0) + 1\n",
    "    #     \n",
    "    #     return sorted(concept_connections.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# ===== CONFIGURATION MODEL =====\n",
    "# Controls system behavior and processing parameters\n",
    "\n",
    "class LitSynthConfig(BaseModel):\n",
    "    \"\"\"Configuration for the Literature Synthesis system.\n",
    "    \n",
    "    This model controls how the system processes and analyzes documents.\n",
    "    Adjust these parameters to customize the analysis for your needs.\n",
    "    \n",
    "    Customization Tips:\n",
    "    - Increase chunk size for more context (but slower processing)\n",
    "    - Adjust confidence thresholds based on LLM quality\n",
    "    - Set your scientific domain for more targeted analysis\n",
    "    - Update max counts based on document size and complexity\n",
    "    \n",
    "    Attributes:\n",
    "        text_chunk_size: Characters per text chunk for processing\n",
    "        text_chunk_overlap: Overlap between chunks to maintain context\n",
    "        min_concept_importance: Minimum importance level to include\n",
    "        extraction_confidence: Minimum confidence for concept extraction\n",
    "        max_concepts: Maximum concepts to extract\n",
    "        relationship_confidence: Minimum confidence for relationships\n",
    "        max_relationships: Maximum relationships to extract\n",
    "        scientific_domain: Optional domain specialization\n",
    "    \"\"\"\n",
    "    # Text Processing Parameters\n",
    "    text_chunk_size: int = Field(\n",
    "        default=2000, ge=500, le=8000, \n",
    "        description=\"Characters per text chunk\"\n",
    "    )\n",
    "    text_chunk_overlap: int = Field(\n",
    "        default=200, ge=50, le=1000,\n",
    "        description=\"Overlap between chunks\"\n",
    "    )\n",
    "    \n",
    "    # Concept Extraction Parameters\n",
    "    min_concept_importance: Literal[\"low\", \"medium\", \"high\"] = Field(\n",
    "        default=\"medium\", \n",
    "        description=\"Minimum importance level to include\"\n",
    "    )\n",
    "    extraction_confidence: float = Field(\n",
    "        default=0.7, ge=0.0, le=1.0,\n",
    "        description=\"Minimum extraction confidence\"\n",
    "    )\n",
    "    max_concepts: int = Field(\n",
    "        default=25, ge=5, le=100,\n",
    "        description=\"Maximum concepts to extract\"\n",
    "    )\n",
    "    \n",
    "    # Relationship Parameters\n",
    "    relationship_confidence: float = Field(\n",
    "        default=0.6, ge=0.0, le=1.0,\n",
    "        description=\"Minimum relationship confidence\"\n",
    "    )\n",
    "    max_relationships: int = Field(\n",
    "        default=50, ge=10, le=200,\n",
    "        description=\"Maximum relationships to extract\"\n",
    "    )\n",
    "    \n",
    "    # Customization\n",
    "    scientific_domain: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Scientific domain for specialized analysis\"\n",
    "    )\n",
    "    \n",
    "    @field_validator('text_chunk_overlap')\n",
    "    @classmethod\n",
    "    def validate_overlap(cls, v, info):\n",
    "        \"\"\"Ensure overlap is less than chunk size.\"\"\"\n",
    "        if 'text_chunk_size' in info.data and v >= info.data['text_chunk_size']:\n",
    "            raise ValueError(\"text_chunk_overlap must be less than text_chunk_size\")\n",
    "        return v\n",
    "        \n",
    "    @field_validator('min_concept_importance')\n",
    "    @classmethod\n",
    "    def validate_importance(cls, v):\n",
    "        \"\"\"Validate importance level values.\"\"\"\n",
    "        valid_levels = [\"low\", \"medium\", \"high\"]\n",
    "        if v not in valid_levels:\n",
    "            raise ValueError(f\"min_concept_importance must be one of {valid_levels}\")\n",
    "        return v\n",
    "    \n",
    "    # You can add domain-specific validation here\n",
    "    # Example:\n",
    "    # @field_validator('scientific_domain')\n",
    "    # @classmethod\n",
    "    # def validate_domain(cls, v):\n",
    "    #     \"\"\"Validate scientific domain if provided.\"\"\"\n",
    "    #     if v is not None:\n",
    "    #         valid_domains = [\"biology\", \"chemistry\", \"physics\", \"computer science\", \"medicine\"]\n",
    "    #         if v.lower() not in valid_domains:\n",
    "    #             raise ValueError(f\"Domain must be one of: {', '.join(valid_domains)}\")\n",
    "    #     return v\n",
    "\n",
    "# Initialize default configuration\n",
    "config = LitSynthConfig()\n",
    "\n",
    "# Example of how to customize for a specific domain (commented out)\n",
    "\"\"\"\n",
    "# Customize for biology papers\n",
    "bio_config = LitSynthConfig(\n",
    "    text_chunk_size=3000,  # Longer chunks for biological context\n",
    "    scientific_domain=\"biology\",\n",
    "    max_concepts=40,  # Biology papers often have more terms\n",
    "    relationship_confidence=0.65  # Slightly higher threshold\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Show confirmation\n",
    "show_info(\"Data models configured successfully - feel free to customize them for your scientific domain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "\n",
    "<small>\n",
    "This section contains the heart of our Literature Synthesis system - the functions that analyze documents, extract key information, and generate insights.\n",
    "\n",
    "## What's Included\n",
    "\n",
    "1. **Prompt Library**: The instructions we give to the AI model\n",
    "2. **Function Definitions**: The code that processes documents and manages the analysis\n",
    "\n",
    "## How to Customize\n",
    "\n",
    "You can easily modify the system's behavior by:\n",
    "\n",
    "- **Changing prompts**: Edit the instructions to focus on specific types of information\n",
    "- **Adjusting parameters**: Fine-tune the analysis by modifying the `config` settings\n",
    "\n",
    "No coding knowledge is required - simply edit the text of prompts in the first code cell below.\n",
    "</small>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📖 Prompt Library\n",
    "\"\"\"\n",
    "This section contains all prompts used by the system.\n",
    "You can safely modify these prompts to customize how the AI analyzes your documents.\n",
    "Each prompt includes clear instructions for the AI and expected output format.\n",
    "\n",
    "CUSTOMIZATION TIPS:\n",
    "1. Keep the output format instructions intact (especially for JSON responses)\n",
    "2. Feel free to add domain-specific instructions or examples\n",
    "3. You can emphasize certain aspects by adding more detailed instructions\n",
    "4. Test your changes with small documents first\n",
    "\"\"\"\n",
    "\n",
    "PROMPTS = {\n",
    "    # === CONCEPT EXTRACTION ===\n",
    "    # Purpose: Extract scientific concepts with definitions and importance\n",
    "    # Output: List of concept objects\n",
    "    \"concept_extraction\": \"\"\"\n",
    "    You are a scientific knowledge extraction expert. Extract the key scientific concepts \n",
    "    from the following text.\n",
    "    \n",
    "    TEXT:\n",
    "    {text}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Identify main scientific concepts, terms, and ideas\n",
    "    2. Provide clear definitions for each concept\n",
    "    3. Rate importance as \"high\", \"medium\", or \"low\"\n",
    "    4. Focus on domain-specific terminology\n",
    "    \n",
    "    Return ONLY a JSON array of concepts with this structure:\n",
    "    ```json\n",
    "    [\n",
    "      {{\n",
    "        \"name\": \"Concept name\",\n",
    "        \"definition\": \"Clear definition of the concept\",\n",
    "        \"importance\": \"high|medium|low\",\n",
    "        \"concept_type\": \"term|method|theory|etc\"\n",
    "      }}\n",
    "    ]\n",
    "    ```\n",
    "    \n",
    "    CONFIG PARAMETERS:\n",
    "    {config}\n",
    "    \"\"\",\n",
    "    \n",
    "    # === RELATIONSHIP MAPPING ===\n",
    "    # Purpose: Identify how concepts relate to each other\n",
    "    # Output: List of relationship objects\n",
    "    \"relationship_mapping\": \"\"\"\n",
    "    You are a scientific knowledge graph expert. Identify relationships between the \n",
    "    following scientific concepts.\n",
    "    \n",
    "    TEXT:\n",
    "    {text}\n",
    "    \n",
    "    CONCEPTS:\n",
    "    {concepts}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Analyze how concepts relate to each other in the text\n",
    "    2. Identify specific relationship types (causes, influences, measures, etc.)\n",
    "    3. Only include relationships with evidence in the text\n",
    "    4. Assign confidence scores based on clarity of evidence\n",
    "    \n",
    "    Return ONLY a JSON array of relationships with this structure:\n",
    "    ```json\n",
    "    [\n",
    "      {{\n",
    "        \"source\": \"Source concept name\",\n",
    "        \"target\": \"Target concept name\",\n",
    "        \"relationship_type\": \"Specific type of relationship\",\n",
    "        \"evidence\": \"Brief evidence from text\",\n",
    "        \"confidence\": 0.8\n",
    "      }}\n",
    "    ]\n",
    "    ```\n",
    "    \"\"\",\n",
    "    \n",
    "    # === RESEARCH GAP IDENTIFICATION ===\n",
    "    # Purpose: Identify potential research gaps or opportunities\n",
    "    # Output: List of research gap objects\n",
    "    \"research_gap\": \"\"\"\n",
    "    You are a research direction consultant. Identify potential research gaps based on \n",
    "    the following analysis.\n",
    "    \n",
    "    TEXT:\n",
    "    {text}\n",
    "    \n",
    "    CONCEPTS:\n",
    "    {concepts}\n",
    "    \n",
    "    RELATIONSHIPS:\n",
    "    {relationships}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Identify unexplored connections between concepts\n",
    "    2. Look for limitations mentioned in the text\n",
    "    3. Consider methodological gaps\n",
    "    4. Identify questions raised but not answered\n",
    "    \n",
    "    Return ONLY a JSON array of research gaps with this structure:\n",
    "    ```json\n",
    "    [\n",
    "      {{\n",
    "        \"description\": \"Clear description of the research gap\",\n",
    "        \"related_concepts\": [\"Concept1\", \"Concept2\"],\n",
    "        \"evidence\": \"Supporting evidence from text\",\n",
    "        \"importance\": \"high|medium|low\"\n",
    "      }}\n",
    "    ]\n",
    "    ```\n",
    "    \"\"\",\n",
    "    \n",
    "    # === SYNTHESIS GENERATION ===\n",
    "    # Purpose: Generate comprehensive synthesis of the analysis\n",
    "    # Output: Formatted text summary\n",
    "    \"synthesis_generation\": \"\"\"\n",
    "    You are a scientific research synthesizer. Create a comprehensive synthesis of the following analysis.\n",
    "    \n",
    "    TEXT EXTRACT:\n",
    "    {text}\n",
    "    \n",
    "    CONCEPTS:\n",
    "    {concepts}\n",
    "    \n",
    "    RELATIONSHIPS:\n",
    "    {relationships}\n",
    "    \n",
    "    RESEARCH GAPS:\n",
    "    {gaps}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    1. Summarize the key concepts and their relationships\n",
    "    2. Highlight the most important findings\n",
    "    3. Discuss potential research opportunities\n",
    "    4. Use clear, concise language suitable for researchers\n",
    "    \n",
    "    Format your response as markdown with sections for:\n",
    "    1. Overview\n",
    "    2. Key Concepts\n",
    "    3. Relationships & Patterns\n",
    "    4. Research Opportunities\n",
    "    5. Conclusion\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# You can customize prompts above to better suit your specific domain or preferences\n",
    "# The system will use these prompts when analyzing documents\n",
    "# Remember to keep the JSON output structure intact for structured data prompts\n",
    "\n",
    "show(\"Prompt library initialized with 4 customizable prompts\", \"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Core Functions\n",
    "\"\"\"\n",
    "This section contains all the core functionality for the Literature Synthesis system.\n",
    "Each function is designed to be modular, well-documented, and easy to customize.\n",
    "\"\"\"\n",
    "\n",
    "import json, re, os, time, hashlib\n",
    "from typing import List, Dict, Any, Optional, Type\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "# ===== DOCUMENT PROCESSING =====\n",
    "# These functions handle loading documents and text processing\n",
    "# You can customize chunking parameters in the LitSynthConfig\n",
    "\n",
    "def load_document(source_type: str, content: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load document from various sources (text or PDF)\n",
    "    \n",
    "    Args:\n",
    "        source_type: Type of document (\"text\" or \"pdf\")\n",
    "        content: Document content or file path\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with extracted text and metadata\n",
    "    \"\"\"\n",
    "    if source_type == \"text\":\n",
    "        return {\"text\": content, \"metadata\": {\"source_type\": \"text\", \"length\": len(content)}}\n",
    "    elif source_type == \"pdf\":\n",
    "        try:\n",
    "            from pypdf import PdfReader\n",
    "            reader = PdfReader(content)\n",
    "            text = \"\\n\\n\".join(page.extract_text() for page in reader.pages)\n",
    "            return {\"text\": text, \"metadata\": {\"source_type\": \"pdf\", \"filename\": os.path.basename(content), \"pages\": len(reader.pages)}}\n",
    "        except Exception as e:\n",
    "            return {\"text\": \"\", \"metadata\": {\"error\": str(e)}}\n",
    "    else:\n",
    "        return {\"text\": \"\", \"metadata\": {\"error\": \"Unsupported source type\"}}\n",
    "\n",
    "def chunk_text(text: str, config: LitSynthConfig) -> List[str]:\n",
    "    \"\"\"Split text into semantically coherent chunks optimized for scientific papers\n",
    "    \n",
    "    Args:\n",
    "        text: The text to chunk\n",
    "        config: Configuration with chunk_size and overlap parameters\n",
    "        \n",
    "    Returns:\n",
    "        List of text chunks optimized for scientific content\n",
    "    \"\"\"\n",
    "    if not text: \n",
    "        return []\n",
    "    \n",
    "    # Safety bounds for config values\n",
    "    chunk_size = min(max(config.text_chunk_size, 1000), 4000)\n",
    "    overlap = min(config.text_chunk_overlap, chunk_size // 4)\n",
    "    \n",
    "    # Scientific paper section headers (common patterns in papers)\n",
    "    section_headers = [\n",
    "        r'\\n+\\s*ABSTRACT\\s*\\n+',\n",
    "        r'\\n+\\s*INTRODUCTION\\s*\\n+', \n",
    "        r'\\n+\\s*METHODS?\\s*\\n+',\n",
    "        r'\\n+\\s*RESULTS\\s*\\n+',\n",
    "        r'\\n+\\s*DISCUSSION\\s*\\n+',\n",
    "        r'\\n+\\s*CONCLUSION\\s*\\n+',\n",
    "        r'\\n+\\s*REFERENCES\\s*\\n+'\n",
    "    ]\n",
    "    \n",
    "    # First try to split by major sections\n",
    "    section_splits = [0]\n",
    "    for pattern in section_headers:\n",
    "        for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "            section_splits.append(match.start())\n",
    "    section_splits.append(len(text))\n",
    "    section_splits = sorted(set(section_splits))\n",
    "    \n",
    "    # Generate base chunks from sections\n",
    "    base_chunks = []\n",
    "    if len(section_splits) > 2:  # More than just start and end\n",
    "        for i in range(len(section_splits) - 1):\n",
    "            start, end = section_splits[i], section_splits[i+1]\n",
    "            if end - start > 100:  # Avoid tiny sections\n",
    "                base_chunks.append(text[start:end].strip())\n",
    "    else:\n",
    "        base_chunks = [text]  # No clear sections, use whole text\n",
    "    \n",
    "    # Further split any chunks that exceed the max size\n",
    "    final_chunks = []\n",
    "    for chunk in base_chunks:\n",
    "        if len(chunk) <= chunk_size:\n",
    "            final_chunks.append(chunk)\n",
    "        else:\n",
    "            # Split large chunks by paragraphs or sentences\n",
    "            start = 0\n",
    "            while start < len(chunk):\n",
    "                end = min(start + chunk_size, len(chunk))\n",
    "                \n",
    "                if end < len(chunk):\n",
    "                    # Try paragraph boundaries\n",
    "                    para_end = chunk.rfind(\"\\n\\n\", start + (chunk_size // 2), end)\n",
    "                    if para_end > start + 200:\n",
    "                        end = para_end + 2\n",
    "                    else:\n",
    "                        # Fall back to sentence boundaries\n",
    "                        for sep in [\". \", \".\\n\", \"? \", \"! \"]:\n",
    "                            sent_end = chunk.rfind(sep, start + (chunk_size // 2), end)\n",
    "                            if sent_end > start + 200:\n",
    "                                end = sent_end + len(sep)\n",
    "                                break\n",
    "                \n",
    "                final_chunks.append(chunk[start:end].strip())\n",
    "                start = max(end - overlap, start + (chunk_size // 2))\n",
    "    \n",
    "    return final_chunks\n",
    "\n",
    "# ===== LLM INTEGRATION =====\n",
    "# These functions manage LLM interactions with enhanced robustness\n",
    "# The parsing logic handles various LLM output formats\n",
    "\n",
    "def create_chain(prompt_name: str, output_model=None):\n",
    "    \"\"\"Create an LCEL chain for a specific LLM task\n",
    "    \n",
    "    Args:\n",
    "        prompt_name: Name of the prompt from PROMPTS dictionary\n",
    "        output_model: Optional Pydantic model for structured output\n",
    "        \n",
    "    Returns:\n",
    "        LCEL chain configured for the specified task\n",
    "    \"\"\"\n",
    "    # Guard against missing prompts\n",
    "    if prompt_name not in PROMPTS:\n",
    "        show(f\"Prompt '{prompt_name}' not found in prompt library\", \"error\")\n",
    "        return None\n",
    "        \n",
    "    template = ChatPromptTemplate.from_template(PROMPTS[prompt_name])\n",
    "    \n",
    "    def parse_output(response):\n",
    "        \"\"\"Parse LLM response with multi-strategy approach\"\"\"\n",
    "        content = response.content if hasattr(response, 'content') else response\n",
    "        \n",
    "        # For text output (synthesis), return directly\n",
    "        if not output_model:\n",
    "            return content\n",
    "        \n",
    "        # For structured output, try multiple parsing strategies:\n",
    "        \n",
    "        # 1. Code block extraction\n",
    "        if isinstance(content, str) and \"```\" in content:\n",
    "            try:\n",
    "                # Handle ```json blocks\n",
    "                if \"```json\" in content:\n",
    "                    json_block = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "                    data = json.loads(json_block)\n",
    "                    return [output_model(**item) for item in data]\n",
    "                # Handle any other code blocks\n",
    "                else:\n",
    "                    code_block = content.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "                    if code_block.strip().startswith(\"[\") and code_block.strip().endswith(\"]\"):\n",
    "                        data = json.loads(code_block)\n",
    "                        return [output_model(**item) for item in data]\n",
    "            except Exception as e:\n",
    "                show(f\"Code block parsing error: {str(e)}\", \"debug\")\n",
    "        \n",
    "        # 2. Direct JSON parsing\n",
    "        try:\n",
    "            data = json.loads(content if isinstance(content, str) else content.content)\n",
    "            return [output_model(**item) for item in data]\n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "        # 3. Fallback regex extraction\n",
    "        try:\n",
    "            matches = re.findall(r'\\[(.*?)\\]', content, re.DOTALL)\n",
    "            if matches:\n",
    "                data = json.loads(f\"[{max(matches, key=len)}]\")\n",
    "                return [output_model(**item) for item in data]\n",
    "        except Exception as e:\n",
    "            show(f\"All parsing methods failed: {str(e)}\", \"debug\")\n",
    "        \n",
    "        return []\n",
    "    \n",
    "    # Create and return the chain\n",
    "    if \"llm\" in globals():\n",
    "        return template | llm | RunnableLambda(parse_output)\n",
    "    else:\n",
    "        return RunnableLambda(lambda _: [] if output_model else \"Placeholder output (no LLM configured)\")\n",
    "\n",
    "def cached_run(chain, inputs: Dict, key_prefix: str = \"\"):\n",
    "    \"\"\"Run chain with caching to minimize API calls\n",
    "    \n",
    "    This function handles the complexity of caching LLM responses and properly\n",
    "    reconstructing Pydantic model objects when retrieving from cache. Without\n",
    "    this reconstruction step, cached results would be plain dictionaries\n",
    "    lacking the methods and behaviors of the original model classes.\n",
    "    \n",
    "    Args:\n",
    "        chain: LCEL chain to run\n",
    "        inputs: Input parameters \n",
    "        key_prefix: Cache key prefix for identification (e.g., \"concepts\", \"relationships\")\n",
    "        \n",
    "    Returns:\n",
    "        Chain output (cached or fresh), with proper Pydantic model types\n",
    "    \"\"\"\n",
    "    if not chain: \n",
    "        return [] if 'text' not in key_prefix else \"No chain available\"\n",
    "    \n",
    "    # Map key_prefix to the appropriate model class\n",
    "    model_map = {\n",
    "        \"concepts\": Concept,\n",
    "        \"relationships\": Relationship,\n",
    "        \"gaps\": ResearchGap\n",
    "    }\n",
    "    output_model = model_map.get(key_prefix)\n",
    "    \n",
    "    # Use the existing caching functions from Core Utilities\n",
    "    if 'CACHE_ENABLED' in globals() and CACHE_ENABLED:\n",
    "        # Prepare inputs for caching - limit text size for reasonable cache keys\n",
    "        cache_inputs = {}\n",
    "        for k, v in inputs.items():\n",
    "            if k == 'text' and isinstance(v, str) and len(v) > 500:\n",
    "                cache_inputs[k] = v[:500]  # Use first 500 chars of text for cache key\n",
    "            else:\n",
    "                cache_inputs[k] = v\n",
    "                \n",
    "        # Add prefix to differentiate between similar calls\n",
    "        cache_inputs['_function'] = key_prefix\n",
    "        \n",
    "        # Try to get cached result\n",
    "        try:\n",
    "            key = cache_key(**cache_inputs)\n",
    "            cached_result = get_cache(key)\n",
    "            \n",
    "            if cached_result is not None:\n",
    "                show(f\"Using cached result for {key_prefix}\", \"debug\")\n",
    "                \n",
    "                # Convert dictionaries back to Pydantic models if needed\n",
    "                if output_model and isinstance(cached_result, list) and cached_result:\n",
    "                    # Check if we need to reconstruct models (if first item is a dict)\n",
    "                    if isinstance(cached_result[0], dict):\n",
    "                        try:\n",
    "                            cached_result = [output_model(**item) for item in cached_result]\n",
    "                        except Exception as e:\n",
    "                            show(f\"Model reconstruction error: {str(e)}\", \"debug\")\n",
    "                \n",
    "                return cached_result\n",
    "        except Exception as e:\n",
    "            show(f\"Cache access error: {str(e)}\", \"debug\")\n",
    "    \n",
    "    # Run chain if not in cache or caching disabled\n",
    "    try:\n",
    "        result = chain.invoke(inputs)\n",
    "        \n",
    "        # Try to cache the result\n",
    "        if 'CACHE_ENABLED' in globals() and CACHE_ENABLED:\n",
    "            try:\n",
    "                set_cache(key, result)\n",
    "            except Exception as e:\n",
    "                show(f\"Cache storage error: {str(e)}\", \"debug\")\n",
    "                \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        show(f\"Error in {key_prefix}: {error_msg}\", \"error\")\n",
    "        return [] if 'text' not in key_prefix else f\"Error: {error_msg}\"\n",
    "\n",
    "# ===== ANALYSIS FUNCTIONS =====\n",
    "# These functions implement the core literature analysis capabilities\n",
    "# Each function can be customized through the corresponding prompt\n",
    "\n",
    "def extract_concepts(text: str, config: LitSynthConfig) -> List[Concept]:\n",
    "    \"\"\"Extract scientific concepts from text\n",
    "    \n",
    "    Args:\n",
    "        text: Scientific text to analyze\n",
    "        config: Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        List of extracted Concept objects with definitions\n",
    "    \"\"\"\n",
    "    if not text or len(text.strip()) < 20:\n",
    "        show(\"Text too short for concept extraction\", \"warning\")\n",
    "        return []\n",
    "    \n",
    "    show(f\"Extracting concepts from text ({len(text)} chars)...\", \"info\")\n",
    "    \n",
    "    try:\n",
    "        # Create chain and run extraction\n",
    "        chain = create_chain(\"concept_extraction\", Concept)\n",
    "        concepts = cached_run(chain, {\"text\": text, \"config\": config.model_dump()}, \"concepts\")\n",
    "        \n",
    "        # Filter and sort by importance\n",
    "        importance_map = {\"high\": 3, \"medium\": 2, \"low\": 1}\n",
    "        min_value = importance_map.get(config.min_concept_importance, 1)\n",
    "        \n",
    "        if not concepts:\n",
    "            show(\"No concepts extracted\", \"warning\")\n",
    "            return []\n",
    "            \n",
    "        filtered = [c for c in concepts if importance_map.get(c.importance, 0) >= min_value]\n",
    "        filtered.sort(key=lambda c: importance_map.get(c.importance, 0), reverse=True)\n",
    "        \n",
    "        show(f\"Extracted {len(filtered[:config.max_concepts])} concepts\", \"info\")\n",
    "        return filtered[:config.max_concepts]\n",
    "        \n",
    "    except Exception as e:\n",
    "        show(f\"Error in concept extraction: {str(e)}\", \"error\")\n",
    "        return []\n",
    "\n",
    "def identify_relationships(text: str, concepts: List[Concept], config: LitSynthConfig) -> List[Relationship]:\n",
    "    \"\"\"Map relationships between concepts\n",
    "    \n",
    "    Args:\n",
    "        text: Source text\n",
    "        concepts: List of extracted concepts\n",
    "        config: Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        List of Relationship objects connecting concepts\n",
    "    \"\"\"\n",
    "    if not text or not concepts: \n",
    "        return []\n",
    "    \n",
    "    # Format concepts for prompt\n",
    "    concepts_text = \"\\n\".join([f\"- {c.name}: {c.definition}\" for c in concepts])\n",
    "    \n",
    "    chain = create_chain(\"relationship_mapping\", Relationship)\n",
    "    relationships = cached_run(chain, {\n",
    "        \"text\": text, \n",
    "        \"concepts\": concepts_text\n",
    "    }, \"relationships\")\n",
    "    \n",
    "    # Filter valid relationships\n",
    "    concept_names = {c.name for c in concepts}\n",
    "    valid = [r for r in relationships \n",
    "            if r.source in concept_names and r.target in concept_names \n",
    "            and (not hasattr(r, 'confidence') or r.confidence >= config.relationship_confidence)]\n",
    "    \n",
    "    # Sort by confidence if available\n",
    "    if valid and hasattr(valid[0], 'confidence'):\n",
    "        valid.sort(key=lambda r: getattr(r, 'confidence', 0), reverse=True)\n",
    "        \n",
    "    return valid[:config.max_relationships]\n",
    "\n",
    "def identify_research_gaps(text: str, concepts: List[Concept], relationships: List[Relationship]) -> List[ResearchGap]:\n",
    "    \"\"\"Identify research gaps and opportunities\n",
    "    \n",
    "    Args:\n",
    "        text: Source text\n",
    "        concepts: List of extracted concepts\n",
    "        relationships: List of identified relationships\n",
    "        \n",
    "    Returns:\n",
    "        List of ResearchGap objects\n",
    "    \"\"\"\n",
    "    if not text: \n",
    "        return []\n",
    "    \n",
    "    # Prepare formatted inputs\n",
    "    concepts_text = \"\\n\".join([f\"- {c.name}: {c.definition}\" for c in concepts])\n",
    "    relationships_text = \"\\n\".join([f\"- {r.source} {r.relationship_type} {r.target}\" for r in relationships])\n",
    "    \n",
    "    chain = create_chain(\"research_gap\", ResearchGap)\n",
    "    return cached_run(chain, {\n",
    "        \"text\": text, \n",
    "        \"concepts\": concepts_text, \n",
    "        \"relationships\": relationships_text\n",
    "    }, \"gaps\")\n",
    "\n",
    "def generate_synthesis(text: str, concepts: List[Concept], relationships: List[Relationship], gaps: List[ResearchGap]) -> str:\n",
    "    \"\"\"Generate synthesis text summarizing the analysis\n",
    "    \n",
    "    Args:\n",
    "        text: Source text\n",
    "        concepts: List of extracted concepts\n",
    "        relationships: List of identified relationships\n",
    "        gaps: List of research gaps\n",
    "        \n",
    "    Returns:\n",
    "        Formatted synthesis text\n",
    "    \"\"\"\n",
    "    if not text or not concepts: \n",
    "        return \"Insufficient data for synthesis.\"\n",
    "    \n",
    "    # Prepare formatted inputs\n",
    "    concepts_text = \"\\n\".join([f\"- {c.name}: {c.definition} (Importance: {c.importance})\" for c in concepts])\n",
    "    relationships_text = \"\\n\".join([f\"- {r.source} {r.relationship_type} {r.target}\" for r in relationships])\n",
    "    gaps_text = \"\\n\".join([f\"- {g.description} (Importance: {g.importance})\" for g in gaps])\n",
    "    \n",
    "    chain = create_chain(\"synthesis_generation\")\n",
    "    return cached_run(chain, {\n",
    "        \"text\": text, \n",
    "        \"concepts\": concepts_text, \n",
    "        \"relationships\": relationships_text,\n",
    "        \"gaps\": gaps_text\n",
    "    }, \"synthesis\")\n",
    "\n",
    "# ===== MAIN ANALYSIS FUNCTION =====\n",
    "# This orchestrates the entire analysis process\n",
    "\n",
    "def analyze_document(source_type: str, content: str, config: LitSynthConfig = None) -> LiteratureSynthesisOutput:\n",
    "    \"\"\"Complete end-to-end document analysis\n",
    "    \n",
    "    Args:\n",
    "        source_type: Document type (\"text\" or \"pdf\")\n",
    "        content: Document content or file path\n",
    "        config: Configuration parameters (optional)\n",
    "        \n",
    "    Returns:\n",
    "        Complete analysis results in LiteratureSynthesisOutput container\n",
    "    \"\"\"\n",
    "    config = config or LitSynthConfig()\n",
    "    \n",
    "    try:\n",
    "        # 1. Load and process document\n",
    "        doc_data = load_document(source_type, content)\n",
    "        text = doc_data.get(\"text\", \"\")\n",
    "        if not text: \n",
    "            raise ValueError(\"Failed to extract text\")\n",
    "        doc_id = hashlib.md5(text[:1000].encode()).hexdigest()[:10]\n",
    "        \n",
    "        # 2. Extract concepts (chunking if needed)\n",
    "        if len(text) > config.text_chunk_size:\n",
    "            # Process in chunks\n",
    "            chunks = chunk_text(text, config)\n",
    "            all_concepts = []\n",
    "            for chunk in chunks:\n",
    "                all_concepts.extend(extract_concepts(chunk, config))\n",
    "            \n",
    "            # Deduplicate keeping highest importance\n",
    "            concepts_map = {}\n",
    "            importance_rank = {\"high\": 3, \"medium\": 2, \"low\": 1}\n",
    "            for concept in all_concepts:\n",
    "                name = concept.name.lower()\n",
    "                if name not in concepts_map or importance_rank.get(concept.importance, 0) > importance_rank.get(concepts_map[name].importance, 0):\n",
    "                    concepts_map[name] = concept\n",
    "            concepts = list(concepts_map.values())\n",
    "        else:\n",
    "            # Process directly\n",
    "            concepts = extract_concepts(text, config)\n",
    "        \n",
    "        # 3. Extract relationships, gaps, and generate synthesis\n",
    "        relationships = identify_relationships(text, concepts, config)\n",
    "        gaps = identify_research_gaps(text, concepts, relationships)\n",
    "        synthesis_text = generate_synthesis(text, concepts, relationships, gaps)\n",
    "        \n",
    "        # 4. Create output container\n",
    "        return LiteratureSynthesisOutput(\n",
    "            document_id=doc_id,\n",
    "            document_metadata=doc_data.get(\"metadata\", {}),\n",
    "            concepts=concepts,\n",
    "            relationships=relationships,\n",
    "            research_gaps=gaps,\n",
    "            synthesis_text=synthesis_text\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Return error container\n",
    "        return LiteratureSynthesisOutput(\n",
    "            document_id=f\"error_{int(time.time())}\",\n",
    "            document_metadata={\"error\": str(e)},\n",
    "            concepts=[],\n",
    "            relationships=[],\n",
    "            research_gaps=[],\n",
    "            synthesis_text=f\"Analysis error: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# Initialization complete\n",
    "show(\"Core functions initialized\", \"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Initialization\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # Initialize the Literature Synthesis System\n",
    "    class LitSynthSystem:\n",
    "        \"\"\"Main system class that coordinates all components of the Literature Synthesis system.\"\"\"\n",
    "        \n",
    "        def __init__(self, config=None):\n",
    "            \"\"\"Initialize the system with configuration and components.\"\"\"\n",
    "            # Use existing config or create new one\n",
    "            self.config = config or globals().get('config', LitSynthConfig())\n",
    "            \n",
    "            # No cache setup needed - already handled in Core Utilities\n",
    "        \n",
    "        def analyze_document(self, source_type, content):\n",
    "            \"\"\"Main entry point to analyze a document.\"\"\"\n",
    "            return analyze_document(source_type, content, self.config)\n",
    "        \n",
    "        def extract_concepts_from_text(self, text):\n",
    "            \"\"\"Extract concepts from text directly.\"\"\"\n",
    "            return extract_concepts(text, self.config)\n",
    "        \n",
    "        def identify_relationships_from_concepts(self, text, concepts):\n",
    "            \"\"\"Identify relationships between concepts.\"\"\"\n",
    "            return identify_relationships(text, concepts, self.config)\n",
    "        \n",
    "        def identify_gaps_from_concepts_relationships(self, text, concepts, relationships):\n",
    "            \"\"\"Identify research gaps from concepts and relationships.\"\"\"\n",
    "            return identify_research_gaps(text, concepts, relationships)\n",
    "        \n",
    "        def generate_synthesis_from_components(self, text, concepts, relationships, gaps):\n",
    "            \"\"\"Generate synthesis from all components.\"\"\"\n",
    "            return generate_synthesis(text, concepts, relationships, gaps)\n",
    "\n",
    "    # Initialize the system (connects previously defined components)\n",
    "    litsynth = LitSynthSystem()\n",
    "    \n",
    "    # Confirm successful initialization - using show_info correctly\n",
    "    show_info(\"Literature Synthesis System initialized successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # Use show from Core Utilities for error (with level parameter)\n",
    "    error_msg = f\"System failed to initialize: {str(e)}\"\n",
    "    show(f\"{error_msg}\\nPlease make sure you run the cells in order: Installation-Initialization-Data Models-Core Functions\", \"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI Structure\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_ui():\n",
    "    \"\"\"Create optimized Literature Synthesis UI.\"\"\"\n",
    "    \n",
    "    with gr.Blocks() as app:\n",
    "        gr.Markdown(\"# Literature Synthesis Expert System\")\n",
    "        \n",
    "        with gr.Tabs() as tabs:\n",
    "            # === INPUT TAB ===\n",
    "            with gr.Tab(\"Document Input\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        # PDF Upload (only option)\n",
    "                        pdf_input = gr.File(\n",
    "                            label=\"Upload Scientific PDF\", \n",
    "                            file_types=[\".pdf\"],\n",
    "                            file_count=\"single\"\n",
    "                        )\n",
    "                        \n",
    "                        with gr.Row():\n",
    "                            analysis_mode = gr.Radio(\n",
    "                                choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                                label=\"Analysis Mode\",\n",
    "                                value=\"quick\",\n",
    "                                info=\"Quick: 30-40s, Balanced: 1-2min, Thorough: 3-5min\"\n",
    "                            )\n",
    "                            analyze_btn = gr.Button(\"Analyze Document\", variant=\"primary\")\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        status_box = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                        progress_bar = gr.Slider(\n",
    "                            minimum=0, maximum=100, value=0, \n",
    "                            label=\"Processing Progress\",\n",
    "                            interactive=False\n",
    "                        )\n",
    "            \n",
    "            # === CONCEPTS TAB ===\n",
    "            with gr.Tab(\"Concepts & Relationships\"):\n",
    "                with gr.Row():\n",
    "                    # Add document metadata box at the top\n",
    "                    doc_info = gr.Markdown(\"*Upload and analyze a document to see results*\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        concepts_filter = gr.Radio(\n",
    "                            choices=[\"all\", \"high\", \"medium\", \"low\"],\n",
    "                            label=\"Filter by Importance\",\n",
    "                            value=\"all\"\n",
    "                        )\n",
    "                        concepts_table = gr.DataFrame(\n",
    "                            headers=[\"Concept\", \"Definition\", \"Importance\", \"Confidence\"]\n",
    "                        )\n",
    "                    \n",
    "                    with gr.Column():\n",
    "                        relationships_table = gr.DataFrame(\n",
    "                            headers=[\"Source\", \"Relationship\", \"Target\", \"Evidence\", \"Confidence\"]\n",
    "                        )\n",
    "            \n",
    "            # === VISUALIZATION TAB ===\n",
    "            with gr.Tab(\"Visualization\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        with gr.Row():\n",
    "                            min_confidence = gr.Slider(\n",
    "                                minimum=0.0, maximum=1.0, value=0.5, step=0.1,\n",
    "                                label=\"Minimum Confidence\"\n",
    "                            )\n",
    "                            layout_type = gr.Dropdown(\n",
    "                                choices=[\"Force-directed\", \"Circular\", \"Spectral\", \"Spring\"],\n",
    "                                label=\"Layout Type\",\n",
    "                                value=\"Force-directed\"\n",
    "                            )\n",
    "                            refresh_viz_btn = gr.Button(\"Refresh\")\n",
    "                        \n",
    "                        network_plot = gr.Plot(label=\"Concept Network\")\n",
    "                            \n",
    "            # === SYNTHESIS TAB ===\n",
    "            with gr.Tab(\"Research Synthesis\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        synthesis_output = gr.Markdown()\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        gr.Markdown(\"### Research Gaps\")\n",
    "                        gaps_table = gr.DataFrame(\n",
    "                            headers=[\"Description\", \"Related Concepts\", \"Importance\"]\n",
    "                        )\n",
    "                        \n",
    "                        with gr.Row():\n",
    "                            export_format = gr.Dropdown(\n",
    "                                choices=[\"Markdown\", \"Text\", \"JSON\"],\n",
    "                                label=\"Export Format\",\n",
    "                                value=\"Markdown\"\n",
    "                            )\n",
    "                            export_btn = gr.Button(\"Export\")\n",
    "                            \n",
    "            # === SETTINGS TAB ===\n",
    "            with gr.Tab(\"Settings\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        # Analysis mode\n",
    "                        gr.Markdown(\"#### Analysis Settings\")\n",
    "                        settings_analysis_mode = gr.Radio(\n",
    "                            choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                            label=\"Analysis Mode\",\n",
    "                            value=\"quick\",\n",
    "                            info=\"Affects document sampling and processing depth\"\n",
    "                        )\n",
    "                        \n",
    "                        # Text processing settings\n",
    "                        gr.Markdown(\"#### Text Processing\")\n",
    "                        chunk_size = gr.Slider(\n",
    "                            minimum=500, maximum=8000, value=2000, step=500,\n",
    "                            label=\"Chunk Size (chars)\",\n",
    "                            info=\"Larger chunks capture more context but process slower\"\n",
    "                        )\n",
    "                        chunk_overlap = gr.Slider(\n",
    "                            minimum=50, maximum=1000, value=200, step=50,\n",
    "                            label=\"Chunk Overlap\"\n",
    "                        )\n",
    "                        \n",
    "                        # Concept settings\n",
    "                        gr.Markdown(\"#### Concepts\")\n",
    "                        min_importance = gr.Dropdown(\n",
    "                            choices=[\"low\", \"medium\", \"high\"],\n",
    "                            label=\"Min Importance\",\n",
    "                            value=\"medium\"\n",
    "                        )\n",
    "                        max_concepts = gr.Slider(\n",
    "                            minimum=5, maximum=100, value=25, step=5,\n",
    "                            label=\"Max Concepts\"\n",
    "                        )\n",
    "                        \n",
    "                        # Relationship settings\n",
    "                        gr.Markdown(\"#### Relationships\")\n",
    "                        relationship_confidence = gr.Slider(\n",
    "                            minimum=0.0, maximum=1.0, value=0.6, step=0.1,\n",
    "                            label=\"Min Confidence\"\n",
    "                        )\n",
    "                        max_relationships = gr.Slider(\n",
    "                            minimum=10, maximum=200, value=50, step=10,\n",
    "                            label=\"Max Relationships\"\n",
    "                        )\n",
    "                        \n",
    "                        apply_settings_btn = gr.Button(\"Apply Settings\", variant=\"primary\")\n",
    "                        settings_status = gr.Textbox(label=\"Settings Status\", interactive=False)\n",
    "        \n",
    "        # === State Variables ===\n",
    "        results_state = gr.State(None)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create the UI\n",
    "ui = create_ui()\n",
    "\n",
    "# Display success message in notebook\n",
    "show_info(\"UI structure defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI Launch\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def launch_litsynth_ui():\n",
    "    \"\"\"Launch the Literature Synthesis Expert System UI.\"\"\"\n",
    "    \n",
    "    # Document Processing Functions\n",
    "    def smart_sample_document(text, sample_percentage=15, min_chars=4000, max_chars=15000):\n",
    "        \"\"\"Sample document to reduce processing time while keeping key sections.\"\"\"\n",
    "        if not text or len(text) <= min_chars:\n",
    "            return (text, 100) if text else (\"\", 0)\n",
    "            \n",
    "        target_size = max(min_chars, min(max_chars, int(len(text) * sample_percentage / 100)))\n",
    "        \n",
    "        # Extract document sections\n",
    "        import re\n",
    "        section_patterns = {\n",
    "            'abstract': r'(?i)abstract\\s*\\n',\n",
    "            'introduction': r'(?i)(introduction|background)\\s*\\n',\n",
    "            'methods': r'(?i)(methods|methodology|materials\\s+and\\s+methods)\\s*\\n',\n",
    "            'results': r'(?i)results\\s*\\n',\n",
    "            'discussion': r'(?i)discussion\\s*\\n',\n",
    "            'conclusion': r'(?i)(conclusion|conclusions|summary)\\s*\\n'\n",
    "        }\n",
    "        \n",
    "        sections = {}\n",
    "        for name, pattern in section_patterns.items():\n",
    "            matches = list(re.finditer(pattern, text))\n",
    "            if matches:\n",
    "                start = matches[0].end()\n",
    "                next_starts = [m.start() for m in re.finditer('|'.join(section_patterns.values()), text[start:])]\n",
    "                end = start + next_starts[0] if next_starts else len(text)\n",
    "                sections[name] = (start, end)\n",
    "        \n",
    "        # Prioritize sections or use beginning-middle-end approach\n",
    "        sampled_text = \"\"\n",
    "        if sections:\n",
    "            priority_order = ['abstract', 'introduction', 'conclusion', 'discussion', 'results', 'methods']\n",
    "            chars_remaining = target_size\n",
    "            \n",
    "            for section in priority_order:\n",
    "                if section in sections and chars_remaining > 0:\n",
    "                    start, end = sections[section]\n",
    "                    section_text = text[start:end]\n",
    "                    chars_to_take = min(len(section_text), chars_remaining)\n",
    "                    sampled_text += section_text[:chars_to_take] + \"\\n\\n\"\n",
    "                    chars_remaining -= chars_to_take\n",
    "        \n",
    "        if len(sampled_text) < min_chars or not sections:\n",
    "            sampled_text = \"\"\n",
    "            part_size = target_size // 3\n",
    "            \n",
    "            sampled_text += text[:part_size] + \"\\n\\n\"\n",
    "            if len(text) > part_size * 3:\n",
    "                middle_start = len(text) // 2 - part_size // 2\n",
    "                sampled_text += \"[...]\\n\\n\" + text[middle_start:middle_start + part_size] + \"\\n\\n\"\n",
    "            if len(text) > part_size * 2:\n",
    "                sampled_text += \"[...]\\n\\n\" + text[max(len(text) - part_size, part_size * 2)]\n",
    "        \n",
    "        coverage = min(100, round(len(sampled_text) / len(text) * 100))\n",
    "        return sampled_text, coverage\n",
    "    \n",
    "    def process_pdf_document(pdf_file, analysis_mode=\"quick\"):\n",
    "        \"\"\"Process PDF with staged concept extraction and relationship mapping.\"\"\"\n",
    "        if not pdf_file:\n",
    "            return \"Please upload a PDF file.\", None, 0\n",
    "        \n",
    "        try:\n",
    "            yield \"Loading PDF document...\", None, 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Process file upload\n",
    "            temp_path = Path(tempfile.mkdtemp()) / \"uploaded.pdf\"\n",
    "            if hasattr(pdf_file, 'name'):\n",
    "                with open(pdf_file.name, \"rb\") as src_file, open(temp_path, \"wb\") as dest_file:\n",
    "                    dest_file.write(src_file.read())\n",
    "            else:\n",
    "                with open(temp_path, \"wb\") as f:\n",
    "                    f.write(pdf_file)\n",
    "            \n",
    "            yield \"Extracting text...\", None, 10\n",
    "            doc_data = load_document(\"pdf\", str(temp_path))\n",
    "            text = doc_data.get(\"text\", \"\")\n",
    "            \n",
    "            if not text:\n",
    "                return \"Failed to extract text from PDF.\", None, 0\n",
    "            \n",
    "            # Sample text based on analysis mode\n",
    "            if len(text) <= 4000:\n",
    "                sampled_text, coverage = text, 100\n",
    "            else:\n",
    "                sample_percent = {\"quick\": 10, \"balanced\": 25, \"thorough\": 50}.get(analysis_mode, 10)\n",
    "                target_size = min(len(text), max(4000, int(len(text) * sample_percent / 100)))\n",
    "                \n",
    "                segment_size = min(target_size // 3, 3000)\n",
    "                start_text = text[:segment_size]\n",
    "                mid_point = len(text) // 2\n",
    "                mid_text = text[mid_point - segment_size//2:mid_point + segment_size//2]\n",
    "                end_text = text[max(0, len(text) - segment_size):]\n",
    "                \n",
    "                sampled_text = start_text + \"\\n\\n[...]\\n\\n\" + mid_text + \"\\n\\n[...]\\n\\n\" + end_text\n",
    "                coverage = round((len(sampled_text) / len(text)) * 100)\n",
    "            \n",
    "            yield f\"Processing document ({len(text)} characters, {coverage}% sample)...\", None, 20\n",
    "            doc_id = hashlib.md5(text[:1000].encode()).hexdigest()[:10]\n",
    "            \n",
    "            # Multi-stage analysis\n",
    "            concepts, relationships, gaps = [], [], []\n",
    "            synthesis = \"No synthesis generated.\"\n",
    "            \n",
    "            # 1. Extract concepts\n",
    "            try:\n",
    "                yield \"Extracting concepts...\", None, 30\n",
    "                current_config = config if 'config' in globals() else LitSynthConfig()\n",
    "                concepts = extract_concepts(sampled_text, current_config)\n",
    "                yield f\"Found {len(concepts)} concepts\", None, 50\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR in concept extraction: {str(e)}\")\n",
    "                yield f\"Error extracting concepts: {str(e)}\", None, 50\n",
    "            \n",
    "            if concepts:\n",
    "                # 2. Identify relationships\n",
    "                try:\n",
    "                    yield \"Identifying relationships...\", None, 60\n",
    "                    relationships = identify_relationships(sampled_text, concepts, current_config)\n",
    "                    yield f\"Found {len(relationships)} relationships\", None, 70\n",
    "                except Exception as e:\n",
    "                    yield f\"Error identifying relationships, continuing...\", None, 70\n",
    "                \n",
    "                # 3. Identify research gaps\n",
    "                try:\n",
    "                    yield \"Identifying research gaps...\", None, 80\n",
    "                    gaps = identify_research_gaps(sampled_text, concepts, relationships)\n",
    "                    yield f\"Found {len(gaps)} research gaps\", None, 90\n",
    "                except Exception as e:\n",
    "                    yield f\"Error identifying research gaps, continuing...\", None, 90\n",
    "                \n",
    "                # 4. Generate synthesis\n",
    "                try:\n",
    "                    yield \"Generating synthesis...\", None, 95\n",
    "                    synthesis = generate_synthesis(sampled_text, concepts, relationships, gaps)\n",
    "                except Exception as e:\n",
    "                    synthesis = \"Synthesis generation failed. Please check the extracted concepts and relationships.\"\n",
    "            else:\n",
    "                yield \"No concepts found, skipping further analysis...\", None, 95\n",
    "            \n",
    "            # Package results\n",
    "            results = LiteratureSynthesisOutput(\n",
    "                document_id=doc_id,\n",
    "                document_metadata={\n",
    "                    \"original_length\": len(text),\n",
    "                    \"processed_length\": len(sampled_text),\n",
    "                    \"coverage_percentage\": coverage,\n",
    "                    \"processing_time\": round(time.time() - start_time, 2),\n",
    "                    \"analysis_mode\": analysis_mode\n",
    "                },\n",
    "                concepts=concepts or [],\n",
    "                relationships=relationships or [],\n",
    "                research_gaps=gaps or [],\n",
    "                synthesis_text=synthesis or \"No synthesis available.\"\n",
    "            )\n",
    "            \n",
    "            processing_time = round(time.time() - start_time, 2)\n",
    "            status_msg = (f\"Analysis complete in {processing_time}s: {len(results.concepts)} concepts, \"\n",
    "                        f\"{len(results.relationships)} relationships, {len(results.research_gaps)} research gaps \"\n",
    "                        f\"({coverage}% of document processed)\")\n",
    "            \n",
    "            yield status_msg, results, 100\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error analyzing document: {str(e)}\", None, 0\n",
    "    \n",
    "    # Visualization Function\n",
    "    def create_network_visualization(concepts, relationships, min_confidence=0.5):\n",
    "        \"\"\"Create network visualization with improved readability.\"\"\"\n",
    "        if not concepts or len(concepts) < 2:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            ax.text(0.5, 0.5, \"Not enough concepts to create visualization\", \n",
    "                   ha='center', va='center', fontsize=12)\n",
    "            ax.axis('off')\n",
    "            return fig\n",
    "        \n",
    "        # Create directed graph\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes and edges\n",
    "        for concept in concepts:\n",
    "            G.add_node(concept.name, importance=concept.importance, definition=concept.definition)\n",
    "        \n",
    "        edge_count = 0\n",
    "        for rel in relationships:\n",
    "            if rel.confidence >= min_confidence and rel.source in G.nodes and rel.target in G.nodes:\n",
    "                G.add_edge(rel.source, rel.target, \n",
    "                          relationship=rel.relationship_type,\n",
    "                          evidence=rel.evidence,\n",
    "                          confidence=rel.confidence)\n",
    "                edge_count += 1\n",
    "        \n",
    "        # Enhanced visualization styling\n",
    "        plt.rcParams.update({'font.size': 12})\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        importance_colors = {\"high\": \"#e41a1c\", \"medium\": \"#377eb8\", \"low\": \"#4daf4a\"}\n",
    "        node_colors = [importance_colors.get(G.nodes[node][\"importance\"], \"#999999\") for node in G.nodes]\n",
    "        \n",
    "        centrality = nx.degree_centrality(G)\n",
    "        node_sizes = [3000 * (centrality[node] + 0.1) for node in G.nodes]\n",
    "        \n",
    "        pos = nx.spring_layout(G, k=0.4, seed=42)\n",
    "        \n",
    "        # Draw network with improved visibility\n",
    "        nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, \n",
    "                              alpha=0.85, edgecolors='white', linewidths=1.5)\n",
    "        nx.draw_networkx_edges(G, pos, edge_color='#555555', width=2.0, alpha=0.7, \n",
    "                              arrows=True, arrowsize=20, node_size=node_sizes)\n",
    "        \n",
    "        # Improved label rendering\n",
    "        labels_pos = {node: (pos[node][0], pos[node][1] + 0.02) for node in G.nodes}\n",
    "        nx.draw_networkx_labels(G, labels_pos, font_size=12, font_weight='bold', \n",
    "                               bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', \n",
    "                                        boxstyle='round,pad=0.3'))\n",
    "        \n",
    "        # Add legend\n",
    "        legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                     markerfacecolor=color, markersize=12, \n",
    "                                     label=f\"{importance.capitalize()} Importance\") \n",
    "                          for importance, color in importance_colors.items()]\n",
    "        ax.legend(handles=legend_elements, loc='upper right', fontsize=11, \n",
    "                 frameon=True, facecolor='white', edgecolor='#cccccc')\n",
    "        \n",
    "        ax.axis('off')\n",
    "        plt.title(f\"Concept Relationship Network ({edge_count} connections at {min_confidence:.1f}+ confidence)\",\n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    # Display Helper Functions\n",
    "    def update_doc_info(results):\n",
    "        \"\"\"Format document metadata for display.\"\"\"\n",
    "        if not results:\n",
    "            return \"*No document analyzed yet*\"\n",
    "            \n",
    "        metadata = results.document_metadata\n",
    "        return (f\"### Document Analysis Details\\n\"\n",
    "                f\"**Coverage**: {metadata.get('coverage_percentage', 'Unknown')}% of document processed\\n\"\n",
    "                f\"**Processing Time**: {metadata.get('processing_time', 'Unknown')}s\\n\"\n",
    "                f\"**Analysis Mode**: {metadata.get('analysis_mode', 'Unknown')}\\n\"\n",
    "                f\"**Concepts**: {len(results.concepts)}, \"\n",
    "                f\"**Relationships**: {len(results.relationships)}, \"\n",
    "                f\"**Research Gaps**: {len(results.research_gaps)}\")\n",
    "    \n",
    "    def update_concepts_display(results, filter_type=\"all\"):\n",
    "        \"\"\"Format concepts data for display with optional filtering.\"\"\"\n",
    "        if not results or not hasattr(results, 'concepts') or not results.concepts:\n",
    "            return None\n",
    "        \n",
    "        filtered_concepts = results.concepts if filter_type == \"all\" else [c for c in results.concepts if c.importance == filter_type]\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            \"Concept\": [c.name for c in filtered_concepts],\n",
    "            \"Definition\": [c.definition for c in filtered_concepts],\n",
    "            \"Importance\": [c.importance.capitalize() for c in filtered_concepts],\n",
    "            \"Confidence\": [f\"{c.confidence:.2f}\" for c in filtered_concepts]\n",
    "        })\n",
    "    \n",
    "    def update_relationships_display(results):\n",
    "        \"\"\"Format relationships data for display.\"\"\"\n",
    "        if not results or not hasattr(results, 'relationships') or not results.relationships:\n",
    "            return None\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            \"Source\": [r.source for r in results.relationships],\n",
    "            \"Relationship\": [r.relationship_type for r in results.relationships],\n",
    "            \"Target\": [r.target for r in results.relationships],\n",
    "            \"Evidence\": [r.evidence or \"N/A\" for r in results.relationships],\n",
    "            \"Confidence\": [f\"{r.confidence:.2f}\" for r in results.relationships]\n",
    "        })\n",
    "    \n",
    "    def update_gaps_display(results):\n",
    "        \"\"\"Format research gaps data for display.\"\"\"\n",
    "        if not results or not hasattr(results, 'research_gaps') or not results.research_gaps:\n",
    "            return None\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            \"Description\": [g.description for g in results.research_gaps],\n",
    "            \"Related Concepts\": [\", \".join(g.related_concepts) for g in results.research_gaps],\n",
    "            \"Importance\": [g.importance.capitalize() for g in results.research_gaps]\n",
    "        })\n",
    "    \n",
    "    def update_visualization(results, min_confidence):\n",
    "        \"\"\"Update network visualization based on minimum confidence.\"\"\"\n",
    "        if not results or not hasattr(results, 'concepts') or len(results.concepts) < 2:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            ax.text(0.5, 0.5, \"Not enough concepts to create visualization\", \n",
    "                   ha='center', va='center', fontsize=12)\n",
    "            ax.axis('off')\n",
    "            return fig\n",
    "        \n",
    "        return create_network_visualization(results.concepts, results.relationships, min_confidence)\n",
    "    \n",
    "    def update_config(analysis_mode, chunk_size, chunk_overlap, min_importance, \n",
    "                     max_concepts, relationship_confidence, max_relationships):\n",
    "        \"\"\"Update system configuration.\"\"\"\n",
    "        try:\n",
    "            new_config = LitSynthConfig(\n",
    "                text_chunk_size=chunk_size,\n",
    "                text_chunk_overlap=chunk_overlap,\n",
    "                min_concept_importance=min_importance,\n",
    "                max_concepts=max_concepts,\n",
    "                relationship_confidence=relationship_confidence,\n",
    "                max_relationships=max_relationships\n",
    "            )\n",
    "            \n",
    "            litsynth.config = new_config\n",
    "            settings_summary = f\"Settings updated: {analysis_mode} mode, {chunk_size} chunk size, {min_importance} min importance\"\n",
    "            return new_config, settings_summary\n",
    "        except Exception as e:\n",
    "            return None, f\"Error updating configuration: {str(e)}\"\n",
    "    \n",
    "    # Create UI\n",
    "    with gr.Blocks(css=\"\"\"\n",
    "        /* Table cell wrapping */\n",
    "        table td {\n",
    "            white-space: normal !important;\n",
    "            word-wrap: break-word !important;\n",
    "            max-width: 300px !important;\n",
    "        }\n",
    "        \n",
    "        /* Clean styling */\n",
    "        .section-header {\n",
    "            font-weight: bold;\n",
    "            margin-top: 10px;\n",
    "            margin-bottom: 5px;\n",
    "            border-bottom: 1px solid rgba(128, 128, 128, 0.3);\n",
    "            padding-bottom: 3px;\n",
    "        }\n",
    "        \n",
    "        .info-text {\n",
    "            font-style: italic;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "    \"\"\") as app:\n",
    "        gr.Markdown(\"# Literature Synthesis Expert System\")\n",
    "        \n",
    "        # State variables\n",
    "        results_state = gr.State(None)\n",
    "        \n",
    "        with gr.Tabs() as tabs:\n",
    "            # INPUT TAB\n",
    "            with gr.Tab(\"Document Input\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        pdf_input = gr.File(\n",
    "                            label=\"Upload Scientific PDF\", \n",
    "                            file_types=[\".pdf\"],\n",
    "                            file_count=\"single\"\n",
    "                        )\n",
    "                        \n",
    "                        with gr.Row():\n",
    "                            analysis_mode = gr.Radio(\n",
    "                                choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                                label=\"Analysis Mode\",\n",
    "                                value=\"quick\",\n",
    "                                info=\"Quick: 30-40s, Balanced: 1-2min, Thorough: 3-5min\"\n",
    "                            )\n",
    "                            analyze_btn = gr.Button(\"Analyze Document\", variant=\"primary\")\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        status_box = gr.Textbox(\n",
    "                            label=\"Status\", \n",
    "                            interactive=False,\n",
    "                            value=\"Ready to analyze. Please upload a PDF document.\"\n",
    "                        )\n",
    "                        progress_bar = gr.Slider(\n",
    "                            minimum=0, maximum=100, value=0, \n",
    "                            label=\"Processing Progress\",\n",
    "                            interactive=False\n",
    "                        )\n",
    "            \n",
    "            # CONCEPTS TAB\n",
    "            with gr.Tab(\"Concepts & Relationships\"):\n",
    "                with gr.Row():\n",
    "                    doc_info = gr.Markdown(\"*Upload and analyze a document to see results*\")\n",
    "                \n",
    "                gr.Markdown(\"### Understanding the Concepts Table\")\n",
    "                gr.Markdown(\"This table shows key concepts extracted from the document. Use the filter to focus on specific importance levels.\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"#### Key Concepts\", elem_classes=[\"section-header\"])\n",
    "                        concepts_filter = gr.Radio(\n",
    "                            choices=[\"all\", \"high\", \"medium\", \"low\"],\n",
    "                            label=\"Filter by Importance\",\n",
    "                            value=\"all\"\n",
    "                        )\n",
    "                        concepts_table = gr.DataFrame(\n",
    "                            headers=[\"Concept\", \"Definition\", \"Importance\", \"Confidence\"]\n",
    "                        )\n",
    "                    \n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"#### Relationships Between Concepts\", elem_classes=[\"section-header\"])\n",
    "                        gr.Markdown(\"This table shows how concepts connect to each other.\", elem_classes=[\"info-text\"])\n",
    "                        relationships_table = gr.DataFrame(\n",
    "                            headers=[\"Source\", \"Relationship\", \"Target\", \"Evidence\", \"Confidence\"]\n",
    "                        )\n",
    "            \n",
    "            # VISUALIZATION TAB\n",
    "            with gr.Tab(\"Visualization\"):\n",
    "                gr.Markdown(\"### Network Visualization Guide\")\n",
    "                gr.Markdown(\"This visualization shows how concepts relate to each other:\")\n",
    "                gr.Markdown(\"- **Red nodes**: High importance concepts\")\n",
    "                gr.Markdown(\"- **Blue nodes**: Medium importance concepts\")\n",
    "                gr.Markdown(\"- **Green nodes**: Low importance concepts\")\n",
    "                gr.Markdown(\"- **Node size**: Larger nodes have more connections\")\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        with gr.Row():\n",
    "                            min_confidence = gr.Slider(\n",
    "                                minimum=0.0, maximum=1.0, value=0.5, step=0.1,\n",
    "                                label=\"Minimum Confidence\",\n",
    "                                info=\"Only show relationships with confidence above this threshold\"\n",
    "                            )\n",
    "                            refresh_viz_btn = gr.Button(\"Refresh Visualization\")\n",
    "                        \n",
    "                        network_plot = gr.Plot(label=\"Concept Network\")\n",
    "                            \n",
    "            # SYNTHESIS TAB\n",
    "            with gr.Tab(\"Research Synthesis\"):\n",
    "                with gr.Row():\n",
    "                    with gr.Column(scale=3):\n",
    "                        gr.Markdown(\"#### Overview & Key Findings\", elem_classes=[\"section-header\"])\n",
    "                        synthesis_output = gr.Markdown()\n",
    "                    \n",
    "                    with gr.Column(scale=2):\n",
    "                        gr.Markdown(\"#### Research Gaps\", elem_classes=[\"section-header\"])\n",
    "                        gr.Markdown(\"These are potential areas for future research that weren't fully addressed.\", elem_classes=[\"info-text\"])\n",
    "                        gaps_table = gr.DataFrame(\n",
    "                            headers=[\"Description\", \"Related Concepts\", \"Importance\"]\n",
    "                        )\n",
    "                            \n",
    "            # SETTINGS TAB\n",
    "            with gr.Tab(\"Settings\"):\n",
    "                gr.Markdown(\"### Settings Guide\")\n",
    "                gr.Markdown(\"These settings control how document analysis works. For most users, the default settings work well.\", elem_classes=[\"info-text\"])\n",
    "                \n",
    "                with gr.Row():\n",
    "                    with gr.Column():\n",
    "                        gr.Markdown(\"#### Analysis Settings\", elem_classes=[\"section-header\"])\n",
    "                        settings_analysis_mode = gr.Radio(\n",
    "                            choices=[\"quick\", \"balanced\", \"thorough\"],\n",
    "                            label=\"Analysis Mode\",\n",
    "                            value=\"quick\",\n",
    "                            info=\"Quick (30-40s): Basic overview | Balanced (1-2min): Standard analysis | Thorough (3-5min): Deep analysis\"\n",
    "                        )\n",
    "                        \n",
    "                        gr.Markdown(\"#### Text Processing\", elem_classes=[\"section-header\"])\n",
    "                        chunk_size = gr.Slider(\n",
    "                            minimum=500, maximum=8000, value=2000, step=500,\n",
    "                            label=\"Chunk Size (chars)\",\n",
    "                            info=\"Larger = Better context but slower | Smaller = Faster but less context\"\n",
    "                        )\n",
    "                        chunk_overlap = gr.Slider(\n",
    "                            minimum=50, maximum=1000, value=200, step=50,\n",
    "                            label=\"Chunk Overlap\",\n",
    "                            info=\"Higher overlap maintains context between chunks\"\n",
    "                        )\n",
    "                        \n",
    "                        gr.Markdown(\"#### Concepts Settings\", elem_classes=[\"section-header\"])\n",
    "                        min_importance = gr.Dropdown(\n",
    "                            choices=[\"low\", \"medium\", \"high\"],\n",
    "                            label=\"Min Importance\",\n",
    "                            value=\"medium\",\n",
    "                            info=\"Only include concepts above this importance level\"\n",
    "                        )\n",
    "                        max_concepts = gr.Slider(\n",
    "                            minimum=5, maximum=100, value=25, step=5,\n",
    "                            label=\"Max Concepts\",\n",
    "                            info=\"Maximum number of concepts to extract\"\n",
    "                        )\n",
    "                        \n",
    "                        gr.Markdown(\"#### Relationships Settings\", elem_classes=[\"section-header\"])\n",
    "                        relationship_confidence = gr.Slider(\n",
    "                            minimum=0.0, maximum=1.0, value=0.6, step=0.1,\n",
    "                            label=\"Min Confidence\",\n",
    "                            info=\"Only include relationships with confidence above this threshold\"\n",
    "                        )\n",
    "                        max_relationships = gr.Slider(\n",
    "                            minimum=10, maximum=200, value=50, step=10,\n",
    "                            label=\"Max Relationships\",\n",
    "                            info=\"Maximum number of relationships to identify\"\n",
    "                        )\n",
    "                        \n",
    "                        apply_settings_btn = gr.Button(\"Apply Settings\", variant=\"primary\")\n",
    "                        settings_status = gr.Textbox(label=\"Settings Status\", interactive=False)\n",
    "        \n",
    "        # Event Handlers\n",
    "        analyze_btn.click(\n",
    "            fn=process_pdf_document,\n",
    "            inputs=[pdf_input, analysis_mode],\n",
    "            outputs=[status_box, results_state, progress_bar]\n",
    "        ).then(\n",
    "            fn=update_doc_info,\n",
    "            inputs=[results_state],\n",
    "            outputs=[doc_info]\n",
    "        ).then(\n",
    "            fn=update_concepts_display,\n",
    "            inputs=[results_state, gr.State(\"all\")],\n",
    "            outputs=[concepts_table]\n",
    "        ).then(\n",
    "            fn=update_relationships_display,\n",
    "            inputs=[results_state],\n",
    "            outputs=[relationships_table]\n",
    "        ).then(\n",
    "            fn=update_gaps_display,\n",
    "            inputs=[results_state],\n",
    "            outputs=[gaps_table]\n",
    "        ).then(\n",
    "            fn=lambda x: x.synthesis_text if x and hasattr(x, 'synthesis_text') else \"No synthesis available.\",\n",
    "            inputs=[results_state],\n",
    "            outputs=[synthesis_output]\n",
    "        ).then(\n",
    "            fn=update_visualization,\n",
    "            inputs=[results_state, min_confidence],\n",
    "            outputs=[network_plot]\n",
    "        )\n",
    "        \n",
    "        # Filter concepts by importance\n",
    "        concepts_filter.change(\n",
    "            fn=update_concepts_display,\n",
    "            inputs=[results_state, concepts_filter],\n",
    "            outputs=[concepts_table]\n",
    "        )\n",
    "        \n",
    "        # Refresh visualization\n",
    "        refresh_viz_btn.click(\n",
    "            fn=update_visualization,\n",
    "            inputs=[results_state, min_confidence],\n",
    "            outputs=[network_plot]\n",
    "        )\n",
    "        \n",
    "        # Update system settings\n",
    "        apply_settings_btn.click(\n",
    "            fn=update_config,\n",
    "            inputs=[\n",
    "                settings_analysis_mode, chunk_size, chunk_overlap, \n",
    "                min_importance, max_concepts, relationship_confidence, max_relationships\n",
    "            ],\n",
    "            outputs=[results_state, settings_status]\n",
    "        )\n",
    "    \n",
    "    # Launch the app\n",
    "    app.launch(inline=True, share=False)\n",
    "\n",
    "# Launch with error handling\n",
    "try:\n",
    "    launch_litsynth_ui()\n",
    "    show(\"UI launched successfully\", \"success\")\n",
    "except Exception as e:\n",
    "    show(\"UI launch failed: \" + str(e), \"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Temp] Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic code to identify cache serialization issues\n",
    "import json, os, time, hashlib\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "\n",
    "# Create a simple test model\n",
    "class TestModel(BaseModel):\n",
    "    name: str\n",
    "    value: int\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "\n",
    "# Set up a test cache\n",
    "CACHE_DIR = \"./test_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# Test models\n",
    "test_model = TestModel(name=\"Test Item\", value=42, tags=[\"test\", \"diagnostics\"])\n",
    "test_list = [\n",
    "    TestModel(name=\"Item 1\", value=10, tags=[\"first\"]),\n",
    "    TestModel(name=\"Item 2\", value=20, tags=[\"second\"])\n",
    "]\n",
    "\n",
    "# Functions to check\n",
    "def cache_key(**kwargs):\n",
    "    serialized = json.dumps({k: v for k, v in kwargs.items() if v is not None}, sort_keys=True)\n",
    "    return hashlib.md5(serialized.encode()).hexdigest()\n",
    "\n",
    "def basic_set_cache(key, value):\n",
    "    \"\"\"Basic version with no special handling\"\"\"\n",
    "    path = os.path.join(CACHE_DIR, f\"{key}_basic.json\")\n",
    "    try:\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump({\"timestamp\": time.time(), \"value\": value}, f)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Basic cache error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def model_dump_cache(key, value):\n",
    "    \"\"\"Version with model_dump\"\"\"\n",
    "    path = os.path.join(CACHE_DIR, f\"{key}_dump.json\")\n",
    "    try:\n",
    "        # Convert Pydantic models to dict\n",
    "        def convert_model(obj):\n",
    "            if hasattr(obj, 'model_dump'):\n",
    "                return obj.model_dump()\n",
    "            elif isinstance(obj, list):\n",
    "                return [convert_model(item) for item in obj]\n",
    "            elif isinstance(obj, dict):\n",
    "                return {k: convert_model(v) for k, v in obj.items()}\n",
    "            return obj\n",
    "            \n",
    "        with open(path, 'w') as f:\n",
    "            json.dump({\"timestamp\": time.time(), \"value\": convert_model(value)}, f)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Model dump cache error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def get_cache(key, suffix):\n",
    "    \"\"\"Get from cache\"\"\"\n",
    "    path = os.path.join(CACHE_DIR, f\"{key}_{suffix}.json\")\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)[\"value\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Get cache error ({suffix}): {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run diagnostics\n",
    "print(\"=== CACHE DIAGNOSTICS ===\")\n",
    "print(f\"Test model: {test_model}\")\n",
    "print(f\"Type: {type(test_model)}\")\n",
    "print(f\"Has model_dump: {hasattr(test_model, 'model_dump')}\")\n",
    "print(f\"Has dict method: {hasattr(test_model, 'dict')}\")\n",
    "\n",
    "# Generate keys\n",
    "single_key = cache_key(model=\"single\")\n",
    "list_key = cache_key(model=\"list\")\n",
    "\n",
    "# Test basic caching (expect failure)\n",
    "print(\"\\n=== BASIC CACHE TEST ===\")\n",
    "basic_result_single = basic_set_cache(single_key, test_model)\n",
    "basic_result_list = basic_set_cache(list_key, test_list)\n",
    "print(f\"Basic cache single model: {'Success' if basic_result_single else 'Failed'}\")\n",
    "print(f\"Basic cache model list: {'Success' if basic_result_list else 'Failed'}\")\n",
    "\n",
    "# Test model_dump caching\n",
    "print(\"\\n=== MODEL DUMP CACHE TEST ===\")\n",
    "dump_result_single = model_dump_cache(single_key, test_model)\n",
    "dump_result_list = model_dump_cache(list_key, test_list)\n",
    "print(f\"Model dump cache single: {'Success' if dump_result_single else 'Failed'}\")\n",
    "print(f\"Model dump cache list: {'Success' if dump_result_list else 'Failed'}\")\n",
    "\n",
    "# Test retrieving\n",
    "print(\"\\n=== RETRIEVAL TEST ===\")\n",
    "# Try to get data (only the model_dump version should have worked)\n",
    "retrieved_data = get_cache(single_key, \"dump\")\n",
    "print(f\"Retrieved data: {retrieved_data}\")\n",
    "print(f\"Retrieved type: {type(retrieved_data)}\")\n",
    "\n",
    "# Test if we can access attributes directly (should fail with dict)\n",
    "print(\"\\n=== ATTRIBUTE ACCESS TEST ===\")\n",
    "try:\n",
    "    name = retrieved_data.name\n",
    "    print(f\"Direct access succeeded: {name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Direct access failed: {str(e)}\")\n",
    "\n",
    "# Test recreating models from cached data\n",
    "print(\"\\n=== MODEL RECONSTRUCTION TEST ===\")\n",
    "try:\n",
    "    reconstructed = TestModel(**retrieved_data)\n",
    "    print(f\"Reconstructed: {reconstructed}\")\n",
    "    print(f\"Can access attribute: {reconstructed.name}\")\n",
    "    print(f\"Is same type: {type(reconstructed) == type(test_model)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Reconstruction failed: {str(e)}\")\n",
    "\n",
    "# Test with list\n",
    "print(\"\\n=== LIST RECONSTRUCTION TEST ===\")\n",
    "retrieved_list = get_cache(list_key, \"dump\")\n",
    "try:\n",
    "    if retrieved_list:\n",
    "        reconstructed_list = [TestModel(**item) for item in retrieved_list]\n",
    "        print(f\"Reconstructed list length: {len(reconstructed_list)}\")\n",
    "        print(f\"First item: {reconstructed_list[0]}\")\n",
    "        print(f\"Can access attribute: {reconstructed_list[0].name}\")\n",
    "except Exception as e:\n",
    "    print(f\"List reconstruction failed: {str(e)}\")\n",
    "\n",
    "print(\"\\n=== DIAGNOSIS COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Testing & Evaluation Framework\n",
    "\"\"\"\n",
    "This modular testing framework evaluates LLM function performance.\n",
    "You can extend it with custom test cases and metrics.\n",
    "\n",
    "EXTENSIBILITY FEATURES:\n",
    "1. Add new test cases by creating TestCase subclasses\n",
    "2. Define custom metrics by adding to the MetricsCollector\n",
    "3. Modify UI display with custom result formatters\n",
    "\"\"\"\n",
    "\n",
    "import time, json, uuid, re, tempfile, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr\n",
    "from typing import Dict, List, Any, Optional, Tuple, Callable, Union, Type\n",
    "from IPython.display import Markdown, display, HTML\n",
    "import tiktoken\n",
    "from enum import Enum\n",
    "\n",
    "# ===== CORE METRICS SYSTEM =====\n",
    "\n",
    "class MetricsCollector:\n",
    "    \"\"\"Collects and aggregates metrics for LLM function evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset all metrics\"\"\"\n",
    "        self.calls = []\n",
    "        self.total_tokens = 0\n",
    "        self.token_cost = 0\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def record_call(self, function_name: str, duration: float, tokens: int = 0, \n",
    "                   success: bool = True, metadata: Dict = None):\n",
    "        \"\"\"Record an LLM function call with metrics\"\"\"\n",
    "        self.calls.append({\n",
    "            \"function\": function_name,\n",
    "            \"duration\": duration,\n",
    "            \"tokens\": tokens,\n",
    "            \"success\": success,\n",
    "            \"timestamp\": time.time() - self.start_time,\n",
    "            \"metadata\": metadata or {}\n",
    "        })\n",
    "        self.total_tokens += tokens\n",
    "        \n",
    "        # Estimate cost (very rough approximation)\n",
    "        # Can be extended with more precise model-specific costs\n",
    "        self.token_cost += tokens * 0.00001\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get aggregated statistics\"\"\"\n",
    "        if not self.calls:\n",
    "            return {\n",
    "                \"calls\": 0, \n",
    "                \"avg_duration\": 0, \n",
    "                \"max_duration\": 0,\n",
    "                \"total_tokens\": 0,\n",
    "                \"success_rate\": 0,\n",
    "                \"est_cost\": \"$0.00\"\n",
    "            }\n",
    "        \n",
    "        durations = [c[\"duration\"] for c in self.calls]\n",
    "        success_count = sum(1 for c in self.calls if c[\"success\"])\n",
    "        \n",
    "        return {\n",
    "            \"calls\": len(self.calls),\n",
    "            \"avg_duration\": sum(durations) / len(durations),\n",
    "            \"max_duration\": max(durations),\n",
    "            \"total_tokens\": self.total_tokens,\n",
    "            \"success_rate\": success_count / len(self.calls) if self.calls else 0,\n",
    "            \"est_cost\": f\"${self.token_cost:.4f}\"\n",
    "        }\n",
    "    \n",
    "    def get_function_stats(self) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"Get statistics broken down by function\"\"\"\n",
    "        if not self.calls:\n",
    "            return {}\n",
    "            \n",
    "        functions = {}\n",
    "        for call in self.calls:\n",
    "            func_name = call[\"function\"]\n",
    "            if func_name not in functions:\n",
    "                functions[func_name] = {\n",
    "                    \"calls\": 0,\n",
    "                    \"durations\": [],\n",
    "                    \"tokens\": 0,\n",
    "                    \"successes\": 0\n",
    "                }\n",
    "            \n",
    "            functions[func_name][\"calls\"] += 1\n",
    "            functions[func_name][\"durations\"].append(call[\"duration\"])\n",
    "            functions[func_name][\"tokens\"] += call[\"tokens\"]\n",
    "            if call[\"success\"]:\n",
    "                functions[func_name][\"successes\"] += 1\n",
    "        \n",
    "        # Calculate aggregates\n",
    "        for name, data in functions.items():\n",
    "            data[\"avg_duration\"] = sum(data[\"durations\"]) / len(data[\"durations\"])\n",
    "            data[\"max_duration\"] = max(data[\"durations\"])\n",
    "            data[\"success_rate\"] = data[\"successes\"] / data[\"calls\"]\n",
    "            data[\"durations\"] = None  # Remove raw data\n",
    "            \n",
    "        return functions\n",
    "\n",
    "# Global metrics collector\n",
    "metrics = MetricsCollector()\n",
    "\n",
    "# ===== TOKEN ESTIMATION =====\n",
    "\n",
    "def estimate_tokens(text_or_obj: Any) -> int:\n",
    "    \"\"\"Estimate token count for OpenAI models with various input types\"\"\"\n",
    "    if not text_or_obj:\n",
    "        return 0\n",
    "    \n",
    "    # Convert to string based on type\n",
    "    if isinstance(text_or_obj, str):\n",
    "        text = text_or_obj\n",
    "    elif isinstance(text_or_obj, list):\n",
    "        if not text_or_obj:\n",
    "            return 0\n",
    "        # Sample up to 3 items and extrapolate\n",
    "        samples = min(3, len(text_or_obj))\n",
    "        sample_text = \"\".join(str(item) for item in text_or_obj[:samples])\n",
    "        tokens_per_item = estimate_tokens(sample_text) / samples\n",
    "        return int(tokens_per_item * len(text_or_obj))\n",
    "    else:\n",
    "        # For other objects, convert to string representation\n",
    "        text = str(text_or_obj)\n",
    "    \n",
    "    # Estimate tokens\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "        return len(encoding.encode(text))\n",
    "    except:\n",
    "        # Fallback estimation\n",
    "        return len(text.split()) * 1.3\n",
    "\n",
    "# ===== TEST RESULT MODEL =====\n",
    "\n",
    "class TestStatus(Enum):\n",
    "    PENDING = \"pending\"\n",
    "    SUCCESS = \"success\"\n",
    "    FAILURE = \"failure\"\n",
    "    SKIPPED = \"skipped\"\n",
    "\n",
    "class TestResult:\n",
    "    \"\"\"Holds results and metrics for a single test\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, description: str = \"\"):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.latency = 0\n",
    "        self.status = TestStatus.PENDING\n",
    "        self.output = None\n",
    "        self.error = None\n",
    "        self.details = {}\n",
    "        self.tokens = 0\n",
    "    \n",
    "    def mark_success(self, output: Any = None, details: Dict = None):\n",
    "        \"\"\"Mark test as successful\"\"\"\n",
    "        self.status = TestStatus.SUCCESS\n",
    "        self.output = output\n",
    "        if details:\n",
    "            self.details.update(details)\n",
    "    \n",
    "    def mark_failure(self, error: str, output: Any = None):\n",
    "        \"\"\"Mark test as failed\"\"\"\n",
    "        self.status = TestStatus.FAILURE\n",
    "        self.error = error\n",
    "        self.output = output\n",
    "    \n",
    "    def mark_skipped(self, reason: str = \"Dependency failed\"):\n",
    "        \"\"\"Mark test as skipped\"\"\"\n",
    "        self.status = TestStatus.SKIPPED\n",
    "        self.error = reason\n",
    "    \n",
    "    def add_detail(self, key: str, value: Any):\n",
    "        \"\"\"Add a detail to the result\"\"\"\n",
    "        self.details[key] = value\n",
    "    \n",
    "    def is_success(self) -> bool:\n",
    "        \"\"\"Check if test was successful\"\"\"\n",
    "        return self.status == TestStatus.SUCCESS\n",
    "    \n",
    "    def get_status_icon(self) -> str:\n",
    "        \"\"\"Get status icon for display\"\"\"\n",
    "        icons = {\n",
    "            TestStatus.SUCCESS: \"✅\",\n",
    "            TestStatus.FAILURE: \"❌\",\n",
    "            TestStatus.PENDING: \"⏳\",\n",
    "            TestStatus.SKIPPED: \"⏭️\"\n",
    "        }\n",
    "        return icons.get(self.status, \"❓\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for display\"\"\"\n",
    "        return {\n",
    "            \"Name\": self.name,\n",
    "            \"Status\": f\"{self.get_status_icon()} {self.status.value}\",\n",
    "            \"Latency\": f\"{self.latency:.2f}s\",\n",
    "            \"Tokens\": self.tokens,\n",
    "            \"Details\": self.details,\n",
    "            \"Error\": self.error\n",
    "        }\n",
    "\n",
    "# ===== TEST CASE BASE CLASSES =====\n",
    "\n",
    "class TestCase:\n",
    "    \"\"\"Base class for all test cases\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, description: str = \"\"):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.result = TestResult(name, description)\n",
    "    \n",
    "    def run(self) -> TestResult:\n",
    "        \"\"\"Run the test case\"\"\"\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            self._execute()\n",
    "            self.result.latency = time.time() - start_time\n",
    "            return self.result\n",
    "        except Exception as e:\n",
    "            self.result.mark_failure(f\"Unexpected error: {str(e)}\")\n",
    "            self.result.latency = time.time() - start_time\n",
    "            return self.result\n",
    "    \n",
    "    def _execute(self):\n",
    "        \"\"\"Implement test logic in subclasses\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement _execute\")\n",
    "\n",
    "class FunctionTestCase(TestCase):\n",
    "    \"\"\"Test case for evaluating a function\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, func: Callable, args: List = None, \n",
    "                kwargs: Dict = None, description: str = \"\"):\n",
    "        super().__init__(name, description)\n",
    "        self.func = func\n",
    "        self.args = args or []\n",
    "        self.kwargs = kwargs or {}\n",
    "        self.is_llm_function = name in [\"extract_concepts\", \"identify_relationships\", \n",
    "                                        \"identify_research_gaps\", \"generate_synthesis\"]\n",
    "    \n",
    "    def _execute(self):\n",
    "        \"\"\"Execute function and record metrics\"\"\"\n",
    "        try:\n",
    "            # Run the function\n",
    "            result = self.func(*self.args, **self.kwargs)\n",
    "            \n",
    "            # Calculate token usage for LLM functions\n",
    "            tokens = 0\n",
    "            if self.is_llm_function:\n",
    "                # Estimate input tokens\n",
    "                input_tokens = sum(estimate_tokens(arg) for arg in self.args \n",
    "                                  if isinstance(arg, (str, list)))\n",
    "                \n",
    "                # Estimate output tokens\n",
    "                output_tokens = estimate_tokens(result)\n",
    "                tokens = input_tokens + output_tokens\n",
    "                \n",
    "                # Record metrics\n",
    "                metrics.record_call(\n",
    "                    self.name, \n",
    "                    self.result.latency, \n",
    "                    tokens=tokens, \n",
    "                    success=True\n",
    "                )\n",
    "                \n",
    "            self.result.tokens = tokens\n",
    "            \n",
    "            # Add appropriate details based on result type\n",
    "            if isinstance(result, str):\n",
    "                self.result.add_detail(\"length\", len(result))\n",
    "                if len(result) > 50:\n",
    "                    self.result.add_detail(\"excerpt\", result[:50] + \"...\")\n",
    "            elif isinstance(result, list):\n",
    "                self.result.add_detail(\"count\", len(result))\n",
    "                if result:\n",
    "                    if hasattr(result[0], \"name\"):\n",
    "                        self.result.add_detail(\"samples\", \", \".join([item.name for item in result[:3]]))\n",
    "                    elif hasattr(result[0], \"description\"):\n",
    "                        self.result.add_detail(\"samples\", result[0].description[:50] + \"...\")\n",
    "            \n",
    "            # Mark success\n",
    "            self.result.mark_success(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Record failure\n",
    "            if self.is_llm_function:\n",
    "                metrics.record_call(\n",
    "                    self.name, \n",
    "                    self.result.latency, \n",
    "                    tokens=0, \n",
    "                    success=False\n",
    "                )\n",
    "            \n",
    "            self.result.mark_failure(str(e))\n",
    "\n",
    "# ===== TEST SUITE =====\n",
    "\n",
    "class TestSuite:\n",
    "    \"\"\"Collection of test cases with dependencies\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.test_cases = []\n",
    "        self.results = []\n",
    "        \n",
    "    def add_test(self, test_case: TestCase):\n",
    "        \"\"\"Add a test case to the suite\"\"\"\n",
    "        self.test_cases.append(test_case)\n",
    "        return self\n",
    "        \n",
    "    def run(self) -> List[TestResult]:\n",
    "        \"\"\"Run all test cases in the suite\"\"\"\n",
    "        self.results = []\n",
    "        metrics.reset()\n",
    "        \n",
    "        for test_case in self.test_cases:\n",
    "            result = test_case.run()\n",
    "            self.results.append(result)\n",
    "            \n",
    "        return self.results\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get aggregated statistics\"\"\"\n",
    "        return metrics.get_stats()\n",
    "\n",
    "# ===== DOCUMENT TEST SUITE =====\n",
    "\n",
    "class DocumentAnalysisSuite(TestSuite):\n",
    "    \"\"\"Test suite for document analysis functions\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"Document Analysis\"):\n",
    "        super().__init__(name)\n",
    "        \n",
    "    @classmethod\n",
    "    def create_sample_suite(cls):\n",
    "        \"\"\"Create a test suite with the reliable sample text\"\"\"\n",
    "        suite = cls(\"Sample Text Analysis\")\n",
    "        \n",
    "        RELIABLE_SAMPLE = \"\"\"\n",
    "        RNA sequencing (RNA-Seq) is a technique for analyzing gene expression patterns.\n",
    "        It involves extracting RNA from biological samples, converting to cDNA, and \n",
    "        sequencing using next-generation platforms. This enables identification of \n",
    "        differentially expressed genes between conditions. RNA-Seq allows for the \n",
    "        detection of novel transcripts, alternative splicing events, and genetic variations.\n",
    "        The methodology typically includes quality control, read alignment to a reference\n",
    "        genome, quantification of expression levels, and differential expression analysis.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create config\n",
    "        config = LitSynthConfig() if 'LitSynthConfig' in globals() else None\n",
    "        \n",
    "        # Add concept extraction test\n",
    "        suite.add_test(FunctionTestCase(\n",
    "            \"extract_concepts\", \n",
    "            extract_concepts,\n",
    "            [RELIABLE_SAMPLE, config],\n",
    "            description=\"Extract key concepts from sample text\"\n",
    "        ))\n",
    "        \n",
    "        # Make other tests dependent on concept extraction\n",
    "        def add_dependent_tests(results):\n",
    "            concepts = results[0].output if results and results[0].is_success() else []\n",
    "            \n",
    "            if concepts:\n",
    "                # Add relationship test\n",
    "                suite.add_test(FunctionTestCase(\n",
    "                    \"identify_relationships\",\n",
    "                    identify_relationships,\n",
    "                    [RELIABLE_SAMPLE, concepts, config],\n",
    "                    description=\"Identify relationships between concepts\"\n",
    "                ))\n",
    "                \n",
    "                # Add gaps test (depends on relationships)\n",
    "                relationships = results[1].output if len(results) > 1 and results[1].is_success() else []\n",
    "                if relationships:\n",
    "                    suite.add_test(FunctionTestCase(\n",
    "                        \"identify_research_gaps\",\n",
    "                        identify_research_gaps,\n",
    "                        [RELIABLE_SAMPLE, concepts, relationships],\n",
    "                        description=\"Identify research gaps\"\n",
    "                    ))\n",
    "                    \n",
    "                    # Add synthesis test (depends on gaps)\n",
    "                    gaps = results[2].output if len(results) > 2 and results[2].is_success() else []\n",
    "                    suite.add_test(FunctionTestCase(\n",
    "                        \"generate_synthesis\",\n",
    "                        generate_synthesis,\n",
    "                        [RELIABLE_SAMPLE, concepts, relationships, gaps],\n",
    "                        description=\"Generate research synthesis\"\n",
    "                    ))\n",
    "        \n",
    "        # Store the callback for executing after initial test\n",
    "        suite.add_dependent_tests = add_dependent_tests\n",
    "        \n",
    "        return suite\n",
    "    \n",
    "    @classmethod\n",
    "    def create_pdf_suite(cls, pdf_path: str):\n",
    "        \"\"\"Create a test suite for a PDF document\"\"\"\n",
    "        suite = cls(f\"PDF Analysis: {os.path.basename(pdf_path)}\")\n",
    "        \n",
    "        # Create config\n",
    "        config = LitSynthConfig() if 'LitSynthConfig' in globals() else None\n",
    "        \n",
    "        # Add document loading test\n",
    "        suite.add_test(FunctionTestCase(\n",
    "            \"load_document\",\n",
    "            load_document,\n",
    "            [\"pdf\", pdf_path],\n",
    "            description=\"Load document from PDF\"\n",
    "        ))\n",
    "        \n",
    "        # Make other tests dependent on document loading\n",
    "        def add_dependent_tests(results):\n",
    "            doc_data = results[0].output if results and results[0].is_success() else {}\n",
    "            \n",
    "            if doc_data and \"text\" in doc_data:\n",
    "                text = doc_data[\"text\"]\n",
    "                \n",
    "                # Add chunking test\n",
    "                suite.add_test(FunctionTestCase(\n",
    "                    \"chunk_text\",\n",
    "                    chunk_text,\n",
    "                    [text, config],\n",
    "                    description=\"Split text into chunks\"\n",
    "                ))\n",
    "                \n",
    "                # Check if chunking succeeded and process the first chunk\n",
    "                chunks = results[1].output if len(results) > 1 and results[1].is_success() else []\n",
    "                if chunks:\n",
    "                    # Use first chunk for analysis\n",
    "                    test_text = chunks[0]\n",
    "                    \n",
    "                    # Add concept extraction\n",
    "                    suite.add_test(FunctionTestCase(\n",
    "                        \"extract_concepts\",\n",
    "                        extract_concepts,\n",
    "                        [test_text, config],\n",
    "                        description=\"Extract key concepts\"\n",
    "                    ))\n",
    "                    \n",
    "                    # Continue with dependent tests if concepts were found\n",
    "                    concepts = results[2].output if len(results) > 2 and results[2].is_success() else []\n",
    "                    if concepts:\n",
    "                        # Add relationship identification\n",
    "                        suite.add_test(FunctionTestCase(\n",
    "                            \"identify_relationships\",\n",
    "                            identify_relationships,\n",
    "                            [test_text, concepts, config],\n",
    "                            description=\"Identify relationships\"\n",
    "                        ))\n",
    "                        \n",
    "                        # Continue with gaps and synthesis...\n",
    "                        relationships = results[3].output if len(results) > 3 and results[3].is_success() else []\n",
    "                        if relationships:\n",
    "                            suite.add_test(FunctionTestCase(\n",
    "                                \"identify_research_gaps\",\n",
    "                                identify_research_gaps,\n",
    "                                [test_text, concepts, relationships],\n",
    "                                description=\"Identify research gaps\"\n",
    "                            ))\n",
    "                            \n",
    "                            gaps = results[4].output if len(results) > 4 and results[4].is_success() else []\n",
    "                            suite.add_test(FunctionTestCase(\n",
    "                                \"generate_synthesis\",\n",
    "                                generate_synthesis,\n",
    "                                [test_text, concepts, relationships, gaps],\n",
    "                                description=\"Generate synthesis\"\n",
    "                            ))\n",
    "        \n",
    "        # Store the callback for executing after initial tests\n",
    "        suite.add_dependent_tests = add_dependent_tests\n",
    "        \n",
    "        return suite\n",
    "    \n",
    "    def run(self) -> List[TestResult]:\n",
    "        \"\"\"Run tests with dependency management\"\"\"\n",
    "        self.results = []\n",
    "        metrics.reset()\n",
    "        \n",
    "        # First run the initial test cases\n",
    "        initial_tests = self.test_cases[:1]  # First test\n",
    "        for test in initial_tests:\n",
    "            result = test.run()\n",
    "            self.results.append(result)\n",
    "        \n",
    "        # Add dependent tests based on results of initial tests\n",
    "        if hasattr(self, 'add_dependent_tests'):\n",
    "            self.add_dependent_tests(self.results)\n",
    "        \n",
    "        # Run any new tests that were added\n",
    "        for test in self.test_cases[len(self.results):]:\n",
    "            result = test.run()\n",
    "            self.results.append(result)\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "# ===== RESULTS VISUALIZATION =====\n",
    "\n",
    "def format_results_table(results: List[TestResult]) -> str:\n",
    "    \"\"\"Format test results as HTML table\"\"\"\n",
    "    html = \"\"\"\n",
    "    <style>\n",
    "    .test-table {\n",
    "        width: 100%;\n",
    "        border-collapse: collapse;\n",
    "        margin: 20px 0;\n",
    "        font-family: inherit;\n",
    "    }\n",
    "    .test-table th, .test-table td {\n",
    "        padding: 8px 12px;\n",
    "        text-align: left;\n",
    "        border-bottom: 1px solid #ddd;\n",
    "    }\n",
    "    .test-table th {\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    .success {\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    .failure {\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    .skipped {\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    .metrics {\n",
    "        padding: 10px 15px;\n",
    "        border-radius: 5px;\n",
    "        margin-bottom: 15px;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    # Get metrics\n",
    "    stats = metrics.get_stats()\n",
    "    html += f\"\"\"\n",
    "    <div class=\"metrics\">\n",
    "        <h3>Test Summary</h3>\n",
    "        <p>\n",
    "            <strong>LLM Calls:</strong> {stats['calls']} | \n",
    "            <strong>Avg Time:</strong> {stats['avg_duration']:.2f}s | \n",
    "            <strong>Total Tokens:</strong> {stats['total_tokens']:,} |\n",
    "            <strong>Est. Cost:</strong> {stats['est_cost']}\n",
    "        </p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create table\n",
    "    html += \"\"\"\n",
    "    <table class=\"test-table\">\n",
    "        <tr>\n",
    "            <th>Function</th>\n",
    "            <th>Status</th>\n",
    "            <th>Latency</th>\n",
    "            <th>Tokens</th>\n",
    "            <th>Details</th>\n",
    "        </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add rows\n",
    "    for result in results:\n",
    "        status_class = {\n",
    "            TestStatus.SUCCESS: \"success\",\n",
    "            TestStatus.FAILURE: \"failure\",\n",
    "            TestStatus.SKIPPED: \"skipped\",\n",
    "            TestStatus.PENDING: \"\"\n",
    "        }.get(result.status, \"\")\n",
    "        \n",
    "        details = \"<br>\".join([f\"<strong>{k}:</strong> {v}\" for k, v in result.details.items()])\n",
    "        if result.error:\n",
    "            details += f\"<br><strong>Error:</strong> <span class='failure'>{result.error}</span>\"\n",
    "            \n",
    "        token_count = f\"{result.tokens:,}\" if result.tokens > 0 else \"-\"\n",
    "        \n",
    "        html += f\"\"\"\n",
    "        <tr>\n",
    "            <td>{result.name}</td>\n",
    "            <td class=\"{status_class}\">{result.get_status_icon()} {result.status.value}</td>\n",
    "            <td>{result.latency:.2f}s</td>\n",
    "            <td>{token_count}</td>\n",
    "            <td>{details}</td>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html += \"</table>\"\n",
    "    return html\n",
    "\n",
    "# ===== TEST INTERFACE =====\n",
    "\n",
    "def create_test_interface():\n",
    "    \"\"\"Create Gradio interface for testing\"\"\"\n",
    "    \n",
    "    def run_sample_test():\n",
    "        \"\"\"Run tests on sample text\"\"\"\n",
    "        suite = DocumentAnalysisSuite.create_sample_suite()\n",
    "        results = suite.run()\n",
    "        return format_results_table(results)\n",
    "    \n",
    "    def run_pdf_test(pdf_file):\n",
    "        \"\"\"Run tests on uploaded PDF\"\"\"\n",
    "        if not pdf_file:\n",
    "            return \"Please upload a PDF file.\"\n",
    "            \n",
    "        # Save to temp file\n",
    "        temp_path = os.path.join(tempfile.mkdtemp(), \"test.pdf\")\n",
    "        with open(pdf_file.name, \"rb\") as src:\n",
    "            with open(temp_path, \"wb\") as dest:\n",
    "                dest.write(src.read())\n",
    "        \n",
    "        # Run tests\n",
    "        suite = DocumentAnalysisSuite.create_pdf_suite(temp_path)\n",
    "        results = suite.run()\n",
    "        return format_results_table(results)\n",
    "    \n",
    "    # Create interface\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Literature Synthesis Testing Framework\")\n",
    "        gr.Markdown(\"Evaluate LLM function performance with standardized tests\")\n",
    "        \n",
    "        with gr.Tabs() as tabs:\n",
    "            with gr.Tab(\"Sample Test\"):\n",
    "                gr.Markdown(\"\"\"\n",
    "                Run tests using a reliable sample text to verify basic functionality.\n",
    "                This is useful for quick validation of the system.\n",
    "                \"\"\")\n",
    "                sample_btn = gr.Button(\"Run Sample Test\", variant=\"primary\")\n",
    "                sample_results = gr.HTML(\"Click the button to run sample tests\")\n",
    "                \n",
    "                sample_btn.click(\n",
    "                    fn=run_sample_test,\n",
    "                    outputs=sample_results\n",
    "                )\n",
    "            \n",
    "            with gr.Tab(\"PDF Test\"):\n",
    "                gr.Markdown(\"\"\"\n",
    "                Upload a PDF document to test the full document analysis pipeline.\n",
    "                This evaluates all components with a real-world document.\n",
    "                \"\"\")\n",
    "                pdf_input = gr.File(\n",
    "                    label=\"Upload PDF Document\",\n",
    "                    file_types=[\".pdf\"]\n",
    "                )\n",
    "                pdf_btn = gr.Button(\"Run PDF Test\", variant=\"primary\")\n",
    "                pdf_results = gr.HTML(\"Upload a PDF and click the button to run tests\")\n",
    "                \n",
    "                pdf_btn.click(\n",
    "                    fn=run_pdf_test,\n",
    "                    inputs=[pdf_input],\n",
    "                    outputs=pdf_results\n",
    "                )\n",
    "                \n",
    "            with gr.Tab(\"Custom Test\"):\n",
    "                gr.Markdown(\"\"\"\n",
    "                #### How to Create Custom Tests\n",
    "                \n",
    "                Add custom test cases by extending the framework:\n",
    "                \n",
    "                ```python\n",
    "                # Example: Create a custom test case\n",
    "                class MyCustomTest(TestCase):\n",
    "                    def _execute(self):\n",
    "                        # Implement your test logic here\n",
    "                        result = my_function()\n",
    "                        if result:\n",
    "                            self.result.mark_success(result)\n",
    "                        else:\n",
    "                            self.result.mark_failure(\"Test failed\")\n",
    "                \n",
    "                # Run your custom test\n",
    "                test = MyCustomTest(\"custom_test\", \"My custom test description\")\n",
    "                result = test.run()\n",
    "                print(f\"Test result: {result.status}\")\n",
    "                ```\n",
    "                \n",
    "                View the source code for more examples and extension points.\n",
    "                \"\"\")\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Create and launch the test interface\n",
    "test_interface = create_test_interface()\n",
    "test_interface.launch(inline=True, share=False)\n",
    "\n",
    "# Show confirmation\n",
    "show(\"Testing framework initialized\", \"success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
