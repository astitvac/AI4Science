{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astitvac/AI4Science/blob/main/%5BDemo2%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![IMG-20241117-WA0008.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "n_tcnF-sjYTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# License and Usage"
      ],
      "metadata": {
        "id": "3nPpe9MqmPrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Aavishkar AI for Science Notebook\n",
        "\n",
        "## License and Usage Information\n",
        "¬© 2025 [Aavishkar.ai]\n",
        "This notebook is licensed under the [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).\n",
        "### What You Can Do:\n",
        "- **Share:** You are free to copy and redistribute this material in any medium or format.\n",
        "- **Adapt:** You can remix, transform, and build upon this material for any purpose, including commercial use.\n",
        "### Usage Terms:\n",
        "- **Attribution:** When using or adapting this notebook, you must give appropriate credit to Aavishkar.ai, provide a link to the license, and indicate if any changes were made.\n",
        "### Important Note:\n",
        "This notebook is provided \"as is\", without any warranties or guarantees, either expressed or implied. Users are responsible for how they use and implement the content within.\n",
        "\n",
        "For any questions or issues, please contact [astitvac@gmail.com]\n",
        "'''"
      ],
      "metadata": {
        "id": "TBD37wOamKLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YW0EpIMV84l"
      },
      "source": [
        "---\n",
        "\n",
        "## **Welcome to the AI4Art Notebook**\n",
        "\n",
        "### **üé® What is AI4Art?**\n",
        "AI4Art is an intelligent system designed to evaluate artwork and artists based on project-specific criteria. It uses advanced Large Language Model Execution Logic (LCEL) chains to:\n",
        "- Generate project evaluation criteria.\n",
        "- Assess artwork and artist suitability.\n",
        "- Provide actionable recommendations.\n",
        "\n",
        "### **üåü Features**\n",
        "1. **Dynamic Prompt Library**: Centralized prompts that can be updated and customized to fit specific projects.\n",
        "2. **Interactive User Interface**: A clean, intuitive interface powered by Gradio for seamless interaction.\n",
        "3. **Comprehensive Evaluation Logic**: Integrates LCEL chains for nuanced and accurate assessments.\n",
        "4. **Configurable Execution**: Allows users to modify configurations like API keys, prompts, and visual styles.\n",
        "\n",
        "---\n",
        "\n",
        "### **üöÄ How LCEL Chains Are Used**\n",
        "LCEL (Large Language Model Execution Logic) chains are the backbone of AI4Art's functionality. Here's a brief overview of how they work:\n",
        "\n",
        "#### **1. Project Criteria Generation**\n",
        "```python\n",
        "criteria_prompt = PromptLibrary.get_project_criteria_prompt()\n",
        "criteria_response = llm.generate_response(criteria_prompt)\n",
        "```\n",
        "- **What it does**: Creates actionable and measurable evaluation criteria for a project.\n",
        "- **User Interaction**: You can modify the prompt via the \"Update Prompts\" section to align with your specific project needs.\n",
        "\n",
        "#### **2. Artwork Evaluation**\n",
        "```python\n",
        "artwork_prompt = PromptLibrary.get_artwork_evaluation_prompt()\n",
        "artwork_response = llm.generate_response(artwork_prompt)\n",
        "```\n",
        "- **What it does**: Evaluates an artwork based on creativity, technical skill, and alignment with project requirements.\n",
        "- **User Interaction**: Use the Gradio interface to provide artwork details and see real-time evaluations.\n",
        "\n",
        "#### **3. Artist Evaluation**\n",
        "```python\n",
        "artist_prompt = PromptLibrary.get_artist_evaluation_prompt()\n",
        "artist_response = llm.generate_response(artist_prompt)\n",
        "```\n",
        "- **What it does**: Assesses the artist's suitability based on experience, style, and skills.\n",
        "- **User Interaction**: Provide artist details and let the system handle the rest.\n",
        "\n",
        "#### **4. Final Recommendation**\n",
        "```python\n",
        "recommendation_prompt = PromptLibrary.get_final_recommendation_prompt()\n",
        "recommendation_response = llm.generate_response(recommendation_prompt)\n",
        "```\n",
        "- **What it does**: Synthesizes all evaluations into a comprehensive recommendation report.\n",
        "- **User Interaction**: Review the final output and take actionable steps based on the system's insights.\n",
        "\n",
        "---\n",
        "\n",
        "### **üí° How to Get Started**\n",
        "1. **Run the Installation Section**: Ensure all dependencies are installed.\n",
        "2. **Set Your API Key**: Add your API key for OpenAI or Google.\n",
        "3. **Explore the Prompt Library**: Customize prompts to align with your project requirements.\n",
        "4. **Interact with the Interface**: Use the Gradio interface to provide input and view outputs.\n",
        "\n",
        "### **üë©‚Äçüé® Customize and Experiment**\n",
        "- Modify prompts using the \"Update Prompts\" section.\n",
        "- Adjust the UI styles in the \"Style Library\" section.\n",
        "- Test and debug using the tools provided.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRvb6_FVknll"
      },
      "source": [
        "# **1. Installation**\n",
        "### **üîß Purpose**:\n",
        "This section installs all the necessary software and dependencies required to run the notebook. It includes Python libraries and any system-level tools needed for the AI4Art system.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- Run the cells in this section to ensure all dependencies are installed.\n",
        "- If a library fails to install, re-run the installation cell or use the error message to troubleshoot.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- You do not need to edit this section unless you want to add or remove specific dependencies.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnhjgPcjlFD3"
      },
      "source": [
        "## Software Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzJlsu9zlHXj",
        "outputId": "9b75f9c6-af50-4fba-bc8f-aea73870281c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-21e4d3f35663>:43: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expert System Environment Verification:\n",
            "-------------------------------------\n",
            "‚úì langchain-community  Version: 0.3.14\n",
            "‚úì langchain-openai     Version: 0.3.0\n",
            "‚úì gradio               Version: 5.12.0\n",
            "‚úì pydantic             Version: 2.10.5\n",
            "\n",
            "Python Version: 3.11.11\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# === Installation Requirements ===\n",
        "\"\"\"\n",
        "Core Expert System Dependencies\n",
        "-----------------------------\n",
        "This installation script establishes the foundational layer for our intelligent\n",
        "processing architecture, ensuring all components are at their latest compatible versions.\n",
        "\n",
        "Key Architectural Layers:\n",
        "1. Knowledge Processing (LangChain components)\n",
        "2. Interface Management (Gradio)\n",
        "3. Data Validation (Pydantic)\n",
        "4. Processing Tools (Scientific computing stack)\n",
        "\"\"\"\n",
        "\n",
        "# Establish base environment\n",
        "!pip install -q pip --upgrade\n",
        "\n",
        "# Core LLM Integration Layer\n",
        "# These form the cognitive backbone of our expert system\n",
        "!pip install -q langchain-community\n",
        "!pip install -q langchain-openai\n",
        "!pip install -q langchain-google-genai\n",
        "!pip install -q langchain-core\n",
        "\n",
        "# Interface Layer\n",
        "# Handles knowledge presentation and interaction\n",
        "!pip install -q gradio\n",
        "!pip install -q pydantic\n",
        "\n",
        "# Data Processing Layer\n",
        "# Scientific computing stack for knowledge manipulation\n",
        "!pip install -q pandas\n",
        "!pip install -q numpy\n",
        "!pip install -q pillow\n",
        "!pip install -q matplotlib\n",
        "\n",
        "# Auxiliary Tools\n",
        "# Supporting components for enhanced functionality\n",
        "!pip install -q python-dotenv\n",
        "!pip install -q faiss-cpu\n",
        "\n",
        "# Optional but recommended: Add version checking\n",
        "import pkg_resources\n",
        "import sys\n",
        "\n",
        "def verify_environment():\n",
        "    \"\"\"Verify core dependencies are properly installed\"\"\"\n",
        "    required_packages = [\n",
        "        'langchain-community',\n",
        "        'langchain-openai',\n",
        "        'gradio',\n",
        "        'pydantic'\n",
        "    ]\n",
        "\n",
        "    print(\"Expert System Environment Verification:\")\n",
        "    print(\"-------------------------------------\")\n",
        "\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            version = pkg_resources.get_distribution(package).version\n",
        "            print(f\"‚úì {package:<20} Version: {version}\")\n",
        "        except pkg_resources.DistributionNotFound:\n",
        "            print(f\"‚úó {package:<20} Not Found!\")\n",
        "\n",
        "    print(\"\\nPython Version:\", sys.version.split()[0])\n",
        "    print(\"-------------------------------------\")\n",
        "\n",
        "# Run verification after installation\n",
        "verify_environment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIT4lZN1lZr1"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fgH7xgz4lbky"
      },
      "outputs": [],
      "source": [
        "# === System Imports ===\n",
        "# Organized by functional layer and system responsibility\n",
        "\n",
        "# === Core System Dependencies ===\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import logging\n",
        "from typing import Dict, List, Any, Optional, Union, Tuple\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "\n",
        "# === LLM Integration ===\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_core.output_parsers import BaseOutputParser\n",
        "\n",
        "# === Knowledge Representation ===\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "\n",
        "# === Data Processing ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# === User Interface ===\n",
        "import gradio as gr\n",
        "\n",
        "# === Environmental Configuration ===\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata  # Only in Colab environment\n",
        "\n",
        "# === Auxiliary Tools ===\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "\n",
        "# === System Configuration ===\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('expert_system.log'),\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EazSn1n2kG_d"
      },
      "source": [
        "# **2. API Key**\n",
        "\n",
        "### **üîë Purpose**:\n",
        "This section sets up API keys for accessing external services like OpenAI or Google APIs.\n",
        "\n",
        "### **üìã How to Find Your OpenAI API Key**:\n",
        "1. Go to the [OpenAI API Keys page](https://platform.openai.com/account/api-keys).\n",
        "2. Log in with your OpenAI account.\n",
        "3. Click **Create new secret key** to generate an API key.\n",
        "4. Copy the key and save it securely.\n",
        "   - For Colab users, add it to Colab secrets using: `!echo \"OPENAI_API_KEY=your_key_here\" > /root/.openai_key`.\n",
        "   - For local users, save it in a `.env` file: `OPENAI_API_KEY=your_key_here`.\n",
        "\n",
        "### **üìã How to Find Your Google API Key**:\n",
        "1. Visit the [Google Cloud Console](https://console.cloud.google.com/).\n",
        "2. Select or create a new project.\n",
        "3. Navigate to **APIs & Services** > **Credentials**.\n",
        "4. Click **Create Credentials** > **API Key**.\n",
        "5. Copy the generated API key.\n",
        "   - For Colab users, add it to Colab secrets using: `!echo \"GOOGLE_API_KEY=your_key_here\" > /root/.google_key`.\n",
        "   - For local users, save it in a `.env` file: `GOOGLE_API_KEY=your_key_here`.\n",
        "\n",
        "### **üìã Learn About the Google Gemini API**:\n",
        "For advanced functionality, you can explore and utilize the Google Gemini API. Visit the [Gemini API Documentation](https://ai.google.dev/gemini-api/docs?_gl=1*1p2nyq9*_ga*MTQ0Nzc3NTY1MC4xNzM0NjUxMjk3*_ga_P1DBVKWT6V*MTczNjk4ODMzNy44LjAuMTczNjk4ODM1OC4zOS4wLjExODk4MTQ3NDA) to learn more about its capabilities and integration steps.\n",
        "1. Visit the [Google Cloud Console](https://console.cloud.google.com/).\n",
        "2. Select or create a new project.\n",
        "3. Navigate to **APIs & Services** > **Credentials**.\n",
        "4. Click **Create Credentials** > **API Key**.\n",
        "5. Copy the generated API key.\n",
        "   - For Colab users, add it to Colab secrets using: `!echo \"GOOGLE_API_KEY=your_key_here\" > /root/.google_key`.\n",
        "   - For local users, save it in a `.env` file: `GOOGLE_API_KEY=your_key_here`.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Replace placeholder values with your actual API key.\n",
        "- Choose between OpenAI or Google as the provider by editing the form field.\n",
        "\n",
        "### **üîë Purpose**:\n",
        "This section sets up API keys for accessing external services like OpenAI or Google APIs.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- Ensure you have an API key for the selected provider (e.g., OpenAI or Google).\n",
        "- Colab users: Add your API key to Colab secrets.\n",
        "- Local users: Store your API key in a `.env` file.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Replace placeholder values with your actual API key.\n",
        "- Choose between OpenAI or Google as the provider by editing the form field.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0veiVZrgPSH",
        "outputId": "269cd545-fbfc-4004-fce9-e8945a75d3da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Expert System Configuration...\n",
            "Configuration Complete ‚úì\n",
            "Provider: Google\n",
            "Models: gemini-2.0-flash-exp (eval) / gemini-2.0-flash-exp (vision)\n"
          ]
        }
      ],
      "source": [
        "# === API Configuration Section ===\n",
        "\n",
        "class APIConfiguration:\n",
        "    \"\"\"\n",
        "    Cognitive system configuration orchestrator implementing environment-aware\n",
        "    parameter management with graceful degradation capabilities.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.environment_type = self._detect_environment()\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # Core system defaults implementing the knowledge configuration pattern\n",
        "        self.default_config = {\n",
        "            \"provider\": \"OpenAI\",\n",
        "            \"evaluation_model\": \"gpt-4o\",  # Aligned with optimized processing model\n",
        "            \"vision_model\": \"gpt-4o\",      # Maintaining visual processing consistency\n",
        "            \"temperature\": 0.7,\n",
        "            \"request_timeout\": 30.0\n",
        "        }\n",
        "\n",
        "    def _detect_environment(self) -> str:\n",
        "        \"\"\"Establish execution context for configuration strategy.\"\"\"\n",
        "        try:\n",
        "            import google.colab\n",
        "            return \"colab\"\n",
        "        except ImportError:\n",
        "            return \"local\"\n",
        "\n",
        "    def _get_provider_key(self, provider: str) -> str:\n",
        "        \"\"\"\n",
        "        Secure credential resolution with environment-specific adaptation.\n",
        "        Implements the secure knowledge access pattern.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.environment_type == \"colab\":\n",
        "                from google.colab import userdata\n",
        "                key_mapping = {\n",
        "                    \"OpenAI\": \"openai_key\",\n",
        "                    \"Google\": \"GOOGLE_API_KEY\"\n",
        "                }\n",
        "                key = userdata.get(key_mapping[provider])\n",
        "            else:\n",
        "                from dotenv import load_dotenv\n",
        "                load_dotenv()\n",
        "                key_mapping = {\n",
        "                    \"OpenAI\": \"OPENAI_API_KEY\",\n",
        "                    \"Google\": \"GOOGLE_API_KEY\"\n",
        "                }\n",
        "                key = os.getenv(key_mapping[provider])\n",
        "\n",
        "            if not key:\n",
        "                raise ValueError(f\"No API key found for {provider}\")\n",
        "            return key\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Key retrieval error: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def configure_system(self) -> Tuple[str, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Intelligent configuration orchestration implementing the adaptive\n",
        "        initialization pattern with environment-specific parameter resolution.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.environment_type == \"colab\":\n",
        "                # === Colab Form Fields Implementation ===\n",
        "                # Provider Selection\n",
        "                provider = \"Google\"  # @param [\"OpenAI\", \"Google\"]\n",
        "\n",
        "                # Model Selection with Provider-Specific Optimization\n",
        "                if provider == \"OpenAI\":\n",
        "                    evaluation_model = \"gpt-4o\"  # @param [\"gpt-4\", \"gpt-4o\"]\n",
        "                    vision_model = \"gpt-4o\"  # @param [\"gpt-4o\"]\n",
        "                else:\n",
        "                    evaluation_model = \"gemini-2.0-flash-exp\"  # @param [\"gemini-pro\", \"gemini-2.0-flash-exp\"]\n",
        "                    vision_model = \"gemini-2.0-flash-exp\"  # @param [\"gemini-2.0-flash-exp\"]\n",
        "\n",
        "                # Response Parameter Calibration\n",
        "                temperature = 0.5  # @param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "                # Critical: Ensure the selected provider propagates through the configuration chain\n",
        "                self.default_config[\"provider\"] = provider  # Update default configuration\n",
        "            else:\n",
        "                # === Local Environment Resolution ===\n",
        "                self.logger.info(\"Initializing local environment configuration...\")\n",
        "                config_path = Path(\"config.json\")\n",
        "\n",
        "                if config_path.exists():\n",
        "                    # Configuration File Resolution\n",
        "                    with open(config_path) as f:\n",
        "                        local_config = json.load(f)\n",
        "                        self.logger.info(\"Loading configuration from config.json\")\n",
        "\n",
        "                        provider = local_config.get(\"provider\", self.default_config[\"provider\"])\n",
        "                        evaluation_model = local_config.get(\"evaluation_model\", self.default_config[\"evaluation_model\"])\n",
        "                        vision_model = local_config.get(\"vision_model\", self.default_config[\"vision_model\"])\n",
        "                        temperature = local_config.get(\"temperature\", self.default_config[\"temperature\"])\n",
        "                else:\n",
        "                    # Environment Variable Resolution\n",
        "                    self.logger.info(\"Loading configuration from environment variables\")\n",
        "                    provider = os.getenv(\"AI_PROVIDER\", self.default_config[\"provider\"])\n",
        "                    evaluation_model = os.getenv(\"AI_EVAL_MODEL\", self.default_config[\"evaluation_model\"])\n",
        "                    vision_model = os.getenv(\"AI_VISION_MODEL\", self.default_config[\"vision_model\"])\n",
        "                    temperature = float(os.getenv(\"AI_TEMPERATURE\", self.default_config[\"temperature\"]))\n",
        "\n",
        "            # === Configuration Assembly and Validation ===\n",
        "            model_config = {\n",
        "                \"provider\": provider,\n",
        "                \"evaluation_model\": evaluation_model,\n",
        "                \"vision_model\": vision_model,\n",
        "                \"temperature\": temperature,\n",
        "                \"request_timeout\": self.default_config[\"request_timeout\"]\n",
        "            }\n",
        "\n",
        "            # Validate provider selection\n",
        "            if provider not in [\"OpenAI\", \"Google\"]:\n",
        "                raise ValueError(f\"Invalid provider: {provider}\")\n",
        "\n",
        "            # Validate model selections\n",
        "            if provider == \"OpenAI\" and evaluation_model not in [\"gpt-4\", \"gpt-4o\"]:\n",
        "                raise ValueError(f\"Invalid OpenAI evaluation model: {evaluation_model}\")\n",
        "            elif provider == \"Google\" and evaluation_model not in [\"gemini-pro\", \"gemini-2.0-flash-exp\"]:\n",
        "                raise ValueError(f\"Invalid Google evaluation model: {evaluation_model}\")\n",
        "\n",
        "            # Secure credential resolution\n",
        "            api_key = self._get_provider_key(provider)\n",
        "\n",
        "            # Log successful configuration\n",
        "            self.logger.info(f\"System configured successfully with {provider} provider\")\n",
        "            return api_key, model_config\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Configuration resolution failed: {str(e)}. Falling back to defaults.\")\n",
        "            return self._get_provider_key(self.default_config[\"provider\"]), self.default_config\n",
        "\n",
        "# Initialize global configuration manager\n",
        "api_config_manager = APIConfiguration()\n",
        "\n",
        "# Execute configuration\n",
        "try:\n",
        "    print(\"Initializing Expert System Configuration...\")\n",
        "    EXPERT_SYSTEM_KEY, EXPERT_SYSTEM_CONFIG = api_config_manager.configure_system()\n",
        "    print(f\"Configuration Complete ‚úì\")\n",
        "    print(f\"Provider: {EXPERT_SYSTEM_CONFIG['provider']}\")\n",
        "    print(f\"Models: {EXPERT_SYSTEM_CONFIG['evaluation_model']} (eval) / {EXPERT_SYSTEM_CONFIG['vision_model']} (vision)\")\n",
        "except Exception as e:\n",
        "    print(f\"Configuration Error: {str(e)}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p-ozbiG_fTy3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEFhQX8GhUED"
      },
      "source": [
        "\n",
        "# **3. Data Models**\n",
        "### **üìä Purpose**:\n",
        "Defines the core data structures used by the AI4Art system for managing projects, evaluating artwork, and assessing artists.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- No direct interaction is needed unless you want to customize the structure of the data models.\n",
        "- Developers can add or modify fields to capture additional details for evaluations.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Advanced users can modify these models to suit specific project requirements.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CVlC1qM3q1r7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Art Evaluation Expert System - Core Knowledge Models with Colab Integration\n",
        "-----------------------------------------------------------------------\n",
        "Implements core knowledge representation models with integrated Colab form fields\n",
        "for interactive expert system configuration and evaluation.\n",
        "\"\"\"\n",
        "\n",
        "# === Data Models ===\n",
        "\n",
        "class ProjectCriteria(BaseModel):\n",
        "    \"\"\"Criteria generated for project evaluation.\"\"\"\n",
        "    artistic_requirements: List[str] = Field(\n",
        "        default_factory=lambda: [\"To be specified\"],\n",
        "        description=\"Specific artistic requirements for the project\"\n",
        "    )\n",
        "    technical_requirements: List[str] = Field(\n",
        "        default_factory=lambda: [\"To be specified\"],\n",
        "        description=\"Technical skills and capabilities needed\"\n",
        "    )\n",
        "    style_preferences: List[str] = Field(\n",
        "        default_factory=lambda: [\"To be specified\"],\n",
        "        description=\"Preferred artistic styles and approaches\"\n",
        "    )\n",
        "    evaluation_metrics: Dict[str, str] = Field(\n",
        "        default_factory=lambda: {\"general\": \"To be specified\"},\n",
        "        description=\"Specific metrics for evaluating artwork and artist\"\n",
        "    )\n",
        "    suggested_artist_profile: Dict[str, str] = Field(\n",
        "        default_factory=lambda: {\"experience\": \"To be specified\"},\n",
        "        description=\"Ideal artist profile characteristics\"\n",
        "    )\n",
        "\n",
        "    class Config:\n",
        "        extra = \"allow\"\n",
        "\n",
        "    @classmethod\n",
        "    def create_default(cls):\n",
        "        \"\"\"Create a default instance with placeholder values.\"\"\"\n",
        "        return cls(\n",
        "            artistic_requirements=[\"To be determined based on project details\"],\n",
        "            technical_requirements=[\"To be determined based on project specifications\"],\n",
        "            style_preferences=[\"To be determined based on project requirements\"],\n",
        "            evaluation_metrics={\"general\": \"To be determined\"},\n",
        "            suggested_artist_profile={\"experience\": \"To be determined\"}\n",
        "        )\n",
        "\n",
        "class ProjectRequirements(BaseModel):\n",
        "    \"\"\"Project requirements model.\"\"\"\n",
        "    title: str\n",
        "    type: str\n",
        "    description: str\n",
        "    budget: Optional[float] = None\n",
        "    timeline: Optional[str] = None\n",
        "    criteria: Optional[ProjectCriteria] = None\n",
        "\n",
        "    def dict(self, *args, **kwargs):\n",
        "        \"\"\"Override dict method to handle None values.\"\"\"\n",
        "        d = super().dict(*args, **kwargs)\n",
        "        return {k: v for k, v in d.items() if v is not None}\n",
        "\n",
        "class ArtworkEvaluation(BaseModel):\n",
        "    \"\"\"Evaluation model for artwork assessment.\"\"\"\n",
        "    technical_score: float = Field(..., ge=0, le=10)\n",
        "    creativity_score: float = Field(..., ge=0, le=10)\n",
        "    project_fit_score: float = Field(..., ge=0, le=10)\n",
        "    visual_impact_score: float = Field(..., ge=0, le=10)\n",
        "    criteria_alignment: Dict[str, float] = Field(..., description=\"Scores for project-specific criteria\")\n",
        "    strengths: List[str]\n",
        "    areas_for_improvement: List[str]\n",
        "    visual_analysis: Dict[str, str]\n",
        "    overall_recommendation: str\n",
        "\n",
        "    def get_evaluation_summary(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate a summary of the artwork evaluation.\"\"\"\n",
        "        return {\n",
        "            \"scores\": {\n",
        "                \"technical\": self.technical_score,\n",
        "                \"creativity\": self.creativity_score,\n",
        "                \"project_fit\": self.project_fit_score,\n",
        "                \"visual_impact\": self.visual_impact_score,\n",
        "                \"criteria_alignment\": self.criteria_alignment\n",
        "            },\n",
        "            \"analysis\": {\n",
        "                \"strengths\": self.strengths,\n",
        "                \"improvements\": self.areas_for_improvement,\n",
        "                \"visual\": self.visual_analysis,\n",
        "                \"recommendation\": self.overall_recommendation\n",
        "            }\n",
        "        }\n",
        "\n",
        "class ArtistEvaluation(BaseModel):\n",
        "    \"\"\"Evaluation model for artist assessment.\"\"\"\n",
        "    experience_score: float = Field(..., ge=0, le=10)\n",
        "    style_match_score: float = Field(..., ge=0, le=10)\n",
        "    technical_capability_score: float = Field(..., ge=0, le=10)\n",
        "    project_suitability_score: float = Field(..., ge=0, le=10)\n",
        "    strengths: List[str]\n",
        "    considerations: List[str]\n",
        "    profile_analysis: Dict[str, str]\n",
        "    criteria_alignment: Dict[str, float]\n",
        "    overall_assessment: str\n",
        "\n",
        "    def get_evaluation_summary(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate a summary of the artist evaluation.\"\"\"\n",
        "        return {\n",
        "            \"scores\": {\n",
        "                \"experience\": self.experience_score,\n",
        "                \"style_match\": self.style_match_score,\n",
        "                \"technical_capability\": self.technical_capability_score,\n",
        "                \"project_suitability\": self.project_suitability_score,\n",
        "                \"criteria_alignment\": self.criteria_alignment\n",
        "            },\n",
        "            \"analysis\": {\n",
        "                \"strengths\": self.strengths,\n",
        "                \"considerations\": self.considerations,\n",
        "                \"profile\": self.profile_analysis,\n",
        "                \"assessment\": self.overall_assessment\n",
        "            }\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjRoREf3hcIU"
      },
      "source": [
        "# **4. Core Functions - Prompt Library**\n",
        "### **üìù Purpose**:\n",
        "Provides a centralized collection of prompts for various tasks, such as evaluating artwork or generating project criteria.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- These prompts are pre-defined templates used by the AI models to guide their responses.\n",
        "- Prompts can be dynamically updated using the \"Update Prompts\" section (if implemented).\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Use the \"Prompt Library Update\" UI to customize these prompts for your specific project needs.\n",
        "- Ensure you save changes if using a configuration file for persistence.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3DnodfryO3j7"
      },
      "outputs": [],
      "source": [
        "# === Prompt Library ===\n",
        "class PromptLibrary:\n",
        "    \"\"\"\n",
        "    Centralized prompt management system for the AI4Art Expert System.\n",
        "    Implements a structured approach to prompt engineering and management.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_project_criteria_prompt() -> str:\n",
        "        \"\"\"Generate prompt for project criteria generation.\"\"\"\n",
        "        return \"\"\"Based on the following project description, generate specific evaluation criteria and an ideal artist profile.\n",
        "\n",
        "Project Description:\n",
        "{project_description}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Generate a comprehensive set of criteria that includes specific requirements, metrics, and preferences.\n",
        "Focus on actionable and measurable criteria that can be used to evaluate both artwork and artists.\n",
        "\n",
        "The response should follow this exact structure:\n",
        "{{\n",
        "    \"artistic_requirements\": [\n",
        "        \"Detailed requirement 1\",\n",
        "        \"Detailed requirement 2\"\n",
        "    ],\n",
        "    \"technical_requirements\": [\n",
        "        \"Specific technical requirement 1\",\n",
        "        \"Specific technical requirement 2\"\n",
        "    ],\n",
        "    \"style_preferences\": [\n",
        "        \"Clear style preference 1\",\n",
        "        \"Clear style preference 2\"\n",
        "    ],\n",
        "    \"evaluation_metrics\": {{\n",
        "        \"creativity\": \"Description of how creativity will be evaluated\",\n",
        "        \"technical_skill\": \"Description of how technical skill will be evaluated\"\n",
        "    }},\n",
        "    \"suggested_artist_profile\": {{\n",
        "        \"experience\": \"Required years and type of experience\",\n",
        "        \"skills\": \"Specific skills needed for this project\"\n",
        "    }}\n",
        "}}\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_artwork_evaluation_prompt() -> str:\n",
        "        \"\"\"Generate prompt for artwork evaluation.\"\"\"\n",
        "        return \"\"\"Evaluate the artwork based on the following information:\n",
        "\n",
        "Project Context:\n",
        "{project_context}\n",
        "\n",
        "Visual Analysis:\n",
        "{visual_analysis}\n",
        "\n",
        "Artwork Details:\n",
        "{artwork_details}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Your response MUST be a valid JSON object matching the ArtworkEvaluation model structure.\n",
        "Ensure all numeric scores are between 0 and 10.\n",
        "\n",
        "The response should follow this exact structure:\n",
        "{{\n",
        "    \"technical_score\": 0.0,\n",
        "    \"creativity_score\": 0.0,\n",
        "    \"project_fit_score\": 0.0,\n",
        "    \"visual_impact_score\": 0.0,\n",
        "    \"criteria_alignment\": {{\n",
        "        \"metric1\": 0.0,\n",
        "        \"metric2\": 0.0\n",
        "    }},\n",
        "    \"strengths\": [\n",
        "        \"Strength 1\",\n",
        "        \"Strength 2\"\n",
        "    ],\n",
        "    \"areas_for_improvement\": [\n",
        "        \"Area 1\",\n",
        "        \"Area 2\"\n",
        "    ],\n",
        "    \"visual_analysis\": {{\n",
        "        \"composition\": \"Analysis of composition\",\n",
        "        \"technique\": \"Analysis of technique\",\n",
        "        \"impact\": \"Analysis of visual impact\"\n",
        "    }},\n",
        "    \"overall_recommendation\": \"Detailed recommendation text\"\n",
        "}}\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_artist_evaluation_prompt() -> str:\n",
        "        \"\"\"Generate prompt for artist evaluation.\"\"\"\n",
        "        return \"\"\"Evaluate the artist's suitability for the project based on their information and the project criteria.\n",
        "\n",
        "Project Context:\n",
        "{project_context}\n",
        "\n",
        "Artist Information:\n",
        "{artist_info}\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Your response MUST be a valid JSON object matching the ArtistEvaluation model structure.\n",
        "Ensure all numeric scores are between 0 and 10.\n",
        "\n",
        "The response should follow this exact structure:\n",
        "{{\n",
        "    \"experience_score\": 0.0,\n",
        "    \"style_match_score\": 0.0,\n",
        "    \"technical_capability_score\": 0.0,\n",
        "    \"project_suitability_score\": 0.0,\n",
        "    \"strengths\": [\n",
        "        \"Strength 1\",\n",
        "        \"Strength 2\"\n",
        "    ],\n",
        "    \"considerations\": [\n",
        "        \"Consideration 1\",\n",
        "        \"Consideration 2\"\n",
        "    ],\n",
        "    \"profile_analysis\": {{\n",
        "        \"experience\": \"Analysis of experience\",\n",
        "        \"skills\": \"Analysis of skills\",\n",
        "        \"style\": \"Analysis of artistic style\"\n",
        "    }},\n",
        "    \"criteria_alignment\": {{\n",
        "        \"metric1\": 0.0,\n",
        "        \"metric2\": 0.0\n",
        "    }},\n",
        "    \"overall_assessment\": \"Detailed assessment text\"\n",
        "}}\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_vision_analysis_prompt(criteria_context: str = \"\") -> str:\n",
        "        \"\"\"Generate prompt for vision model analysis.\"\"\"\n",
        "        base_prompt = \"\"\"Analyze this artwork{} considering the following aspects:\n",
        "\n",
        "1. Composition and layout\n",
        "2. Color palette and use of color\n",
        "3. Technique and medium\n",
        "4. Visual elements and symbolism\n",
        "5. Overall aesthetic impact\n",
        "6. Technical execution quality\n",
        "7. Creative interpretation\n",
        "8. Emotional resonance\n",
        "9. Cultural context and references\n",
        "10. Innovation and originality\n",
        "\n",
        "Please provide a detailed analysis that can be used to evaluate the artwork against project requirements.\n",
        "Focus on concrete observations and specific details rather than general impressions.\n",
        "Your analysis should help inform both technical and artistic evaluation scores.\"\"\"\n",
        "\n",
        "        if criteria_context:\n",
        "            criteria_section = f\" based on the following project-specific criteria:\\n\\n{criteria_context}\\n\"\n",
        "        else:\n",
        "            criteria_section = \" \"\n",
        "\n",
        "        return base_prompt.format(criteria_section)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_final_recommendation_prompt() -> str:\n",
        "        \"\"\"Generate prompt for final recommendation.\"\"\"\n",
        "        return \"\"\"Generate a final recommendation based on the complete evaluation.\n",
        "\n",
        "Project Requirements:\n",
        "{project_requirements}\n",
        "\n",
        "Artwork Evaluation:\n",
        "{artwork_evaluation}\n",
        "\n",
        "Artist Evaluation:\n",
        "{artist_evaluation}\n",
        "\n",
        "Provide a comprehensive recommendation including:\n",
        "1. Overall project fit assessment\n",
        "2. Key strengths and unique value propositions\n",
        "3. Potential risks and mitigation strategies\n",
        "4. Timeline and budget considerations\n",
        "5. Specific next steps and action items\n",
        "6. Long-term value and potential impact\n",
        "7. Alternative approaches or considerations\n",
        "8. Success metrics and evaluation criteria\n",
        "\n",
        "Your response should be detailed and actionable, with clear justification for the recommendation based on the evaluations provided.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Core Functions - Update Prompt**\n",
        "### **üõ†Ô∏è Purpose**:\n",
        "Allows users to dynamically update prompts in the `PromptLibrary` through an easy-to-use interface.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- Use the provided text fields to edit prompts.\n",
        "- Click \"Update Prompts\" to save changes.\n",
        "- Updated prompts are used immediately in the notebook for subsequent evaluations.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Ensure the prompt structure remains valid (e.g., required placeholders like `{artwork_details}` are included).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "K8_gx8eeUx1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Define the prompts and their descriptions\n",
        "prompt_keys = {\n",
        "    \"Project Criteria Prompt\": PromptLibrary.get_project_criteria_prompt(),\n",
        "    \"Artwork Evaluation Prompt\": PromptLibrary.get_artwork_evaluation_prompt(),\n",
        "    \"Artist Evaluation Prompt\": PromptLibrary.get_artist_evaluation_prompt(),\n",
        "    \"Vision Analysis Prompt\": PromptLibrary.get_vision_analysis_prompt(),\n",
        "    \"Final Recommendation Prompt\": PromptLibrary.get_final_recommendation_prompt(),\n",
        "}\n",
        "\n",
        "# Create a tabbed interface for updating prompts\n",
        "tab = widgets.Tab()\n",
        "\n",
        "# Dynamically create text areas for each prompt\n",
        "textareas = []\n",
        "for key, prompt in prompt_keys.items():\n",
        "    textarea = widgets.Textarea(\n",
        "        value=prompt,  # Fetch the existing prompt\n",
        "        description=key,\n",
        "        layout=widgets.Layout(width=\"100%\", height=\"150px\"),\n",
        "    )\n",
        "    textareas.append(textarea)\n",
        "\n",
        "# Set titles for each tab\n",
        "tab.children = textareas\n",
        "for i, key in enumerate(prompt_keys.keys()):\n",
        "    tab.set_title(i, key)\n",
        "\n",
        "# Button to apply updates\n",
        "apply_button = widgets.Button(description=\"Update Prompts\")\n",
        "output = widgets.Output()\n",
        "\n",
        "# Callback function to update the PromptLibrary\n",
        "def update_prompts(button):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        try:\n",
        "            # Update each prompt in the library\n",
        "            for i, key in enumerate(prompt_keys.keys()):\n",
        "                new_prompt = textareas[i].value\n",
        "                if key == \"Project Criteria Prompt\":\n",
        "                    PromptLibrary.get_project_criteria_prompt = staticmethod(lambda: new_prompt)\n",
        "                elif key == \"Artwork Evaluation Prompt\":\n",
        "                    PromptLibrary.get_artwork_evaluation_prompt = staticmethod(lambda: new_prompt)\n",
        "                elif key == \"Artist Evaluation Prompt\":\n",
        "                    PromptLibrary.get_artist_evaluation_prompt = staticmethod(lambda: new_prompt)\n",
        "                elif key == \"Vision Analysis Prompt\":\n",
        "                    PromptLibrary.get_vision_analysis_prompt = staticmethod(lambda: new_prompt)\n",
        "                elif key == \"Final Recommendation Prompt\":\n",
        "                    PromptLibrary.get_final_recommendation_prompt = staticmethod(lambda: new_prompt)\n",
        "            print(\"Prompts updated successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error updating prompts: {e}\")\n",
        "\n",
        "# Attach the callback to the button\n",
        "apply_button.on_click(update_prompts)\n",
        "\n",
        "# Display the UI components\n",
        "display(tab, apply_button, output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "eb7513d2681b4e8cb958d7e76281a9ff",
            "c96f2be16596445197c069bb790663e1",
            "786c41b5cd2e455a9dd0479d1ee6a40c",
            "98b9834ef039496ea23778ffe9e9c44b",
            "ea0c7f7eecc7442a9c22dba0de91f807",
            "645688bbfb864ef5af972d1e46428da2",
            "ddbe04d6f64d47de981f9286efcda3fc",
            "f921e8170f6c41949b4547c28993ce0d",
            "61373859acee4b8e8e43997fa975fca7",
            "e12f3b73f1774d6091b53014b793b042",
            "34e259167f0e497f85f72c6e558a9a87",
            "bc126e6882f84c1ba456fda16c0b3d08",
            "2dc53a5f96094459921ccea9e96f22be",
            "565c062aedcf4a3eb04b455382e5285a",
            "f4082c68bd734883a4c3688ee0898e3e",
            "eb53c6042bde489299e4d05a82239bfe",
            "5344cd175b144efe81c9dd9fcb008c3f",
            "a7bf49fec1704cc0bcd3db9a0ef01505",
            "371c182c77f046958cebe18f86646846",
            "00a0bc145b47447f9781ab51431bf15a",
            "7704f92884ec466998ee9e0b283266bc",
            "2ea0cc2234834a7098c47ae12e78dc84"
          ]
        },
        "id": "nOJlKzERU0oX",
        "outputId": "eeb37a19-e93d-40d8-f214-ba41b2c984eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tab(children=(Textarea(value='Based on the following project description, generate specific evaluation criteri‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb7513d2681b4e8cb958d7e76281a9ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Update Prompts', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7bf49fec1704cc0bcd3db9a0ef01505"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7704f92884ec466998ee9e0b283266bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5VP0jwNO3j7"
      },
      "source": [
        "# **6. Core Functions - Main Methods**\n",
        "### **‚öôÔ∏è Purpose**:\n",
        "Implements the primary logic for tasks like generating project criteria, evaluating artwork, and assessing artists.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- No direct interaction is required.\n",
        "- These methods are invoked automatically during evaluations.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Developers can modify these methods to change how evaluations are performed or how data is processed.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "twH5174PttM2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Enhanced AI4Art Expert System Core\n",
        "--------------------------------\n",
        "Implements an intelligent art evaluation system with LCEL chains\n",
        "and vision model integration for artwork evaluation.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, List, Any, Optional, Union\n",
        "from pydantic import BaseModel, Field\n",
        "from datetime import datetime\n",
        "import json\n",
        "import logging\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain_core.output_parsers import BaseOutputParser\n",
        "from vertexai.preview.generative_models import GenerativeModel, Part\n",
        "from vertexai.preview.generative_models import Content\n",
        "\n",
        "class SystemConfig:\n",
        "    \"\"\"Configuration for expert system parameters\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_config():\n",
        "        \"\"\"Generate system configuration\"\"\"\n",
        "        try:\n",
        "            config = {\n",
        "                \"temperature\": 0.7,\n",
        "                \"model_name\": \"gpt-4o\",\n",
        "                \"weights\": {\n",
        "                    \"technical\": 1.0,\n",
        "                    \"creativity\": 1.0,\n",
        "                    \"impact\": 1.0,\n",
        "                },\n",
        "                \"generation_config\": {\n",
        "                    \"max_output_tokens\": 2048,\n",
        "                    \"temperature\": 0.7,\n",
        "                    \"top_p\": 0.95,\n",
        "                },\n",
        "                \"safety_settings\": [\n",
        "                    {\n",
        "                        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "                        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "                        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "                        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "                        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "                    }\n",
        "                ],\n",
        "                \"debug\": False\n",
        "            }\n",
        "            return config\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Configuration error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "class AI4ArtSystem:\n",
        "    \"\"\"\n",
        "    Intelligent art evaluation framework implementing the adaptive expert system pattern.\n",
        "    Provides multi-modal cognitive processing capabilities for artistic assessment through\n",
        "    configurable knowledge models and structured evaluation protocols.\n",
        "    \"\"\"\n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"\n",
        "        Initialize core knowledge processing framework with secure credential management.\n",
        "        Establishes baseline cognitive architecture for artistic evaluation.\n",
        "        \"\"\"\n",
        "        self.api_key = api_key\n",
        "\n",
        "        # Knowledge processing engines\n",
        "        self.llm = None\n",
        "        self.vision_model = None\n",
        "\n",
        "        # Core system components\n",
        "        self.artwork_parser = None\n",
        "        self.artist_parser = None\n",
        "        self.criteria_parser = None\n",
        "\n",
        "        # State management\n",
        "        self.evaluation_history = []\n",
        "        self.current_project = None\n",
        "        self.current_criteria = None\n",
        "        self.current_artwork_eval = None\n",
        "        self.current_artist_eval = None\n",
        "        self._current_config = None\n",
        "\n",
        "        # System monitoring\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def configure_models(self, config: Dict[str, Any]) -> None:\n",
        "        \"\"\"\n",
        "        Configure cognitive processing models implementing the adaptive intelligence pattern.\n",
        "        Establishes specialized knowledge processing capabilities for both textual and visual analysis.\n",
        "\n",
        "        Args:\n",
        "            config: Configuration dictionary defining cognitive processing parameters\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self._current_config = config\n",
        "\n",
        "            # Initialize knowledge processing engines based on provider selection\n",
        "            if config[\"provider\"] == \"OpenAI\":\n",
        "                from langchain_openai import ChatOpenAI\n",
        "\n",
        "                # Primary evaluation engine\n",
        "                self.llm = ChatOpenAI(\n",
        "                    temperature=config[\"temperature\"],\n",
        "                    model_name=config[\"evaluation_model\"],\n",
        "                    api_key=self.api_key\n",
        "                )\n",
        "\n",
        "                # Visual analysis engine\n",
        "                self.vision_model = ChatOpenAI(\n",
        "                    temperature=config[\"temperature\"],\n",
        "                    model_name=config[\"vision_model\"],\n",
        "                    api_key=self.api_key\n",
        "                )\n",
        "\n",
        "            else:  # Google provider\n",
        "                from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "                # Primary evaluation engine\n",
        "                self.llm = ChatGoogleGenerativeAI(\n",
        "                    temperature=config[\"temperature\"],\n",
        "                    model=config[\"evaluation_model\"],\n",
        "                    google_api_key=self.api_key\n",
        "                )\n",
        "\n",
        "                # Visual analysis engine\n",
        "                self.vision_model = ChatGoogleGenerativeAI(\n",
        "                    temperature=config[\"temperature\"],\n",
        "                    model=config[\"vision_model\"],\n",
        "                    google_api_key=self.api_key\n",
        "                )\n",
        "\n",
        "            # Initialize knowledge structure parsers\n",
        "            self.artwork_parser = PydanticOutputParser(pydantic_object=ArtworkEvaluation)\n",
        "            self.artist_parser = PydanticOutputParser(pydantic_object=ArtistEvaluation)\n",
        "            self.criteria_parser = PydanticOutputParser(pydantic_object=ProjectCriteria)\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"Cognitive processing engines initialized: \"\n",
        "                f\"{config['evaluation_model']} (evaluation) / {config['vision_model']} (vision)\"\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Cognitive engine initialization failed: {str(e)}\")\n",
        "            raise ValueError(f\"Knowledge processing configuration error: {str(e)}\")\n",
        "\n",
        "    def set_project_requirements(self, project_requirements: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Establish project evaluation framework with intelligent criteria generation.\"\"\"\n",
        "        try:\n",
        "            # Initialize project context\n",
        "            self.current_project = ProjectRequirements(**project_requirements)\n",
        "\n",
        "            # Generate specialized evaluation criteria\n",
        "            criteria_result = self.generate_project_criteria(self.current_project.description)\n",
        "\n",
        "            if \"error\" in criteria_result:\n",
        "                # Implement graceful degradation to default criteria\n",
        "                criteria_result = ProjectCriteria.create_default().dict()\n",
        "\n",
        "            # Update project with intelligent criteria\n",
        "            self.current_project.criteria = ProjectCriteria(**criteria_result)\n",
        "            self.current_criteria = self.current_project.criteria\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"message\": \"Project requirements established successfully\",\n",
        "                \"criteria\": self.current_criteria.dict()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Project framework initialization failed: {str(e)}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": f\"Error: {str(e)}\",\n",
        "                \"criteria\": ProjectCriteria.create_default().dict()\n",
        "            }\n",
        "\n",
        "    def create_project_criteria_chain(self):\n",
        "        \"\"\"Create LCEL chain for generating project criteria.\"\"\"\n",
        "        template = PromptLibrary.get_project_criteria_prompt()\n",
        "\n",
        "        # Create the prompt template with format instructions\n",
        "        prompt = ChatPromptTemplate.from_template(template).partial(\n",
        "            format_instructions=self.criteria_parser.get_format_instructions()\n",
        "        )\n",
        "\n",
        "        def format_output(output):\n",
        "            if isinstance(output, str):\n",
        "                try:\n",
        "                    import re\n",
        "                    json_match = re.search(r'\\{.*\\}', output, re.DOTALL)\n",
        "                    if json_match:\n",
        "                        json_str = json_match.group()\n",
        "                        parsed = json.loads(json_str)\n",
        "                        return ProjectCriteria(**parsed)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error parsing criteria output: {str(e)}\\nOutput: {output}\")\n",
        "                    return ProjectCriteria.create_default()\n",
        "            return output\n",
        "\n",
        "        chain = (\n",
        "            {\n",
        "                \"project_description\": RunnablePassthrough()\n",
        "            }\n",
        "            | prompt\n",
        "            | self.llm\n",
        "            | format_output\n",
        "            | self.criteria_parser\n",
        "        )\n",
        "\n",
        "        return chain\n",
        "\n",
        "    def create_artwork_chain(self):\n",
        "        \"\"\"Create artwork evaluation chain using LCEL.\"\"\"\n",
        "        template = PromptLibrary.get_artwork_evaluation_prompt()\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template).partial(\n",
        "            format_instructions=self.artwork_parser.get_format_instructions()\n",
        "        )\n",
        "\n",
        "        def format_output(output):\n",
        "            if isinstance(output, str):\n",
        "                try:\n",
        "                    import re\n",
        "                    json_match = re.search(r'\\{.*\\}', output, re.DOTALL)\n",
        "                    if json_match:\n",
        "                        json_str = json_match.group()\n",
        "                        parsed = json.loads(json_str)\n",
        "                        return ArtworkEvaluation(**parsed)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error parsing artwork evaluation output: {str(e)}\\nOutput: {output}\")\n",
        "                    raise ValueError(\"Failed to parse artwork evaluation output\")\n",
        "            return output\n",
        "\n",
        "        return (\n",
        "            {\n",
        "                \"project_context\": lambda x: self.current_project.dict(),\n",
        "                \"visual_analysis\": RunnablePassthrough(),\n",
        "                \"artwork_details\": RunnablePassthrough()\n",
        "            }\n",
        "            | prompt\n",
        "            | self.llm\n",
        "            | format_output\n",
        "            | self.artwork_parser\n",
        "        )\n",
        "\n",
        "    def create_artist_chain(self):\n",
        "        \"\"\"Create artist evaluation chain using LCEL.\"\"\"\n",
        "        template = PromptLibrary.get_artist_evaluation_prompt()\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_template(template).partial(\n",
        "            format_instructions=self.artist_parser.get_format_instructions()\n",
        "        )\n",
        "\n",
        "        def format_output(output):\n",
        "            if isinstance(output, str):\n",
        "                try:\n",
        "                    import re\n",
        "                    json_match = re.search(r'\\{.*\\}', output, re.DOTALL)\n",
        "                    if json_match:\n",
        "                        json_str = json_match.group()\n",
        "                        parsed = json.loads(json_str)\n",
        "                        return ArtistEvaluation(**parsed)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error parsing artist evaluation output: {str(e)}\\nOutput: {output}\")\n",
        "                    raise ValueError(\"Failed to parse artist evaluation output\")\n",
        "            return output\n",
        "\n",
        "        return (\n",
        "            {\n",
        "                \"project_context\": lambda x: self.current_project.dict(),\n",
        "                \"artist_info\": RunnablePassthrough()\n",
        "            }\n",
        "            | prompt\n",
        "            | self.llm\n",
        "            | format_output\n",
        "            | self.artist_parser\n",
        "        )\n",
        "\n",
        "    def generate_project_criteria(self, project_description: str) -> Dict[str, Any]:\n",
        "        \"\"\"Generate project-specific evaluation criteria using LCEL chain.\"\"\"\n",
        "        try:\n",
        "            if not project_description or len(project_description.strip()) < 10:\n",
        "                return ProjectCriteria.create_default().dict()\n",
        "\n",
        "            chain = self.create_project_criteria_chain()\n",
        "            criteria = chain.invoke({\"project_description\": project_description})\n",
        "            self.current_criteria = criteria\n",
        "            return criteria.dict()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating project criteria: {str(e)}\")\n",
        "            default_criteria = ProjectCriteria.create_default()\n",
        "            self.current_criteria = default_criteria\n",
        "            return default_criteria.dict()\n",
        "\n",
        "    def _analyze_image_with_vision(self, image: Image.Image) -> str:\n",
        "        \"\"\"Analyze artwork using the vision model.\"\"\"\n",
        "        try:\n",
        "            criteria_context = \"\"\n",
        "            if self.current_criteria:\n",
        "                criteria_context = f\"\"\"\n",
        "Artistic Requirements:\n",
        "{self.current_criteria.artistic_requirements}\n",
        "\n",
        "Technical Requirements:\n",
        "{self.current_criteria.technical_requirements}\n",
        "\n",
        "Style Preferences:\n",
        "{self.current_criteria.style_preferences}\n",
        "\"\"\"\n",
        "\n",
        "            prompt = PromptLibrary.get_vision_analysis_prompt(criteria_context)\n",
        "\n",
        "            # Convert PIL Image to bytes\n",
        "            with io.BytesIO() as buffer:\n",
        "                image.save(buffer, format=\"PNG\")\n",
        "                image_bytes = buffer.getvalue()\n",
        "\n",
        "            # Create message content\n",
        "            from langchain_core.messages import HumanMessage\n",
        "            message = HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/png;base64,{base64.b64encode(image_bytes).decode('utf-8')}\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            response = self.vision_model.invoke([message])\n",
        "            return response.content\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in vision analysis: {str(e)}\")\n",
        "            return f\"Error analyzing image: {str(e)}\"\n",
        "\n",
        "    def evaluate_artwork(self, artwork_details: Dict[str, Any], image: Optional[Image.Image] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Evaluate artwork using the vision model and LCEL chain.\"\"\"\n",
        "        try:\n",
        "            if not self.current_project:\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"message\": \"Please set project requirements first\"\n",
        "                }\n",
        "\n",
        "            if not image:\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"message\": \"Image is required for artwork evaluation\"\n",
        "                }\n",
        "\n",
        "            visual_analysis = self._analyze_image_with_vision(image)\n",
        "            chain = self.create_artwork_chain()\n",
        "\n",
        "            evaluation = chain.invoke({\n",
        "                \"artwork_details\": json.dumps(artwork_details),\n",
        "                \"visual_analysis\": visual_analysis\n",
        "            })\n",
        "\n",
        "            self.current_artwork_eval = evaluation\n",
        "            self._store_evaluation(evaluation, artwork_details)\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"evaluation\": evaluation.get_evaluation_summary()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error evaluating artwork: {str(e)}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": str(e)\n",
        "            }\n",
        "\n",
        "    def evaluate_artist(self, artist_info: Dict[str, str]) -> Dict[str, Any]:\n",
        "        \"\"\"Evaluate artist using LCEL chain.\"\"\"\n",
        "        try:\n",
        "            if not self.current_project:\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"message\": \"Project requirements must be set first\"\n",
        "                }\n",
        "\n",
        "            chain = self.create_artist_chain()\n",
        "            evaluation = chain.invoke(json.dumps(artist_info))\n",
        "\n",
        "            self.current_artist_eval = evaluation\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"evaluation\": evaluation.get_evaluation_summary()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error evaluating artist: {str(e)}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": str(e)\n",
        "            }\n",
        "\n",
        "    def generate_final_recommendation(self) -> Dict[str, Any]:\n",
        "        \"\"\"Generate a comprehensive final recommendation.\"\"\"\n",
        "        try:\n",
        "            if not all([self.current_project, self.current_artwork_eval, self.current_artist_eval]):\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"message\": \"Both artwork and artist evaluations must be completed first\"\n",
        "                }\n",
        "\n",
        "            template = PromptLibrary.get_final_recommendation_prompt()\n",
        "            prompt = ChatPromptTemplate.from_template(template)\n",
        "            chain = prompt | self.llm\n",
        "\n",
        "            recommendation = chain.invoke({\n",
        "                \"project_requirements\": self.current_project.dict(),\n",
        "                \"artwork_evaluation\": self.current_artwork_eval.get_evaluation_summary(),\n",
        "                \"artist_evaluation\": self.current_artist_eval.get_evaluation_summary()\n",
        "            })\n",
        "\n",
        "            final_recommendation = {\n",
        "                \"project_overview\": {\n",
        "                    \"title\": self.current_project.title,\n",
        "                    \"type\": self.current_project.type,\n",
        "                    \"budget\": self.current_project.budget,\n",
        "                    \"timeline\": self.current_project.timeline\n",
        "                },\n",
        "                \"artwork_evaluation\": self.current_artwork_eval.get_evaluation_summary(),\n",
        "                \"artist_evaluation\": self.current_artist_eval.get_evaluation_summary(),\n",
        "                \"combined_score\": self._calculate_combined_score(),\n",
        "                \"recommendation\": recommendation.content,\n",
        "                \"next_steps\": self._generate_next_steps(),\n",
        "                \"risk_factors\": self._identify_risk_factors()\n",
        "            }\n",
        "\n",
        "            self._store_final_recommendation(final_recommendation)\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"recommendation\": final_recommendation\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating final recommendation: {str(e)}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": str(e)\n",
        "            }\n",
        "\n",
        "    def _calculate_combined_score(self) -> float:\n",
        "        \"\"\"Calculate combined score from artwork and artist evaluations.\"\"\"\n",
        "        artwork_avg = sum([\n",
        "            self.current_artwork_eval.technical_score,\n",
        "            self.current_artwork_eval.creativity_score,\n",
        "            self.current_artwork_eval.project_fit_score,\n",
        "            self.current_artwork_eval.visual_impact_score\n",
        "        ]) / 4\n",
        "\n",
        "        artist_avg = sum([\n",
        "            self.current_artist_eval.experience_score,\n",
        "            self.current_artist_eval.style_match_score,\n",
        "            self.current_artist_eval.technical_capability_score,\n",
        "            self.current_artist_eval.project_suitability_score\n",
        "        ]) / 4\n",
        "\n",
        "        return (artwork_avg + artist_avg) / 2\n",
        "\n",
        "    def _generate_next_steps(self) -> List[str]:\n",
        "        \"\"\"Generate recommended next steps based on evaluations.\"\"\"\n",
        "        combined_score = self._calculate_combined_score()\n",
        "\n",
        "        if combined_score >= 8.0:\n",
        "            return [\n",
        "                \"Proceed with formal artist engagement\",\n",
        "                \"Schedule detailed project timeline review\",\n",
        "                \"Begin technical requirements documentation\",\n",
        "                \"Set up project milestones and review points\"\n",
        "            ]\n",
        "        elif combined_score >= 6.5:\n",
        "            return [\n",
        "                \"Request additional artwork samples or modifications\",\n",
        "                \"Conduct detailed technical feasibility review\",\n",
        "                \"Discuss specific project requirements with artist\",\n",
        "                \"Consider trial period or smaller initial scope\"\n",
        "            ]\n",
        "        else:\n",
        "            return [\n",
        "                \"Continue artist search\",\n",
        "                \"Refine project requirements\",\n",
        "                \"Consider adjusting budget or timeline expectations\",\n",
        "                \"Review evaluation criteria\"\n",
        "            ]\n",
        "\n",
        "    def _identify_risk_factors(self) -> List[str]:\n",
        "        \"\"\"Identify potential risk factors based on evaluations.\"\"\"\n",
        "        risks = []\n",
        "\n",
        "        # Artwork-related risks\n",
        "        if self.current_artwork_eval.technical_score < 7:\n",
        "            risks.append(\"Technical execution concerns\")\n",
        "        if self.current_artwork_eval.project_fit_score < 7:\n",
        "            risks.append(\"Project alignment issues\")\n",
        "\n",
        "        # Artist-related risks\n",
        "        if self.current_artist_eval.experience_score < 7:\n",
        "            risks.append(\"Experience level concerns\")\n",
        "        if self.current_artist_eval.project_suitability_score < 7:\n",
        "            risks.append(\"Project suitability concerns\")\n",
        "\n",
        "        # Budget and timeline risks\n",
        "        if hasattr(self.current_project, 'budget') and self.current_project.budget:\n",
        "            if self._calculate_combined_score() > 8 and self.current_project.budget < 100000:\n",
        "                risks.append(\"Budget may be insufficient for desired quality\")\n",
        "\n",
        "        return risks if risks else [\"No significant risk factors identified\"]\n",
        "\n",
        "    def _store_evaluation(self, evaluation: Union[ArtworkEvaluation, ArtistEvaluation], details: Dict[str, Any]):\n",
        "        \"\"\"Store evaluation results in history.\"\"\"\n",
        "        evaluation_record = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"project_context\": self.current_project.dict() if self.current_project else None,\n",
        "            \"details\": details,\n",
        "            \"evaluation\": evaluation.dict()\n",
        "        }\n",
        "        self.evaluation_history.append(evaluation_record)\n",
        "\n",
        "    def _store_final_recommendation(self, recommendation: Dict[str, Any]):\n",
        "        \"\"\"Store the final recommendation in history.\"\"\"\n",
        "        evaluation_record = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"project\": self.current_project.dict(),\n",
        "            \"artwork_evaluation\": self.current_artwork_eval.dict(),\n",
        "            \"artist_evaluation\": self.current_artist_eval.dict(),\n",
        "            \"final_recommendation\": recommendation\n",
        "        }\n",
        "        self.evaluation_history.append(evaluation_record)\n",
        "\n",
        "    def get_evaluation_history(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Retrieve the evaluation history.\"\"\"\n",
        "        return self.evaluation_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MA1sjJmO3j8"
      },
      "source": [
        "# **7. UI - Style Library**\n",
        "### **üé® Purpose**:\n",
        "Defines the look and feel of the Gradio interface, ensuring a consistent and visually appealing design.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- This section applies global CSS styles to the interface.\n",
        "- Users do not need to modify this section unless they want to customize the UI.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Customize colors, fonts, or layouts by editing the style definitions.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3AvkYp0AO3j8"
      },
      "outputs": [],
      "source": [
        "# === Style Library ===\n",
        "class StyleLibrary:\n",
        "    \"\"\"\n",
        "    Centralized style management system for the AI4Art Expert System UI.\n",
        "    Implements consistent styling and theming across the interface.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_base_styles() -> str:\n",
        "        \"\"\"Get base CSS styles for the interface.\"\"\"\n",
        "        return \"\"\"\n",
        "        .gradio-container {\n",
        "            max-width: 1200px;\n",
        "            margin: auto;\n",
        "        }\n",
        "        .gr-box, .gr-panel {\n",
        "            border-radius: 10px;\n",
        "            border: 1px solid #ddd;\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_text_styles() -> str:\n",
        "        \"\"\"Get text-related CSS styles.\"\"\"\n",
        "        return \"\"\"\n",
        "        .gr-output-html, .gr-output-markdown, .gr-output-text,\n",
        "        .gr-text *, .gr-box *, .gr-panel * {\n",
        "            color: #000000 !important;\n",
        "            background-color: #ffffff !important;\n",
        "            font-weight: 500 !important;\n",
        "            font-size: 16px !important;\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_table_styles() -> str:\n",
        "        \"\"\"Get table-related CSS styles.\"\"\"\n",
        "        return \"\"\"\n",
        "        td, th, p, li, span {\n",
        "            color: #000000 !important;\n",
        "            background-color: #ffffff !important;\n",
        "        }\n",
        "        table {\n",
        "            width: 100%;\n",
        "            border-collapse: collapse;\n",
        "        }\n",
        "        th, td {\n",
        "            border: 1px solid black;\n",
        "            padding: 8px;\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_header_styles() -> str:\n",
        "        \"\"\"Get header-related CSS styles.\"\"\"\n",
        "        return \"\"\"\n",
        "        h1, h2, h3, h4, h5, h6 {\n",
        "            color: #2c3e50 !important;\n",
        "            font-weight: 600 !important;\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_evaluation_output_styles() -> str:\n",
        "        \"\"\"Get styles for evaluation outputs.\"\"\"\n",
        "        return \"\"\"\n",
        "        .evaluation-container {\n",
        "            padding: 20px;\n",
        "            background-color: #ffffff;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "            color: #000000;\n",
        "        }\n",
        "        .evaluation-header {\n",
        "            color: #2c3e50;\n",
        "            margin-top: 20px;\n",
        "        }\n",
        "        .evaluation-list {\n",
        "            margin-left: 20px;\n",
        "        }\n",
        "        .evaluation-list li {\n",
        "            margin: 5px 0;\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_error_styles() -> str:\n",
        "        \"\"\"Get styles for error messages.\"\"\"\n",
        "        return \"\"\"\n",
        "        .error-message {\n",
        "            color: red;\n",
        "            padding: 10px;\n",
        "            border: 1px solid red;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_combined_styles() -> str:\n",
        "        \"\"\"Combine all styles into a single CSS string.\"\"\"\n",
        "        return \"\\n\".join([\n",
        "            StyleLibrary.get_base_styles(),\n",
        "            StyleLibrary.get_text_styles(),\n",
        "            StyleLibrary.get_table_styles(),\n",
        "            StyleLibrary.get_header_styles(),\n",
        "            StyleLibrary.get_evaluation_output_styles(),\n",
        "            StyleLibrary.get_error_styles()\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def format_scores_table(scores: Dict[str, Any]) -> str:\n",
        "        \"\"\"Format scores as an HTML table with consistent styling.\"\"\"\n",
        "        table = \"<table>\"\n",
        "        table += \"<tr><th>Metric</th><th>Score</th></tr>\"\n",
        "\n",
        "        for metric, score in scores.items():\n",
        "            if isinstance(score, (int, float)):\n",
        "                table += f\"<tr><td>{metric.replace('_', ' ').title()}</td>\"\n",
        "                table += f\"<td>{score:.1f}</td></tr>\"\n",
        "\n",
        "        table += \"</table>\"\n",
        "        return table\n",
        "\n",
        "    @staticmethod\n",
        "    def format_list_items(items: List[str]) -> str:\n",
        "        \"\"\"Format list items as HTML bullet points with consistent styling.\"\"\"\n",
        "        return \"<ul class='evaluation-list'>\" + \\\n",
        "               \"\".join([f\"<li>{item}</li>\" for item in items]) + \\\n",
        "               \"</ul>\"\n",
        "\n",
        "    @staticmethod\n",
        "    def format_error_message(message: str) -> str:\n",
        "        \"\"\"Format error message with consistent styling.\"\"\"\n",
        "        return f\"<div class='error-message'>{message}</div>\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIqQt8LPO3j8"
      },
      "source": [
        "# **8. UI - Core UI**\n",
        "### **üñ•Ô∏è Purpose**:\n",
        "Creates the Gradio user interface for the AI4Art system, including input forms, tabs, and output displays.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- Interact with the UI to input project details, evaluate artwork, or assess artists.\n",
        "- View the results and recommendations generated by the system.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Use the interface to provide necessary inputs and view results.\n",
        "- Developers can add new tabs or modify existing ones to include additional features.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6IgG_qH1V84k"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Enhanced Expert System Interface Architecture\n",
        "------------------------------------------\n",
        "Implements an intelligent interface layer that bridges our expert system's\n",
        "knowledge processing capabilities with user interaction patterns.\n",
        "\"\"\"\n",
        "# === UI ===\n",
        "class ExpertSystemInterface:\n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"Initialize the expert system interface.\"\"\"\n",
        "        self.system = AI4ArtSystem(api_key)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.current_project_description = None\n",
        "        self.current_artwork_evaluation = None\n",
        "        self.current_artist_evaluation = None\n",
        "\n",
        "    def _format_evaluation_output(self, evaluation_data: Dict[str, Any]) -> str:\n",
        "        \"\"\"Format evaluation results as HTML using consistent styling.\"\"\"\n",
        "        if not evaluation_data.get(\"success\", False):\n",
        "            return StyleLibrary.format_error_message(\n",
        "                evaluation_data.get('message', 'Error in evaluation')\n",
        "            )\n",
        "\n",
        "        evaluation = evaluation_data.get(\"evaluation\", {})\n",
        "        html = \"<div class='evaluation-container'>\"\n",
        "\n",
        "        # Scores section\n",
        "        if \"scores\" in evaluation:\n",
        "            html += \"<h3 class='evaluation-header'>Evaluation Scores</h3>\"\n",
        "            html += StyleLibrary.format_scores_table(evaluation[\"scores\"])\n",
        "\n",
        "        # Analysis section\n",
        "        if \"analysis\" in evaluation:\n",
        "            analysis = evaluation[\"analysis\"]\n",
        "\n",
        "            if \"strengths\" in analysis:\n",
        "                html += \"<h3 class='evaluation-header'>Strengths</h3>\"\n",
        "                html += StyleLibrary.format_list_items(analysis[\"strengths\"])\n",
        "\n",
        "            if \"improvements\" in analysis:\n",
        "                html += \"<h3 class='evaluation-header'>Areas for Improvement</h3>\"\n",
        "                html += StyleLibrary.format_list_items(analysis[\"improvements\"])\n",
        "\n",
        "            if \"recommendation\" in analysis:\n",
        "                html += \"<h3 class='evaluation-header'>Recommendation</h3>\"\n",
        "                html += f\"<p>{analysis['recommendation']}</p>\"\n",
        "\n",
        "        html += \"</div>\"\n",
        "        return html\n",
        "\n",
        "    def _format_recommendation_output(self, recommendation: Dict[str, Any]) -> str:\n",
        "        \"\"\"Format final recommendation as HTML using consistent styling.\"\"\"\n",
        "        html = \"<div class='evaluation-container'>\"\n",
        "\n",
        "        # Project Overview\n",
        "        html += \"<h3 class='evaluation-header'>Project Overview</h3>\"\n",
        "        overview = recommendation[\"project_overview\"]\n",
        "        table = \"<table>\"\n",
        "        for key, value in overview.items():\n",
        "            if value is not None:\n",
        "                table += f\"<tr><td>{key.replace('_', ' ').title()}</td>\"\n",
        "                table += f\"<td>{value}</td></tr>\"\n",
        "        table += \"</table>\"\n",
        "        html += table\n",
        "\n",
        "        # Combined Score\n",
        "        html += \"<h3 class='evaluation-header'>Overall Assessment</h3>\"\n",
        "        html += f\"<p style='font-size:1.2em; margin:10px 0;'>Combined Score: {recommendation['combined_score']:.1f}/10</p>\"\n",
        "\n",
        "        # Recommendation\n",
        "        html += \"<h3 class='evaluation-header'>Detailed Recommendation</h3>\"\n",
        "        html += f\"<p>{recommendation['recommendation']}</p>\"\n",
        "\n",
        "        # Next Steps\n",
        "        html += \"<h3 class='evaluation-header'>Next Steps</h3>\"\n",
        "        html += StyleLibrary.format_list_items(recommendation['next_steps'])\n",
        "\n",
        "        # Risk Factors\n",
        "        html += \"<h3 class='evaluation-header'>Risk Factors</h3>\"\n",
        "        html += StyleLibrary.format_list_items(recommendation['risk_factors'])\n",
        "\n",
        "        html += \"</div>\"\n",
        "        return html\n",
        "\n",
        "    def _create_project_tab(self) -> gr.Tab:\n",
        "        \"\"\"Create the project requirements tab.\"\"\"\n",
        "        with gr.Tab(\"Project Requirements\") as tab:\n",
        "            gr.Markdown(\"## Define Your Project\")\n",
        "\n",
        "            project_title = gr.Textbox(label=\"Project Title\")\n",
        "            project_type = gr.Textbox(label=\"Project Type\")\n",
        "            project_description = gr.Textbox(\n",
        "                label=\"Project Description\",\n",
        "                placeholder=\"Describe your project, including goals, style preferences, and any specific requirements...\",\n",
        "                lines=5\n",
        "            )\n",
        "            budget = gr.Number(label=\"Budget (Optional)\")\n",
        "            timeline = gr.Textbox(label=\"Timeline (Optional)\")\n",
        "\n",
        "            submit_button = gr.Button(\"Set Project Requirements\", variant=\"primary\")\n",
        "            criteria_output = gr.HTML(label=\"Generated Project Criteria\")\n",
        "\n",
        "            def handle_project_submission(title, type, description, budget, timeline):\n",
        "                try:\n",
        "                    project_data = {\n",
        "                        \"title\": title,\n",
        "                        \"type\": type,\n",
        "                        \"description\": description,\n",
        "                        \"budget\": budget,\n",
        "                        \"timeline\": timeline\n",
        "                    }\n",
        "\n",
        "                    result = self.system.set_project_requirements(project_data)\n",
        "                    self.current_project_description = description\n",
        "\n",
        "                    if not result[\"success\"]:\n",
        "                        return StyleLibrary.format_error_message(result['message'])\n",
        "\n",
        "                    criteria = result[\"criteria\"]\n",
        "                    html = \"<div class='evaluation-container'>\"\n",
        "\n",
        "                    # Artistic Requirements\n",
        "                    html += \"<h3 class='evaluation-header'>Artistic Requirements</h3>\"\n",
        "                    html += StyleLibrary.format_list_items(criteria[\"artistic_requirements\"])\n",
        "\n",
        "                    # Technical Requirements\n",
        "                    html += \"<h3 class='evaluation-header'>Technical Requirements</h3>\"\n",
        "                    html += StyleLibrary.format_list_items(criteria[\"technical_requirements\"])\n",
        "\n",
        "                    # Style Preferences\n",
        "                    html += \"<h3 class='evaluation-header'>Style Preferences</h3>\"\n",
        "                    html += StyleLibrary.format_list_items(criteria[\"style_preferences\"])\n",
        "\n",
        "                    # Evaluation Metrics\n",
        "                    html += \"<h3 class='evaluation-header'>Evaluation Metrics</h3>\"\n",
        "                    metrics_table = \"<table>\"\n",
        "                    for metric, description in criteria[\"evaluation_metrics\"].items():\n",
        "                        metrics_table += f\"<tr><td>{metric.replace('_', ' ').title()}</td>\"\n",
        "                        metrics_table += f\"<td>{description}</td></tr>\"\n",
        "                    metrics_table += \"</table>\"\n",
        "                    html += metrics_table\n",
        "\n",
        "                    html += \"</div>\"\n",
        "                    return html\n",
        "\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error in project submission: {str(e)}\")\n",
        "                    return StyleLibrary.format_error_message(str(e))\n",
        "\n",
        "            submit_button.click(\n",
        "                handle_project_submission,\n",
        "                inputs=[project_title, project_type, project_description, budget, timeline],\n",
        "                outputs=[criteria_output]\n",
        "            )\n",
        "\n",
        "            return tab\n",
        "\n",
        "    def _create_artwork_tab(self) -> gr.Tab:\n",
        "        \"\"\"Create the artwork evaluation tab.\"\"\"\n",
        "        with gr.Tab(\"Artwork Evaluation\") as tab:\n",
        "            gr.Markdown(\"## Evaluate Artwork\")\n",
        "\n",
        "            # Project check warning\n",
        "            project_warning = gr.Markdown(\n",
        "                \"‚ö†Ô∏è Please set project requirements first\",\n",
        "                visible=False\n",
        "            )\n",
        "\n",
        "            # Artwork inputs\n",
        "            artwork_title = gr.Textbox(label=\"Artwork Title\")\n",
        "            artwork_medium = gr.Textbox(label=\"Medium\")\n",
        "            artwork_dimensions = gr.Textbox(label=\"Dimensions\")\n",
        "            artwork_image = gr.Image(label=\"Upload Artwork Image\", type=\"pil\")\n",
        "            additional_notes = gr.Textbox(\n",
        "                label=\"Additional Notes\",\n",
        "                placeholder=\"Any additional information about the artwork...\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            # Evaluation button and output\n",
        "            evaluate_button = gr.Button(\"Evaluate Artwork\", variant=\"primary\")\n",
        "            evaluation_output = gr.HTML(label=\"Artwork Evaluation Results\")\n",
        "\n",
        "            def check_project_requirements():\n",
        "                return gr.update(visible=not bool(self.system.current_project))\n",
        "\n",
        "            def handle_artwork_evaluation(title, medium, dimensions, image, notes):\n",
        "                try:\n",
        "                    if not self.system.current_project:\n",
        "                        return StyleLibrary.format_error_message(\"Please set project requirements first\")\n",
        "\n",
        "                    artwork_details = {\n",
        "                        \"title\": title,\n",
        "                        \"medium\": medium,\n",
        "                        \"dimensions\": dimensions,\n",
        "                        \"additional_notes\": notes\n",
        "                    }\n",
        "\n",
        "                    result = self.system.evaluate_artwork(artwork_details, image)\n",
        "                    self.current_artwork_evaluation = result\n",
        "                    return self._format_evaluation_output(result)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error in artwork evaluation: {str(e)}\")\n",
        "                    return StyleLibrary.format_error_message(str(e))\n",
        "\n",
        "            evaluate_button.click(\n",
        "                handle_artwork_evaluation,\n",
        "                inputs=[artwork_title, artwork_medium, artwork_dimensions, artwork_image, additional_notes],\n",
        "                outputs=[evaluation_output]\n",
        "            )\n",
        "\n",
        "            return tab\n",
        "\n",
        "    def _create_artist_tab(self) -> gr.Tab:\n",
        "        \"\"\"Create the artist evaluation tab.\"\"\"\n",
        "        with gr.Tab(\"Artist Evaluation\") as tab:\n",
        "            gr.Markdown(\"## Evaluate Artist\")\n",
        "\n",
        "            # Artist inputs\n",
        "            artist_name = gr.Textbox(label=\"Artist Name\")\n",
        "            artist_bio = gr.Textbox(\n",
        "                label=\"Artist Biography\",\n",
        "                placeholder=\"Provide a brief biography of the artist...\",\n",
        "                lines=5\n",
        "            )\n",
        "            portfolio_description = gr.Textbox(\n",
        "                label=\"Portfolio Description\",\n",
        "                placeholder=\"Describe the artist's portfolio and relevant experience...\",\n",
        "                lines=5\n",
        "            )\n",
        "\n",
        "            # Evaluation button and output\n",
        "            evaluate_button = gr.Button(\"Evaluate Artist\", variant=\"primary\")\n",
        "            evaluation_output = gr.HTML(label=\"Artist Evaluation Results\")\n",
        "\n",
        "            def handle_artist_evaluation(name, bio, portfolio):\n",
        "                try:\n",
        "                    if not self.system.current_project:\n",
        "                        return StyleLibrary.format_error_message(\"Please set project requirements first\")\n",
        "\n",
        "                    artist_info = {\n",
        "                        \"name\": name,\n",
        "                        \"biography\": bio,\n",
        "                        \"portfolio\": portfolio\n",
        "                    }\n",
        "\n",
        "                    result = self.system.evaluate_artist(artist_info)\n",
        "                    self.current_artist_evaluation = result\n",
        "                    return self._format_evaluation_output(result)\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error in artist evaluation: {str(e)}\")\n",
        "                    return StyleLibrary.format_error_message(str(e))\n",
        "\n",
        "            evaluate_button.click(\n",
        "                handle_artist_evaluation,\n",
        "                inputs=[artist_name, artist_bio, portfolio_description],\n",
        "                outputs=[evaluation_output]\n",
        "            )\n",
        "\n",
        "            return tab\n",
        "\n",
        "    def _create_recommendation_tab(self) -> gr.Tab:\n",
        "        \"\"\"Create the final recommendation tab.\"\"\"\n",
        "        with gr.Tab(\"Final Recommendation\") as tab:\n",
        "            gr.Markdown(\"## Generate Final Recommendation\")\n",
        "\n",
        "            # Status indicators\n",
        "            project_status = gr.Markdown(\"‚ùå Project Requirements: Not Set\")\n",
        "            artwork_status = gr.Markdown(\"‚ùå Artwork Evaluation: Not Complete\")\n",
        "            artist_status = gr.Markdown(\"‚ùå Artist Evaluation: Not Complete\")\n",
        "\n",
        "            # Generate button and output\n",
        "            generate_button = gr.Button(\"Generate Final Recommendation\", variant=\"primary\")\n",
        "            recommendation_output = gr.HTML(label=\"Final Recommendation\")\n",
        "\n",
        "            def update_status():\n",
        "                return [\n",
        "                    gr.update(value=\"‚úÖ Project Requirements: Set\" if self.system.current_project else \"‚ùå Project Requirements: Not Set\"),\n",
        "                    gr.update(value=\"‚úÖ Artwork Evaluation: Complete\" if self.current_artwork_evaluation else \"‚ùå Artwork Evaluation: Not Complete\"),\n",
        "                    gr.update(value=\"‚úÖ Artist Evaluation: Complete\" if self.current_artist_evaluation else \"‚ùå Artist Evaluation: Not Complete\")\n",
        "                ]\n",
        "\n",
        "            def handle_recommendation_generation():\n",
        "                try:\n",
        "                    if not all([self.system.current_project, self.current_artwork_evaluation, self.current_artist_evaluation]):\n",
        "                        return StyleLibrary.format_error_message(\"Please complete all evaluations first\")\n",
        "\n",
        "                    result = self.system.generate_final_recommendation()\n",
        "                    if result.get(\"success\", False):\n",
        "                        return self._format_recommendation_output(result[\"recommendation\"])\n",
        "                    return StyleLibrary.format_error_message(result.get('message', 'Error generating recommendation'))\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error generating recommendation: {str(e)}\")\n",
        "                    return StyleLibrary.format_error_message(str(e))\n",
        "\n",
        "            generate_button.click(\n",
        "                handle_recommendation_generation,\n",
        "                outputs=[recommendation_output]\n",
        "            )\n",
        "\n",
        "            # Update status when tab is selected\n",
        "            tab.select(\n",
        "                update_status,\n",
        "                outputs=[project_status, artwork_status, artist_status]\n",
        "            )\n",
        "\n",
        "            return tab\n",
        "\n",
        "    def _create_history_tab(self) -> gr.Tab:\n",
        "        \"\"\"Create the evaluation history tab.\"\"\"\n",
        "        with gr.Tab(\"History\") as tab:\n",
        "            gr.Markdown(\"## Evaluation History\")\n",
        "\n",
        "            history_output = gr.HTML(label=\"Previous Evaluations\")\n",
        "            refresh_button = gr.Button(\"Refresh History\", variant=\"secondary\")\n",
        "\n",
        "            def handle_history_refresh():\n",
        "                history = self.system.get_evaluation_history()\n",
        "                html = \"<div class='evaluation-container'>\"\n",
        "\n",
        "                for entry in history:\n",
        "                    html += \"<div style='margin-bottom:30px; padding:15px; border:1px solid #ddd; border-radius:5px;'>\"\n",
        "                    html += f\"<h4 class='evaluation-header'>Evaluation at {entry['timestamp']}</h4>\"\n",
        "\n",
        "                    if \"project_context\" in entry and entry[\"project_context\"]:\n",
        "                        html += \"<h5 class='evaluation-header'>Project Details</h5>\"\n",
        "                        project = entry[\"project_context\"]\n",
        "                        html += f\"<p><strong>Title:</strong> {project.get('title', 'N/A')}</p>\"\n",
        "                        html += f\"<p><strong>Type:</strong> {project.get('type', 'N/A')}</p>\"\n",
        "\n",
        "                    if \"evaluation\" in entry:\n",
        "                        html += \"<h5 class='evaluation-header'>Evaluation Results</h5>\"\n",
        "                        eval_data = entry[\"evaluation\"]\n",
        "                        if isinstance(eval_data, dict):\n",
        "                            for key, value in eval_data.items():\n",
        "                                if isinstance(value, (int, float)):\n",
        "                                    html += f\"<p><strong>{key.replace('_', ' ').title()}:</strong> {value:.1f}</p>\"\n",
        "\n",
        "                    html += \"</div>\"\n",
        "\n",
        "                html += \"</div>\"\n",
        "                return html\n",
        "\n",
        "            refresh_button.click(\n",
        "                handle_history_refresh,\n",
        "                outputs=[history_output]\n",
        "            )\n",
        "\n",
        "            return tab\n",
        "\n",
        "    def create_interface(self) -> gr.Blocks:\n",
        "        \"\"\"Create the Gradio interface.\"\"\"\n",
        "        with gr.Blocks(title=\"AI4Art Expert System\", theme=gr.themes.Soft()) as interface:\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                # AI4Art Expert System\n",
        "                ### An AI-powered system for evaluating artwork and artists for projects\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "            with gr.Tabs() as tabs:\n",
        "                project_tab = self._create_project_tab()\n",
        "                artwork_tab = self._create_artwork_tab()\n",
        "                artist_tab = self._create_artist_tab()\n",
        "                recommendation_tab = self._create_recommendation_tab()\n",
        "                history_tab = self._create_history_tab()\n",
        "\n",
        "            # Apply combined styles\n",
        "            gr.Markdown(f\"<style>{StyleLibrary.get_combined_styles()}</style>\")\n",
        "\n",
        "        return interface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_uVcOXioW_4"
      },
      "source": [
        "# **9. Main Execution**\n",
        "### **üöÄ Purpose**:\n",
        "Initializes the entire system, configures API keys, and launches the Gradio app.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- Run this section to start the AI4Art system.\n",
        "- Ensure that all previous sections have been executed successfully.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Start the system by running the cell.\n",
        "- Use the generated link to access the Gradio interface if running in Colab.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4axg5NLMg-76"
      },
      "outputs": [],
      "source": [
        "# === Main Execution Layer ===\n",
        "\n",
        "def initialize_expert_system(api_key: str, model_config: Dict[str, Any]) -> ExpertSystemInterface:\n",
        "    \"\"\"\n",
        "    Expert system cognitive bootstrap implementing the intelligent initialization pattern.\n",
        "    Establishes core knowledge processing capabilities with validated configuration.\n",
        "\n",
        "    Args:\n",
        "        api_key: Validated provider credential for knowledge processing\n",
        "        model_config: Configuration dictionary defining cognitive processing parameters\n",
        "\n",
        "    Returns:\n",
        "        Initialized ExpertSystemInterface with established knowledge processing capabilities\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(__name__)\n",
        "    try:\n",
        "        logger.info(\"Initializing expert system cognitive framework...\")\n",
        "\n",
        "        # Core system initialization\n",
        "        interface = ExpertSystemInterface(api_key)\n",
        "\n",
        "        # Configure knowledge processing models\n",
        "        interface.system.configure_models(model_config)\n",
        "\n",
        "        logger.info(f\"Expert system initialized with {model_config['provider']} knowledge processing\")\n",
        "        return interface\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Expert system initialization failed: {str(e)}\")\n",
        "        raise RuntimeError(f\"Cognitive framework initialization error: {str(e)}\")\n",
        "\n",
        "def get_launch_configuration() -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Determine environment-aware launch parameters implementing the adaptive deployment pattern.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of launch configuration parameters optimized for deployment context\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(__name__)\n",
        "    try:\n",
        "        is_colab = api_config_manager.environment_type == \"colab\"\n",
        "\n",
        "        launch_config = {\n",
        "            \"server_name\": \"0.0.0.0\" if is_colab else None,\n",
        "            \"share\": is_colab,\n",
        "            \"debug\": False,\n",
        "            \"show_error\": True,\n",
        "            \"quiet\": False\n",
        "        }\n",
        "\n",
        "        logger.info(f\"Launch configuration resolved for {api_config_manager.environment_type} environment\")\n",
        "        return launch_config\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Launch configuration error: {str(e)}\")\n",
        "        # Fallback to safe defaults\n",
        "        return {\"debug\": True, \"show_error\": True}\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Enhanced cognitive orchestration layer implementing the expert system deployment pattern.\n",
        "    Provides comprehensive initialization status reporting while coordinating system bootstrap.\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    print(\"\\nExpert System Initialization\")\n",
        "    print(\"===========================\")\n",
        "\n",
        "    try:\n",
        "        # Environment Detection Phase\n",
        "        env_type = api_config_manager.environment_type\n",
        "        print(f\"‚Ä¢ Environment detected: {env_type.upper()}\")\n",
        "\n",
        "        # Configuration State Verification\n",
        "        if not all([EXPERT_SYSTEM_KEY, EXPERT_SYSTEM_CONFIG]):\n",
        "            raise ValueError(\"System configuration not properly initialized\")\n",
        "\n",
        "        # Knowledge Processing Configuration Status\n",
        "        print(f\"‚Ä¢ Provider selected: {EXPERT_SYSTEM_CONFIG['provider']}\")\n",
        "        print(f\"‚Ä¢ Models configured:\")\n",
        "        print(f\"  - Evaluation: {EXPERT_SYSTEM_CONFIG['evaluation_model']}\")\n",
        "        print(f\"  - Vision: {EXPERT_SYSTEM_CONFIG['vision_model']}\")\n",
        "        print(f\"‚Ä¢ Response calibration: temperature={EXPERT_SYSTEM_CONFIG['temperature']}\")\n",
        "\n",
        "        print(\"‚Ä¢ Configuration state verified\")\n",
        "\n",
        "        # Cognitive Framework Initialization\n",
        "        interface = initialize_expert_system(EXPERT_SYSTEM_KEY, EXPERT_SYSTEM_CONFIG)\n",
        "        print(\"‚Ä¢ Cognitive framework initialized\")\n",
        "\n",
        "        # Interface Layer Generation\n",
        "        demo = interface.create_interface()\n",
        "        print(\"‚Ä¢ Interface layer created\")\n",
        "\n",
        "        # Deployment Configuration Resolution\n",
        "        launch_config = get_launch_configuration()\n",
        "        print(f\"‚Ä¢ Launch configuration resolved for {env_type}\")\n",
        "\n",
        "        # System Deployment Phase\n",
        "        print(\"\\nDeploying Expert System...\")\n",
        "        demo.launch(**launch_config)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"System initialization failed: {str(e)}\")\n",
        "        print(f\"\\n‚ùå Error: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting Steps:\")\n",
        "        print(\"1. Verify API credentials are properly configured\")\n",
        "        print(\"2. Check selected provider and model compatibility\")\n",
        "        print(\"3. Ensure all required dependencies are installed\")\n",
        "        print(\"4. Review logs for detailed error information\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configure logging for initialization phase\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler('expert_system.log'),\n",
        "            logging.StreamHandler(sys.stdout)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Launch expert system\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrIHegVgO3j9"
      },
      "source": [
        "# **10. Testing and Debugging**\n",
        "### **üîç Purpose**:\n",
        "Provides tools to validate that the system works as expected. Includes test cases for prompts, models, and the overall workflow.\n",
        "\n",
        "### **üìã How to Use**:\n",
        "- Run the test cases to ensure the system is functioning correctly.\n",
        "- Debug any issues using the output messages.\n",
        "\n",
        "### **üë§ User Actions**:\n",
        "- Use these tools to identify and fix issues.\n",
        "- Developers can add more test cases to validate additional components.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ixa0RKCO3j9"
      },
      "outputs": [],
      "source": [
        "# Debug and Testing\n",
        "def test_llm_methods():\n",
        "    \"\"\"Test harness for LLM methods in the AI4Art system.\"\"\"\n",
        "\n",
        "    # Initialize system with configuration\n",
        "    system = AI4ArtSystem(EXPERT_SYSTEM_KEY)\n",
        "    system.configure_models(EXPERT_SYSTEM_CONFIG)\n",
        "\n",
        "    print(\"\\nAI4Art System Test Harness\")\n",
        "    print(\"=========================\")\n",
        "\n",
        "    def test_project_criteria():\n",
        "        \"\"\"Test project criteria generation.\"\"\"\n",
        "        print(\"\\n1. Testing Project Criteria Generation\")\n",
        "        print(\"---------------------------------\")\n",
        "\n",
        "        test_description = \"\"\"\n",
        "        Create a series of digital artworks for a tech startup's office space.\n",
        "        The artwork should reflect innovation, collaboration, and future-thinking.\n",
        "        Budget is $50,000 and timeline is 3 months.\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Input Description:\", test_description)\n",
        "        print(\"\\nGenerating criteria...\")\n",
        "\n",
        "        try:\n",
        "            criteria = system.generate_project_criteria(test_description)\n",
        "            print(\"\\nGenerated Criteria:\")\n",
        "            print(json.dumps(criteria, indent=2))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error in criteria generation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def test_artwork_evaluation():\n",
        "        \"\"\"Test artwork evaluation chain.\"\"\"\n",
        "        print(\"\\n2. Testing Artwork Evaluation\")\n",
        "        print(\"---------------------------\")\n",
        "\n",
        "        # First set project requirements\n",
        "        project_data = {\n",
        "            \"title\": \"Tech Office Art Series\",\n",
        "            \"type\": \"Digital Art Installation\",\n",
        "            \"description\": \"Modern digital artwork series for tech office\",\n",
        "            \"budget\": 50000,\n",
        "            \"timeline\": \"3 months\"\n",
        "        }\n",
        "\n",
        "        print(\"Setting project requirements...\")\n",
        "        system.set_project_requirements(project_data)\n",
        "\n",
        "        # Test artwork evaluation\n",
        "        try:\n",
        "            # Create a test image (white square)\n",
        "            test_image = Image.new('RGB', (500, 500), 'white')\n",
        "            draw = ImageDraw.Draw(test_image)\n",
        "            draw.rectangle([100, 100, 400, 400], fill='blue')\n",
        "\n",
        "            artwork_details = {\n",
        "                \"title\": \"Digital Harmony\",\n",
        "                \"medium\": \"Digital Art\",\n",
        "                \"dimensions\": \"500x500px\",\n",
        "                \"additional_notes\": \"Abstract representation of digital transformation\"\n",
        "            }\n",
        "\n",
        "            print(\"\\nEvaluating test artwork...\")\n",
        "            result = system.evaluate_artwork(artwork_details, test_image)\n",
        "            print(\"\\nEvaluation Result:\")\n",
        "            print(json.dumps(result, indent=2))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error in artwork evaluation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def test_artist_evaluation():\n",
        "        \"\"\"Test artist evaluation chain.\"\"\"\n",
        "        print(\"\\n3. Testing Artist Evaluation\")\n",
        "        print(\"--------------------------\")\n",
        "\n",
        "        artist_info = {\n",
        "            \"name\": \"Alex Digital\",\n",
        "            \"biography\": \"\"\"\n",
        "            Digital artist with 10 years of experience in creating immersive digital experiences.\n",
        "            Specialized in large-scale installations and interactive art.\n",
        "            Previously worked with major tech companies on office art installations.\n",
        "            \"\"\",\n",
        "            \"portfolio\": \"\"\"\n",
        "            - Created 15 large-scale digital installations\n",
        "            - Expertise in projection mapping and interactive displays\n",
        "            - Award-winning pieces featured in modern art museums\n",
        "            - Proficient in various digital art tools and technologies\n",
        "            \"\"\"\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(\"Evaluating test artist...\")\n",
        "            result = system.evaluate_artist(artist_info)\n",
        "            print(\"\\nEvaluation Result:\")\n",
        "            print(json.dumps(result, indent=2))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error in artist evaluation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def test_final_recommendation():\n",
        "        \"\"\"Test final recommendation generation.\"\"\"\n",
        "        print(\"\\n4. Testing Final Recommendation\")\n",
        "        print(\"-----------------------------\")\n",
        "\n",
        "        try:\n",
        "            print(\"Generating final recommendation...\")\n",
        "            result = system.generate_final_recommendation()\n",
        "            print(\"\\nRecommendation Result:\")\n",
        "            print(json.dumps(result, indent=2))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error in recommendation generation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    # Run all tests\n",
        "    tests = [\n",
        "        (\"Project Criteria\", test_project_criteria),\n",
        "        (\"Artwork Evaluation\", test_artwork_evaluation),\n",
        "        (\"Artist Evaluation\", test_artist_evaluation),\n",
        "        (\"Final Recommendation\", test_final_recommendation)\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    for test_name, test_func in tests:\n",
        "        print(f\"\\nExecuting {test_name} test...\")\n",
        "        success = test_func()\n",
        "        results.append((test_name, success))\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nTest Summary\")\n",
        "    print(\"===========\")\n",
        "    for test_name, success in results:\n",
        "        status = \"‚úì Passed\" if success else \"‚úó Failed\"\n",
        "        print(f\"{test_name}: {status}\")\n",
        "\n",
        "# Run tests\n",
        "test_llm_methods()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random"
      ],
      "metadata": {
        "id": "kaiTBJYVS4gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Default prompts\n",
        "default_prompts = {\n",
        "    \"artwork_evaluation\": \"Evaluate the following artwork based on creativity, technical quality, and impact: {artwork_details}\",\n",
        "    \"artist_evaluation\": \"Assess the following artist based on experience, portfolio quality, and style match: {artist_details}\",\n",
        "}\n",
        "\n",
        "# Create tabbed form fields for dynamic prompt input\n",
        "tab = widgets.Tab()\n",
        "\n",
        "# Textareas for editing prompts\n",
        "artwork_prompt_input = widgets.Textarea(\n",
        "    value=default_prompts[\"artwork_evaluation\"],\n",
        "    description=\"Artwork Prompt:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"100px\")\n",
        ")\n",
        "\n",
        "artist_prompt_input = widgets.Textarea(\n",
        "    value=default_prompts[\"artist_evaluation\"],\n",
        "    description=\"Artist Prompt:\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"100px\")\n",
        ")\n",
        "\n",
        "# Tab structure\n",
        "tab.children = [artwork_prompt_input, artist_prompt_input]\n",
        "tab.set_title(0, \"Artwork Prompt\")\n",
        "tab.set_title(1, \"Artist Prompt\")\n",
        "\n",
        "# Button to apply changes\n",
        "apply_button = widgets.Button(description=\"Update Prompts\")\n",
        "\n",
        "# Output for displaying confirmation messages\n",
        "output = widgets.Output()\n",
        "\n",
        "# Callback to update prompts\n",
        "def update_prompts(button):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        try:\n",
        "            # Update the default prompts with user input\n",
        "            default_prompts[\"artwork_evaluation\"] = artwork_prompt_input.value\n",
        "            default_prompts[\"artist_evaluation\"] = artist_prompt_input.value\n",
        "            print(\"Prompts updated successfully!\")\n",
        "            print(\"Updated Prompts:\")\n",
        "            print(\"Artwork Evaluation:\", default_prompts[\"artwork_evaluation\"])\n",
        "            print(\"Artist Evaluation:\", default_prompts[\"artist_evaluation\"])\n",
        "        except Exception as e:\n",
        "            print(f\"Error updating prompts: {e}\")\n",
        "\n",
        "# Bind callback to the button\n",
        "apply_button.on_click(update_prompts)\n",
        "\n",
        "# Display form\n",
        "display(tab, apply_button, output)\n"
      ],
      "metadata": {
        "id": "MC6IIDBXS6jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBxtGWygV84l"
      },
      "source": [
        "\n",
        "## System Initialization Flow\n",
        "\n",
        "### 1. Initial Setup\n",
        "When the AI4Art system is initialized, it follows this sequence:\n",
        "\n",
        "#### System Configuration\n",
        "- The `SystemConfig.create_config()` method establishes base parameters:\n",
        "  - Temperature settings for model responses\n",
        "  - Model names and versions\n",
        "  - Safety thresholds for content filtering\n",
        "  - Default evaluation criteria\n",
        "\n",
        "#### Model Initialization\n",
        "- Based on the provided API key type (OpenAI or Google), the system initializes:\n",
        "  - A primary language model (GPT-4 or Gemini)\n",
        "  - A vision model (GPT-4-Vision or Gemini Pro Vision)\n",
        "  - Output parsers for structured responses\n",
        "\n",
        "#### State Management Setup\n",
        "- Initializes empty evaluation history\n",
        "- Sets up null states for:\n",
        "  - Current project\n",
        "  - Current criteria\n",
        "  - Current artwork evaluation\n",
        "  - Current artist evaluation\n",
        "\n",
        "## Core Workflow and Method Chain\n",
        "\n",
        "### 1. Project Requirements Phase\n",
        "\n",
        "#### Setting Project Requirements\n",
        "**Input:**\n",
        "- Project title\n",
        "- Project type\n",
        "- Project description\n",
        "- Budget (optional)\n",
        "- Timeline (optional)\n",
        "\n",
        "**Process:**\n",
        "1. The system validates inputs\n",
        "2. Generates project-specific criteria using LLM\n",
        "3. Creates default criteria if LLM generation fails\n",
        "\n",
        "**Output:**\n",
        "- Structured criteria object containing:\n",
        "  - Artistic requirements\n",
        "  - Technical requirements\n",
        "  - Style preferences\n",
        "  - Evaluation metrics\n",
        "  - Suggested artist profile\n",
        "\n",
        "### 2. Artist Evaluation Phase\n",
        "\n",
        "#### Artist Analysis\n",
        "**Input:**\n",
        "- Artist name\n",
        "- Artist biography\n",
        "- Portfolio description\n",
        "\n",
        "**Process:**\n",
        "1. LLM analyzes artist information against project criteria\n",
        "2. Generates numerical scores and rationales\n",
        "3. Creates visual representations of scores\n",
        "\n",
        "**Output:**\n",
        "- Comprehensive artist evaluation including:\n",
        "  - Experience score\n",
        "  - Style match score\n",
        "  - Technical capability score\n",
        "  - Project suitability score\n",
        "  - Detailed rationales for each score\n",
        "\n",
        "### 3. Artwork Evaluation Phase\n",
        "\n",
        "#### Visual Analysis\n",
        "**Input:**\n",
        "- Artwork image\n",
        "- Artwork details (title, medium, dimensions)\n",
        "- Additional notes\n",
        "\n",
        "**Process:**\n",
        "1. Vision model analyzes image composition\n",
        "2. LLM interprets visual elements\n",
        "3. Combines analysis with project requirements\n",
        "\n",
        "**Output:**\n",
        "- Detailed artwork evaluation including:\n",
        "  - Technical score\n",
        "  - Creativity score\n",
        "  - Project fit score\n",
        "  - Visual impact score\n",
        "  - Analysis of composition, color, technique\n",
        "\n",
        "### 4. Final Recommendation Phase\n",
        "\n",
        "#### Comprehensive Evaluation\n",
        "**Input:**\n",
        "- Artist evaluation results\n",
        "- Artwork evaluation results\n",
        "- Project requirements\n",
        "\n",
        "**Process:**\n",
        "1. Combines all previous evaluations\n",
        "2. Calculates overall suitability scores\n",
        "3. Generates actionable recommendations\n",
        "\n",
        "**Output:**\n",
        "- Final recommendation report including:\n",
        "  - Combined suitability score\n",
        "  - Strengths and risks\n",
        "  - Next steps\n",
        "  - Timeline and budget considerations\n",
        "\n",
        "## LLM Integration Details\n",
        "\n",
        "### 1. Project Criteria Generation\n",
        "- **LLM Role**: Analyzes project description to generate custom criteria\n",
        "- **Prompt Structure**: Includes project context and required output format\n",
        "- **Output Processing**: Converts LLM response to structured criteria object\n",
        "\n",
        "### 2. Artist Evaluation\n",
        "- **LLM Role**: Evaluates artist biography and portfolio\n",
        "- **Prompt Structure**: Includes project criteria and evaluation metrics\n",
        "- **Output Processing**: Generates numerical scores with explanations\n",
        "\n",
        "### 3. Artwork Analysis\n",
        "- **Vision Model Role**: Analyzes visual elements and composition\n",
        "- **LLM Role**: Interprets visual analysis and generates evaluation\n",
        "- **Combined Processing**: Merges visual and contextual analysis\n",
        "\n",
        "### 4. Recommendation Generation\n",
        "- **LLM Role**: Synthesizes all evaluations into final recommendation\n",
        "- **Prompt Structure**: Includes all previous evaluations and project context\n",
        "- **Output Processing**: Generates structured recommendation report\n",
        "\n",
        "## State Management and Data Flow\n",
        "\n",
        "### 1. Project State\n",
        "- Maintains current project details\n",
        "- Updates criteria as generated\n",
        "- Tracks evaluation progress\n",
        "\n",
        "### 2. Evaluation State\n",
        "- Stores current evaluations\n",
        "- Maintains history of all evaluations\n",
        "- Enables comparison and tracking\n",
        "\n",
        "### 3. Output State\n",
        "- Manages formatted outputs\n",
        "- Handles visualization data\n",
        "- Stores recommendation history\n",
        "\n",
        "## Error Handling and Fallbacks\n",
        "\n",
        "### 1. LLM Error Handling\n",
        "- Retries failed LLM calls\n",
        "- Uses default criteria when generation fails\n",
        "- Maintains system stability during errors\n",
        "\n",
        "### 2. Vision Model Fallbacks\n",
        "- Handles image processing errors\n",
        "- Provides feedback for invalid inputs\n",
        "- Maintains partial analysis capability\n",
        "\n",
        "### 3. State Recovery\n",
        "- Preserves evaluation progress\n",
        "- Enables continuation after errors\n",
        "- Maintains data consistency\n",
        "\n",
        "## System Limitations and Considerations\n",
        "\n",
        "### 1. LLM Dependencies\n",
        "- Requires active API connections\n",
        "- Subject to model version changes\n",
        "- Rate limiting considerations\n",
        "\n",
        "### 2. Vision Analysis Constraints\n",
        "- Image quality requirements\n",
        "- Processing time limitations\n",
        "- Format restrictions\n",
        "\n",
        "### 3. Evaluation Boundaries\n",
        "- Subjective assessment limitations\n",
        "- Cultural context considerations\n",
        "- Technical feasibility constraints"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4YW0EpIMV84l",
        "gnhjgPcjlFD3",
        "UIT4lZN1lZr1",
        "zpd2meSx-8sN",
        "8epnK_QN_BBk",
        "YhzXgWhJgLsl",
        "uEFhQX8GhUED",
        "PjRoREf3hcIU",
        "JnGYt3b-hi-b",
        "lw7o8LETg6kV"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb7513d2681b4e8cb958d7e76281a9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TabModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TabModel",
            "_titles": {
              "0": "Project Criteria Prompt",
              "1": "Artwork Evaluation Prompt",
              "2": "Artist Evaluation Prompt",
              "3": "Vision Analysis Prompt",
              "4": "Final Recommendation Prompt"
            },
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TabView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c96f2be16596445197c069bb790663e1",
              "IPY_MODEL_786c41b5cd2e455a9dd0479d1ee6a40c",
              "IPY_MODEL_98b9834ef039496ea23778ffe9e9c44b",
              "IPY_MODEL_ea0c7f7eecc7442a9c22dba0de91f807",
              "IPY_MODEL_645688bbfb864ef5af972d1e46428da2"
            ],
            "layout": "IPY_MODEL_ddbe04d6f64d47de981f9286efcda3fc",
            "selected_index": 0
          }
        },
        "c96f2be16596445197c069bb790663e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Project Criteria Prompt",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f921e8170f6c41949b4547c28993ce0d",
            "placeholder": "‚Äã",
            "rows": null,
            "style": "IPY_MODEL_61373859acee4b8e8e43997fa975fca7",
            "value": "Based on the following project description, generate specific evaluation criteria and an ideal artist profile that would be suitable for the project.\n\nProject Description:\n{project_description}\n\n{format_instructions}\n\nGenerate a comprehensive set of criteria that includes specific requirements, metrics, and preferences.\nFocus on actionable and measurable criteria that can be used to evaluate both artwork and artists.\n\nThe response should follow this exact structure:\n{{\n    \"artistic_requirements\": [\n        \"Detailed requirement 1\",\n        \"Detailed requirement 2\"\n    ],\n    \"technical_requirements\": [\n        \"Specific technical requirement 1\",\n        \"Specific technical requirement 2\"\n    ],\n    \"style_preferences\": [\n        \"Clear style preference 1\",\n        \"Clear style preference 2\"\n    ],\n    \"evaluation_metrics\": {{\n        \"creativity\": \"Description of how creativity will be evaluated\",\n        \"technical_skill\": \"Description of how technical skill will be evaluated\"\n    }},\n    \"suggested_artist_profile\": {{\n        \"experience\": \"Required years and type of experience\",\n        \"skills\": \"Specific skills needed for this project\"\n    }}\n}}"
          }
        },
        "786c41b5cd2e455a9dd0479d1ee6a40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Artwork Evaluation Prompt",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e12f3b73f1774d6091b53014b793b042",
            "placeholder": "‚Äã",
            "rows": null,
            "style": "IPY_MODEL_34e259167f0e497f85f72c6e558a9a87",
            "value": "Evaluate the artwork based on the following information:\n\nProject Context:\n{project_context}\n\nVisual Analysis:\n{visual_analysis}\n\nArtwork Details:\n{artwork_details}\n\n{format_instructions}\n\nYour response MUST be a valid JSON object matching the ArtworkEvaluation model structure.\nEnsure all numeric scores are between 0 and 10.\n\nThe response should follow this exact structure:\n{{\n    \"technical_score\": 0.0,\n    \"creativity_score\": 0.0,\n    \"project_fit_score\": 0.0,\n    \"visual_impact_score\": 0.0,\n    \"criteria_alignment\": {{\n        \"metric1\": 0.0,\n        \"metric2\": 0.0\n    }},\n    \"strengths\": [\n        \"Strength 1\",\n        \"Strength 2\"\n    ],\n    \"areas_for_improvement\": [\n        \"Area 1\",\n        \"Area 2\"\n    ],\n    \"visual_analysis\": {{\n        \"composition\": \"Analysis of composition\",\n        \"technique\": \"Analysis of technique\",\n        \"impact\": \"Analysis of visual impact\"\n    }},\n    \"overall_recommendation\": \"Detailed recommendation text\"\n}}"
          }
        },
        "98b9834ef039496ea23778ffe9e9c44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Artist Evaluation Prompt",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bc126e6882f84c1ba456fda16c0b3d08",
            "placeholder": "‚Äã",
            "rows": null,
            "style": "IPY_MODEL_2dc53a5f96094459921ccea9e96f22be",
            "value": "Evaluate the artist's suitability for the project based on their information and the project criteria.\n\nProject Context:\n{project_context}\n\nArtist Information:\n{artist_info}\n\n{format_instructions}\n\nYour response MUST be a valid JSON object matching the ArtistEvaluation model structure.\nEnsure all numeric scores are between 0 and 10.\n\nThe response should follow this exact structure:\n{{\n    \"experience_score\": 0.0,\n    \"style_match_score\": 0.0,\n    \"technical_capability_score\": 0.0,\n    \"project_suitability_score\": 0.0,\n    \"strengths\": [\n        \"Strength 1\",\n        \"Strength 2\"\n    ],\n    \"considerations\": [\n        \"Consideration 1\",\n        \"Consideration 2\"\n    ],\n    \"profile_analysis\": {{\n        \"experience\": \"Analysis of experience\",\n        \"skills\": \"Analysis of skills\",\n        \"style\": \"Analysis of artistic style\"\n    }},\n    \"criteria_alignment\": {{\n        \"metric1\": 0.0,\n        \"metric2\": 0.0\n    }},\n    \"overall_assessment\": \"Detailed assessment text\"\n}}"
          }
        },
        "ea0c7f7eecc7442a9c22dba0de91f807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Vision Analysis Prompt",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_565c062aedcf4a3eb04b455382e5285a",
            "placeholder": "‚Äã",
            "rows": null,
            "style": "IPY_MODEL_f4082c68bd734883a4c3688ee0898e3e",
            "value": "Analyze this artwork  considering the following aspects:\n\n1. Composition and layout\n2. Color palette and use of color\n3. Technique and medium\n4. Visual elements and symbolism\n5. Overall aesthetic impact\n6. Technical execution quality\n7. Creative interpretation\n8. Emotional resonance\n9. Cultural context and references\n10. Innovation and originality\n\nPlease provide a detailed analysis that can be used to evaluate the artwork against project requirements.\nFocus on concrete observations and specific details rather than general impressions.\nYour analysis should help inform both technical and artistic evaluation scores."
          }
        },
        "645688bbfb864ef5af972d1e46428da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Final Recommendation Prompt",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_eb53c6042bde489299e4d05a82239bfe",
            "placeholder": "‚Äã",
            "rows": null,
            "style": "IPY_MODEL_5344cd175b144efe81c9dd9fcb008c3f",
            "value": "Generate a final recommendation based on the complete evaluation.\n\nProject Requirements:\n{project_requirements}\n\nArtwork Evaluation:\n{artwork_evaluation}\n\nArtist Evaluation:\n{artist_evaluation}\n\nProvide a comprehensive recommendation including:\n1. Overall project fit assessment\n2. Key strengths and unique value propositions\n3. Potential risks and mitigation strategies\n4. Timeline and budget considerations\n5. Specific next steps and action items\n6. Long-term value and potential impact\n7. Alternative approaches or considerations\n8. Success metrics and evaluation criteria\n\nYour response should be detailed and actionable, with clear justification for the recommendation based on the evaluations provided."
          }
        },
        "ddbe04d6f64d47de981f9286efcda3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f921e8170f6c41949b4547c28993ce0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "61373859acee4b8e8e43997fa975fca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e12f3b73f1774d6091b53014b793b042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "34e259167f0e497f85f72c6e558a9a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc126e6882f84c1ba456fda16c0b3d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2dc53a5f96094459921ccea9e96f22be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "565c062aedcf4a3eb04b455382e5285a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f4082c68bd734883a4c3688ee0898e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb53c6042bde489299e4d05a82239bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "150px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5344cd175b144efe81c9dd9fcb008c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7bf49fec1704cc0bcd3db9a0ef01505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Update Prompts",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_371c182c77f046958cebe18f86646846",
            "style": "IPY_MODEL_00a0bc145b47447f9781ab51431bf15a",
            "tooltip": ""
          }
        },
        "371c182c77f046958cebe18f86646846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00a0bc145b47447f9781ab51431bf15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7704f92884ec466998ee9e0b283266bc": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2ea0cc2234834a7098c47ae12e78dc84",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Prompts updated successfully!\n"
                ]
              }
            ]
          }
        },
        "2ea0cc2234834a7098c47ae12e78dc84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}